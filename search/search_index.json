{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AirSDLC","text":"<p>The AI-Responsible Software Development Lifecycle</p> <p>A comprehensive framework specification for AI-driven software development that bridges the gap between business requirements and production code.</p>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<ul> <li> <p>\ud83d\udcd6 Get Started</p> <p>New to AirSDLC? Start here to understand the framework.</p> <p>\u2192 Read Overview</p> </li> <li> <p>\ud83e\udde0 Core Philosophy</p> <p>Learn the foundational AI-DLC principles behind AirSDLC.</p> <p>\u2192 Explore Philosophy</p> </li> <li> <p>\ud83d\udd04 Three Phases</p> <p>Understand Inception, Design, and Construction phases.</p> <p>\u2192 View Lifecycle</p> </li> <li> <p>\ud83d\udcc4 Artifacts</p> <p>Complete specifications for DAA, ADR, TIP, RFC, and more.</p> <p>\u2192 Browse Artifacts</p> </li> <li> <p>\u2705 Workflow Guide</p> <p>Step-by-step process from PRD to production.</p> <p>\u2192 Follow Workflow</p> </li> <li> <p>\u26a1 Operations</p> <p>Context-aware incident response and monitoring.</p> <p>\u2192 Learn Operations</p> </li> <li> <p>\ud83e\udde9 Extensibility</p> <p>Adapt the framework to your team's unique needs.</p> <p>\u2192 Extend Framework</p> </li> <li> <p>\ud83d\udcbb Examples</p> <p>See real-world artifacts in action.</p> <p>\u2192 View Examples</p> </li> </ul>"},{"location":"#what-is-airsdlc","title":"What is AirSDLC?","text":"<p>AirSDLC (AI-Responsible Software Development Lifecycle) is not a tool\u2014it is a framework specification that provides:</p> <ul> <li>Core Principles: AI-driven execution with human oversight</li> <li>Artifact Definitions: Structured specifications for all lifecycle artifacts</li> <li>Lifecycle Phases: Sequential knowledge handoff from business to code</li> <li>Workflow Patterns: Repeatable, validated processes</li> <li>Extension Guidelines: Adapt to your team's needs</li> </ul>"},{"location":"#the-three-phases","title":"The Three Phases","text":"<pre><code>graph LR\n    A[Business Intent] --&gt; B(Inception)\n    B --&gt; C[AI-DAA]\n    C --&gt; D(Design)\n    D --&gt; E[AI-ADR]\n    E --&gt; F(Construction)\n    F --&gt; G[Production Code]</code></pre> <ol> <li>Inception (The \"WHAT\") - Business intent \u2192 Domain model</li> <li>Design (The \"HOW\") - Domain model \u2192 Architecture decisions</li> <li>Construction (The \"BUILD &amp; RUN\") - Decisions \u2192 Production code</li> </ol>"},{"location":"#framework-vs-implementation","title":"Framework vs. Implementation","text":"<p>Important Distinction</p> <ul> <li>AirSDLC (this repository): The framework specification</li> <li>Implementation Tools: Concrete software that implements the framework</li> </ul> <p>This separation ensures multiple tools can implement the same standard.</p> <p>Framework Origins</p> <p>AirSDLC is an open-source implementation of the AI-Driven Development Lifecycle (AI-DLC) framework developed by Amazon Web Services. See AI-DLC Attribution for details.</p>"},{"location":"#for-different-audiences","title":"For Different Audiences","text":"Teams Adopting AirSDLCTool ImplementersArchitects &amp; Leads <p>Getting Started:</p> <ol> <li>Read Overview for the big picture</li> <li>Study Philosophy for core principles</li> <li>Follow Workflow for practical guidance</li> <li>Explore Examples to see artifacts</li> </ol> <p>Best Practices:</p> <ul> <li>Start with Lightweight Workflow for simple features</li> <li>Use Full Workflow for complex/high-risk features</li> <li>Maintain Knowledge Repository as single source of truth</li> <li>Validate AI outputs at every phase</li> </ul> <p>Implementation Guide:</p> <ol> <li>Review Artifacts for data structures</li> <li>Study Lifecycle for phase requirements</li> <li>Check Extensibility for conformance criteria</li> <li>Build tools that implement this specification</li> </ol> <p>Conformance Requirements:</p> <ul> <li>\u2705 Implement core artifacts (PRD, DAA/TIP, ADR)</li> <li>\u2705 Support sequential phases with validation gates</li> <li>\u2705 Maintain traceability chain</li> <li>\u2705 Store artifacts in Knowledge Repository</li> </ul> <p>Strategic Adoption:</p> <ul> <li>Evaluate Philosophy against team values</li> <li>Customize Extensibility for your context</li> <li>Build Architectural Playbook</li> <li>Define workflow paths for your complexity matrix</li> </ul> <p>Key Decisions:</p> <ul> <li>Full vs Lightweight workflow thresholds</li> <li>Custom artifact types for compliance</li> <li>Validation ceremony cadence</li> <li>Tool selection criteria</li> </ul>"},{"location":"#ready-to-start","title":"Ready to Start?","text":"<p>   \ud83d\ude80 Get Started </p> <p>   \ud83d\udce6 View on GitHub </p>    Built with \u2764\ufe0f by the AirsStack community |    GitHub"},{"location":"AI-DLC-ATTRIBUTION/","title":"AI-DLC Attribution and Sources","text":""},{"location":"AI-DLC-ATTRIBUTION/#official-amazon-ai-dlc-framework","title":"Official Amazon AI-DLC Framework","text":"<p>The AI-Driven Development Lifecycle (AI-DLC) is an official framework developed by Amazon Web Services (AWS) and introduced by Raja SP, Principal Solutions Architect at AWS.</p>"},{"location":"AI-DLC-ATTRIBUTION/#official-sources","title":"Official Sources","text":"<ol> <li>AWS Blog Post: AI-Driven Development Life Cycle: Reimagining Software Engineering</li> <li>Published: July 31, 2025</li> <li> <p>Author: Raja SP, Principal Solutions Architect, AWS</p> </li> <li> <p>AI-DLC White Paper: https://prod.d13rzhkk8cj2z0.amplifyapp.com/</p> </li> <li>Comprehensive methodology documentation</li> <li>Detailed terminology and rituals</li> </ol>"},{"location":"AI-DLC-ATTRIBUTION/#key-ai-dlc-concepts-from-aws","title":"Key AI-DLC Concepts (from AWS)","text":"<p>Core Philosophy: - AI-Powered Execution with Human Oversight: AI creates plans, seeks clarification, and defers critical decisions to humans - Dynamic Team Collaboration: Teams unite in collaborative spaces for real-time problem-solving</p> <p>Three Phases: 1. Inception Phase: Transform business intent into detailed requirements through \"Mob Elaboration\" 2. Construction Phase: AI proposes logical architecture, domain models, code, and tests through \"Mob Construction\" 3. Operations Phase: AI manages infrastructure as code and deployments with team oversight</p> <p>New Terminology: - Bolts: Replace \"sprints\" - shorter work cycles measured in hours/days instead of weeks - Units of Work (UoW): Replace \"Epics\" - primary containers for functionality - Mob Elaboration: Cross-functional team validates AI's questions and proposals (Inception) - Mob Construction: Technical team provides clarification on architectural choices (Construction)</p> <p>Core Mental Model: <pre><code>AI proposes \u2192 AI clarifies \u2192 Human validates \u2192 AI implements\n(This cycle repeats rapidly for every SDLC activity)\n</code></pre></p>"},{"location":"AI-DLC-ATTRIBUTION/#how-airsdlc-relates-to-ai-dlc","title":"How AirSDLC Relates to AI-DLC","text":"<p>AirSDLC is a practical, open-source implementation of the AWS AI-DLC methodology, adapted and extended with:</p> <ol> <li>Domain-Driven Design (DDD): AirSDLC adopts DDD as the core modeling language for domain analysis</li> <li>Specific Artifact Definitions: Concrete specifications for DAA, ADR, TIP, RFC, and Playbook</li> <li>Technology Agnosticism: Emphasis on 100% technology-neutral domain modeling</li> <li>Extensibility Framework: Well-defined extension points for customization</li> <li>Lightweight Workflow Option: Pragmatic path for simple features (TIP-based workflow)</li> </ol> <p>Attribution: - AI-DLC: \u00a9 Amazon Web Services, Inc. - AirSDLC: Open-source framework implementing AI-DLC principles</p>"},{"location":"AI-DLC-ATTRIBUTION/#references","title":"References","text":"<ul> <li>AWS Blog: https://aws.amazon.com/blogs/devops/ai-driven-development-life-cycle/</li> <li>AI-DLC White Paper: https://prod.d13rzhkk8cj2z0.amplifyapp.com/</li> <li>Amazon Q Developer: https://aws.amazon.com/q/developer/</li> <li>Kiro: https://kiro.dev/</li> </ul> <p>Last Updated: December 7, 2025</p>"},{"location":"artifacts/","title":"AirSDLC Artifacts","text":""},{"location":"artifacts/#overview","title":"Overview","text":"<p>Artifacts are the structured data objects that flow through the AirSDLC lifecycle. Each artifact has a specific purpose, defined structure, and clear ownership model. This document provides detailed specifications for each core artifact type.</p>"},{"location":"artifacts/#artifact-classification","title":"Artifact Classification","text":"<p>Artifacts can be classified along two dimensions:</p>"},{"location":"artifacts/#by-lifecycle-phase","title":"By Lifecycle Phase","text":"Phase Artifacts Inception PRD, AI-DAA, TIP Design RFC, AI-ADR, Architectural Playbook Construction Bolt, Deployment Unit Operations Post-mortem, Fix-It Bolt"},{"location":"artifacts/#by-technology-specificity","title":"By Technology Specificity","text":"Classification Artifacts Technology-Agnostic PRD, AI-DAA Technology-Specific TIP, RFC, AI-ADR, Bolt"},{"location":"artifacts/#phase-1-artifacts-inception","title":"Phase 1 Artifacts: Inception","text":""},{"location":"artifacts/#1-prd-product-requirements-document","title":"1. PRD (Product Requirements Document)","text":"<p>Purpose: Define the business requirements and success criteria for a feature.</p> <p>Generator: Product Manager (with optional AI assistance)</p> <p>Consumers: Engineering team, AI (for DAA generation)</p> <p>Key Characteristics: - Business-focused (minimal technical details) - Structured and parseable by AI - Contains clear success metrics</p> <p>Mandatory Sections:</p>"},{"location":"artifacts/#1-feature-overview","title":"1. Feature Overview","text":"<ul> <li>Title: Descriptive name</li> <li>Objective: One-paragraph summary of the business goal</li> <li>Target Users: Who will use this feature?</li> </ul>"},{"location":"artifacts/#2-user-stories","title":"2. User Stories","text":"<p>Format: \"As a [role], I want [capability] so that [benefit]\"</p> <p>Each story must include: - Acceptance Criteria: Testable conditions for \"done\" - Priority: Must-have, should-have, nice-to-have</p>"},{"location":"artifacts/#3-non-functional-requirements-nfrs","title":"3. Non-Functional Requirements (NFRs)","text":"<ul> <li>Performance: Response times, throughput requirements</li> <li>Availability: Uptime requirements (e.g., 99.9%)</li> <li>Scalability: Expected load (users, transactions, data volume)</li> <li>Security: Authentication, authorization, data protection</li> <li>Compliance: Regulatory requirements (GDPR, PCI-DSS, etc.)</li> </ul>"},{"location":"artifacts/#4-risk-assessment","title":"4. Risk Assessment","text":"<ul> <li>Identified Risks: What could go wrong?</li> <li>Mitigation Strategies: How to reduce risk</li> <li>Assumptions: What we're assuming to be true</li> </ul>"},{"location":"artifacts/#5-success-metrics","title":"5. Success Metrics","text":"<ul> <li>Primary KPI: The main measure of success</li> <li>Secondary Metrics: Supporting indicators</li> <li>Measurement Method: How these will be tracked</li> </ul>"},{"location":"artifacts/#6-constraints","title":"6. Constraints","text":"<ul> <li>Timeline: Deadlines, milestones</li> <li>Budget: Resource limitations</li> <li>Technical Constraints: Must use specific technologies, integrate with existing systems</li> <li>Team Constraints: Available skills, team size</li> </ul> <p>Example Structure: <pre><code># PRD: Booking Notes Feature\n\n## 1. Feature Overview\n- **Title**: Booking Notes\n- **Objective**: Allow users to add custom notes to their bookings\n- **Target Users**: All users with reservations\n\n## 2. User Stories\n### Story 1: Add Notes\nAs a user, I want to add notes to my booking so that I can easily remember important details.\n\n**Acceptance Criteria**:\n- User can set notes via mobile app\n- Notes are 1-200 characters\n- Notes are displayed in booking details\n- User can change notes anytime\n\n**Priority**: Must-have\n\n## 3. Non-Functional Requirements\n- **Performance**: Notes save &lt; 500ms\n- **Availability**: 99.9% uptime\n- **Security**: Notes are user-specific (no cross-user access)\n\n## 4. Risks\n- **Risk**: Inappropriate content in notes\n- **Mitigation**: Implement content moderation filter\n\n## 5. Success Metrics\n- **Primary KPI**: 40% of users add notes within 30 days\n- **Secondary**: &lt; 1% support tickets related to notes feature\n\n## 6. Constraints\n- **Timeline**: Must launch in 2 weeks\n- **Technical**: Must integrate with existing booking service API\n</code></pre></p>"},{"location":"artifacts/#2-ai-daa-domain-architecture-analysis","title":"2. AI-DAA (Domain Architecture Analysis)","text":"<p>Purpose: Provide a pure, technology-agnostic model of the business domain using Domain-Driven Design patterns.</p> <p>Generator: AI (from PRD input)</p> <p>Validators: Domain experts, architects, senior engineers</p> <p>Consumers: Engineers (for design), AI (for ADR generation)</p> <p>Key Characteristics: - 100% technology-neutral (no databases, languages, frameworks) - Uses DDD patterns consistently - Written in clear pseudocode - Every business invariant is explicit</p> <p>Mandatory Sections:</p>"},{"location":"artifacts/#1-strategic-design","title":"1. Strategic Design","text":"<p>1.1 Bounded Contexts Define logical boundaries for different parts of the domain.</p> <pre><code>BOUNDED_CONTEXT: Booking Management\n  RESPONSIBILITY: \n    - Booking lifecycle management\n    - Booking state transitions\n    - Booking-level business rules\n\n  UBIQUITOUS_LANGUAGE:\n    - Booking: A reservation for a room or resource\n    - BookingStatus: confirmed | cancelled | completed\n    - Cancel: Termination of a confirmed booking\n</code></pre> <p>1.2 Context Map Define relationships between Bounded Contexts.</p> <pre><code>CONTEXT_MAP:\n  [Booking Management] --publishes events--&gt; [Notification Service]\n  [Booking Management] --queries--&gt; [User Service]\n  [Booking Management] &lt;--ACL-- [External Property Management System]\n</code></pre>"},{"location":"artifacts/#2-tactical-design","title":"2. Tactical Design","text":"<p>2.1 Aggregates Define consistency boundaries with a root entity.</p> <pre><code>AGGREGATE: Booking\n  AGGREGATE_ROOT: Booking\n    IDENTITY: booking_id (UUID)\n\n    ATTRIBUTES:\n      user_id: UserID (reference to User aggregate)\n      status: BookingStatus (value object)\n      confirmation_code: ConfirmationCode (value object)\n      room_details: RoomDetails (value object)\n      created_at: Timestamp\n      updated_at: Timestamp\n\n    INVARIANTS:\n      - confirmation_code must be unique across all bookings\n      - status transitions must follow state machine\n      - only confirmed bookings can be cancelled\n      - completed bookings are terminal (no further transitions)\n\n    OPERATIONS:\n      create(user_id, room_id, dates) \u2192 BookingConfirmed\n        PRECONDITION: user exists and room is available\n        POSTCONDITION: booking.status = confirmed\n        DOMAIN_EVENT: BookingConfirmed\n\n      cancel(reason) \u2192 BookingCancelled\n        PRECONDITION: status = confirmed\n        POSTCONDITION: status = cancelled\n        DOMAIN_EVENT: BookingCancelled\n\n      complete() \u2192 BookingCompleted\n        PRECONDITION: status = confirmed AND check-out date passed\n        POSTCONDITION: status = completed\n        DOMAIN_EVENT: BookingCompleted\n\n      modify(new_dates) \u2192 BookingModified\n        PRECONDITION: status = confirmed\n        POSTCONDITION: dates updated, status remains confirmed\n        DOMAIN_EVENT: BookingModified\n</code></pre> <p>2.2 Value Objects Immutable objects defined by their attributes.</p> <pre><code>VALUE_OBJECT: BookingStatus\n  ALLOWED_VALUES: [confirmed, cancelled, completed]\n\n  OPERATIONS:\n    can_transition_to(new_status) \u2192 Boolean\n      RULES:\n        confirmed \u2192 cancelled: YES\n        confirmed \u2192 completed: YES\n        cancelled \u2192 *: NO\n        completed \u2192 *: NO\n</code></pre> <p>2.3 Domain Events Significant occurrences in the domain.</p> <pre><code>DOMAIN_EVENT: BookingCancelled\n  ATTRIBUTES:\n    booking_id: UUID\n    reason: String\n    cancelled_at: Timestamp\n    cancelled_by: UserID\n\n  CONSUMERS:\n    - Notification Service (send alert to user)\n    - Analytics Service (track cancellation reasons)\n    - Audit Log (compliance)\n</code></pre> <p>2.4 Domain Services Operations that don't naturally belong to a single Aggregate.</p> <pre><code>DOMAIN_SERVICE: BookingReservationService\n  OPERATION: create_booking(user_id, room_id, dates) \u2192 Result&lt;Booking, ReservationError&gt;\n    STEPS:\n      1. Verify user exists and is eligible\n      2. Check room availability for dates\n      3. Generate unique confirmation_code\n      4. Create Booking aggregate\n      5. Publish BookingConfirmed event\n      6. Return Booking or ReservationError\n</code></pre> <p>Validation Checklist for AI-DAA: - [ ] Every user story from PRD maps to at least one operation - [ ] All business invariants are explicitly stated - [ ] No technology-specific terms (databases, APIs, frameworks) - [ ] Aggregates have clear boundaries (no god objects) - [ ] Domain events are named in past tense - [ ] Value objects are immutable - [ ] State machines are fully specified</p>"},{"location":"artifacts/#3-tip-technical-implementation-proposal","title":"3. TIP (Technical Implementation Proposal)","text":"<p>Purpose: Engineer's initial technical proposal for simple, well-understood features (Lightweight Workflow alternative to AI-DAA).</p> <p>Generator: Engineer</p> <p>Validators: Peer engineers, architect (in design review)</p> <p>Consumers: Design team (for RFC creation)</p> <p>Key Characteristics: - Technology-specific (mentions actual databases, APIs, frameworks) - More concrete and direct than DAA - Suitable for simple features where domain modeling is overkill</p> <p>Suggested Sections:</p>"},{"location":"artifacts/#1-context","title":"1. Context","text":"<ul> <li>Link to PRD</li> <li>Brief summary of the feature</li> </ul>"},{"location":"artifacts/#2-proposed-implementation","title":"2. Proposed Implementation","text":"<p>2.1 Database Changes <pre><code>-- Example: Add notes column\nALTER TABLE bookings ADD COLUMN notes VARCHAR(200);\nCREATE INDEX idx_bookings_user_id ON bookings(user_id);\n</code></pre></p> <p>2.2 API Changes <pre><code>PUT /v1/bookings/{booking_id}/notes\nRequest:\n  {\n    \"notes\": \"Ground floor room preferred\"\n  }\nResponse:\n  200 OK\n  {\n    \"booking_id\": \"123\",\n    \"notes\": \"Ground floor room preferred\"\n  }\n</code></pre></p> <p>2.3 Service Logic - Update <code>BookingService.setNotes()</code> method - Add validation: 1-200 characters, no special characters - Audit log notes changes</p> <p>2.4 Testing - Unit tests for validation logic - Integration test for full API flow - Edge case: Set notes to existing value (idempotent)</p>"},{"location":"artifacts/#3-open-questions","title":"3. Open Questions","text":"<ul> <li>Do we need to audit-log notes changes for compliance?</li> <li>Should notes be searchable?</li> </ul>"},{"location":"artifacts/#4-effort-estimate","title":"4. Effort Estimate","text":"<ul> <li>Implementation: 4 hours</li> <li>Testing: 2 hours</li> <li>Code review: 1 hour</li> </ul> <p>When to Use TIP vs. AI-DAA:</p> Use TIP When Use AI-DAA When Feature is simple CRUD Feature has complex business rules Domain is well-understood Domain is unfamiliar Implementation is obvious Multiple approaches possible Timeline is tight High-risk or critical feature Feature touches 1-2 services Feature spans multiple bounded contexts"},{"location":"artifacts/#phase-2-artifacts-design","title":"Phase 2 Artifacts: Design","text":""},{"location":"artifacts/#4-rfc-request-for-comments","title":"4. RFC (Request for Comments)","text":"<p>Purpose: Formalize a design proposal and facilitate collaborative review.</p> <p>Generator: Engineer (assembles from DAA/TIP + own thoughts)</p> <p>Validators: Team (architects, senior engineers, domain experts)</p> <p>Consumers: Design reviewers, AI (for generating ADR)</p> <p>Key Characteristics: - Forum for discussion (not finalized) - Contains both domain understanding (DAA/TIP) and proposed technical approach - Explicitly lists open questions and constraints</p> <p>Mandatory Sections:</p>"},{"location":"artifacts/#1-metadata","title":"1. Metadata","text":"<ul> <li>RFC Number: Sequential (e.g., RFC-042)</li> <li>Title: Descriptive name</li> <li>Author: Who wrote this</li> <li>Status: Draft | Under Review | Approved | Rejected | Superseded</li> <li>Created: Date</li> <li>Last Updated: Date</li> </ul>"},{"location":"artifacts/#2-context-problem-statement","title":"2. Context &amp; Problem Statement","text":"<ul> <li>Link to PRD: Traceability to business requirements</li> <li>Problem Summary: What we're trying to solve</li> <li>Domain Model (if Full Workflow): Link to or embed AI-DAA</li> <li>Technical Context: Existing system, constraints</li> </ul>"},{"location":"artifacts/#3-proposed-solution","title":"3. Proposed Solution","text":"<ul> <li>High-Level Approach: Overall strategy</li> <li>Component Design: Services, APIs, data models</li> <li>Technology Choices: Databases, frameworks, third-party services</li> <li>Integration Points: How this fits with existing systems</li> <li>Diagrams: Architecture diagrams, sequence diagrams (use diagrams-as-code)</li> </ul>"},{"location":"artifacts/#4-alternatives-considered","title":"4. Alternatives Considered","text":"<ul> <li>Alternative 1: Approach 2, why rejected</li> <li>Alternative 2: Approach 3, why rejected</li> </ul>"},{"location":"artifacts/#5-trade-offs-risks","title":"5. Trade-offs &amp; Risks","text":"<ul> <li>Pro: Benefits of this approach</li> <li>Con: Drawbacks or limitations</li> <li>Risks: What could go wrong</li> <li>Mitigations: How to reduce risks</li> </ul>"},{"location":"artifacts/#6-open-questions","title":"6. Open Questions","text":"<ul> <li>What decisions need input from others?</li> <li>What unknowns need investigation?</li> </ul>"},{"location":"artifacts/#7-edge-cases-non-functional-considerations","title":"7. Edge Cases &amp; Non-Functional Considerations","text":"<ul> <li>Performance: How will this scale?</li> <li>Security: What are the security implications?</li> <li>Failure Modes: What happens when things go wrong?</li> <li>Monitoring: How will we observe this in production?</li> </ul> <p>RFC Evolution: 1. Draft: Initial proposal 2. Under Review: Team is discussing 3. Approved: Design is finalized \u2192 Generate AI-ADR 4. Rejected: Not moving forward 5. Superseded: Replaced by newer RFC</p>"},{"location":"artifacts/#5-ai-adr-architectural-decision-record","title":"5. AI-ADR (Architectural Decision Record)","text":"<p>Purpose: Immutable record of a finalized architectural decision. This is the executable specification for implementation.</p> <p>Generator: AI (after Collaborative Design session)</p> <p>Validators: Architect, senior engineer</p> <p>Consumers: Engineers (for implementation), AI (for code generation), Operations (for context)</p> <p>Key Characteristics: - Final and immutable (amendments create new ADRs) - Links back to DAA to show domain alignment - Contains enough detail to guide implementation - Explicitly documents trade-offs</p> <p>Mandatory Sections:</p>"},{"location":"artifacts/#1-metadata_1","title":"1. Metadata","text":"<ul> <li>ADR Number: Sequential (e.g., ADR-023)</li> <li>Title: Short, descriptive</li> <li>Status: Proposed | Accepted | Deprecated | Superseded</li> <li>Date: When finalized</li> <li>Context Links:</li> <li>PRD: [link]</li> <li>DAA: [link] (if applicable)</li> <li>RFC: [link]</li> </ul>"},{"location":"artifacts/#2-context","title":"2. Context","text":"<p>What is the problem or feature we're designing?</p> <p>Example:</p> <p>We are implementing the Booking Cancellation feature as defined in PRD-015. The AI-DAA identified the <code>Booking.cancel()</code> operation as a state transition that must preserve domain invariants (only confirmed bookings can be cancelled). We need to decide how to implement this in a way that guarantees consistency and reliable event delivery.</p>"},{"location":"artifacts/#3-decision","title":"3. Decision","text":"<p>A clear, concise statement of the chosen approach.</p> <p>Example:</p> <p>We will implement the Booking Cancellation feature as follows: 1. Use a synchronous database transaction to update booking status 2. Employ the Transactional Outbox Pattern to publish <code>BookingCancelled</code> events 3. A separate worker will relay events from the outbox to Kafka 4. The Notification Service will consume events asynchronously</p>"},{"location":"artifacts/#4-rationale","title":"4. Rationale","text":"<p>Why was this decision made? What were the constraints?</p> <p>Example:</p> <ul> <li>The DAA specifies that only confirmed bookings can be cancelled (invariant)</li> <li>We need guaranteed event delivery for compliance (NFR from PRD)</li> <li>Synchronous external calls were rejected due to failure coupling risk</li> <li>The Transactional Outbox Pattern (from Playbook entry \"OUTBOX-001\") provides atomicity between database write and event publish</li> <li>Trade-off: Slight latency in event delivery is acceptable per PRD requirements</li> </ul>"},{"location":"artifacts/#5-implementation-details","title":"5. Implementation Details","text":"<p>5.1 Technology Choices - Language: Go 1.21 - Database: PostgreSQL 15 - Message Broker: Kafka 3.5 - Framework: Standard library + custom DDD patterns</p> <p>5.2 Database Schema <pre><code>CREATE TABLE bookings (\n  booking_id UUID PRIMARY KEY,\n  user_id UUID NOT NULL,\n  status VARCHAR(20) NOT NULL CHECK (status IN ('confirmed', 'cancelled', 'completed')),\n  created_at TIMESTAMP NOT NULL,\n  updated_at TIMESTAMP NOT NULL\n);\n\nCREATE TABLE booking_outbox (\n  id BIGSERIAL PRIMARY KEY,\n  aggregate_id UUID NOT NULL,\n  event_type VARCHAR(100) NOT NULL,\n  event_payload JSONB NOT NULL,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  processed_at TIMESTAMP\n);\n</code></pre></p> <p>5.3 API Contract <pre><code>POST /v1/bookings/{booking_id}/cancel\nAuthorization: Bearer &lt;token&gt;\n\nRequest:\n{\n  \"reason\": \"Plans changed\"\n}\n\nResponse:\n200 OK\n{\n  \"booking_id\": \"a1b2c3d4\",\n  \"status\": \"cancelled\",\n  \"cancelled_at\": \"2024-01-15T10:30:00Z\"\n}\n\nErrors:\n400 Bad Request - Invalid booking state\n404 Not Found - Booking does not exist\n403 Forbidden - User does not own booking\n</code></pre></p> <p>5.4 Sequence Diagram <pre><code>sequenceDiagram\n    participant Client\n    participant API\n    participant BookingService\n    participant DB\n    participant Outbox Worker\n    participant Kafka\n\n    Client-&gt;&gt;API: POST /bookings/{id}/cancel\n    API-&gt;&gt;BookingService: cancel_booking(id, reason)\n    BookingService-&gt;&gt;DB: BEGIN TRANSACTION\n    BookingService-&gt;&gt;DB: UPDATE bookings SET status='cancelled'\n    BookingService-&gt;&gt;DB: INSERT INTO booking_outbox (BookingCancelled event)\n    BookingService-&gt;&gt;DB: COMMIT\n    BookingService--&gt;&gt;API: Success\n    API--&gt;&gt;Client: 200 OK\n\n    Outbox Worker-&gt;&gt;DB: SELECT unprocessed events\n    Outbox Worker-&gt;&gt;Kafka: Publish BookingCancelled\n    Kafka--&gt;&gt;Outbox Worker: ACK\n    Outbox Worker-&gt;&gt;DB: UPDATE processed_at</code></pre></p>"},{"location":"artifacts/#6-edge-cases-failure-handling","title":"6. Edge Cases &amp; Failure Handling","text":"<ul> <li>Idempotency: Cancelling an already-cancelled booking returns success (idempotent)</li> <li>Concurrent Cancellations: Database-level status check prevents race conditions</li> <li>Outbox Relay Failure: Worker retries up to 3 times, then moves to dead-letter queue</li> <li>Kafka Unavailable: Events accumulate in outbox, processed when Kafka recovers</li> </ul>"},{"location":"artifacts/#7-monitoring-observability","title":"7. Monitoring &amp; Observability","text":"<ul> <li>Metrics:</li> <li><code>booking_cancellation_requests_total</code> (counter)</li> <li><code>booking_cancellation_duration_seconds</code> (histogram)</li> <li><code>outbox_pending_events</code> (gauge)</li> <li>Alerts:</li> <li>Outbox size &gt; 10,000 events (indicates relay failure)</li> <li>Cancellation API error rate &gt; 1%</li> </ul>"},{"location":"artifacts/#8-rejected-alternatives","title":"8. Rejected Alternatives","text":"<p>Alternative 1: Synchronous HTTP call to Notification Service - Rejected because: Creates tight coupling; booking cancellation fails if notification service is down - Trade-off: Synchronous call would be simpler but violates availability NFR</p> <p>Alternative 2: Direct Kafka publish (without outbox) - Rejected because: No atomicity guarantee between DB write and event publish - Trade-off: Slightly less complex, but risk of data inconsistency</p>"},{"location":"artifacts/#9-references","title":"9. References","text":"<ul> <li>Playbook Entry: OUTBOX-001 (Transactional Outbox Pattern)</li> <li>PRD: PRD-015 (Booking Management Features)</li> <li>DAA: Section 3.2 (Booking Aggregate)</li> </ul> <p>ADR Lifecycle: - Proposed: Draft awaiting approval - Accepted: Approved, ready for implementation - Deprecated: No longer used but kept for historical record - Superseded: Replaced by a newer ADR (link to replacement)</p>"},{"location":"artifacts/#6-architectural-playbook","title":"6. Architectural Playbook","text":"<p>Purpose: A living library of approved architectural patterns and solutions to common cross-cutting concerns.</p> <p>Generator: Architects, senior engineers (collaboratively)</p> <p>Validators: Architecture review board</p> <p>Consumers: Engineers (during design), AI (as knowledge base for sparring)</p> <p>Key Characteristics: - Curated, vetted patterns only - Self-contained entries - Explicitly documents trade-offs</p> <p>Structure of a Playbook Entry:</p>"},{"location":"artifacts/#entry-metadata","title":"Entry Metadata","text":"<ul> <li>Pattern ID: OUTBOX-001</li> <li>Name: Transactional Outbox Pattern</li> <li>Category: Event-Driven Architecture</li> <li>Status: Active | Deprecated</li> </ul>"},{"location":"artifacts/#1-problem","title":"1. Problem","text":"<p>What recurring problem does this solve?</p> <p>Example:</p> <p>How do we guarantee atomicity between a database write and publishing an asynchronous message? Direct Kafka publishing from application code risks data inconsistency if the publish fails after the DB commit.</p>"},{"location":"artifacts/#2-context_1","title":"2. Context","text":"<p>When should this pattern be used? When should it NOT be used?</p> <p>Example:</p> <p>Use when: - You need guaranteed at-least-once event delivery - You're using a relational database - Event order matters</p> <p>Do NOT use when: - You can tolerate event loss - You need real-time streaming (&lt; 100ms latency) - You don't have transactional database support</p>"},{"location":"artifacts/#3-solution","title":"3. Solution","text":"<p>Detailed implementation guide.</p> <p>Example:</p> <ol> <li>Within the same database transaction that modifies domain data, insert an event record into an \"outbox\" table</li> <li>A separate worker process polls the outbox table for unprocessed events</li> <li>Worker publishes events to message broker (Kafka, RabbitMQ)</li> <li>Upon successful publish, worker marks the event as processed</li> </ol> <p>Reference Architecture: <pre><code>graph LR\n    Service[Domain Service] --&gt;|1. DB Transaction| DB[(Database)]\n    Service --&gt;|2. Write Event| Outbox[Outbox Table]\n    Worker[Outbox Worker] --&gt;|3. Poll| Outbox\n    Worker --&gt;|4. Publish| Kafka[Message Broker]\n    Worker --&gt;|5. Mark Processed| Outbox</code></pre></p>"},{"location":"artifacts/#4-implementation-checklist","title":"4. Implementation Checklist","text":"<p>Critical details to address:</p> <ul> <li> Outbox table has index on <code>created_at</code> and <code>processed_at</code></li> <li> Worker implements retry logic (3 attempts with exponential backoff)</li> <li> Dead-letter queue configured for poison pills</li> <li> Monitoring for outbox table size (alert if &gt; 10k events)</li> <li> Event ordering guaranteed within same aggregate_id</li> <li> Worker implements graceful shutdown (no partial processing)</li> </ul>"},{"location":"artifacts/#5-trade-offs","title":"5. Trade-offs","text":"<p>Pros: - \u2705 Guarantees at-least-once delivery - \u2705 Atomic consistency (event + data change) - \u2705 Decouples services</p> <p>Cons: - \u274c Adds implementation complexity - \u274c Introduces potential message latency (seconds) - \u274c Requires outbox table maintenance - \u274c Consumers must handle duplicate events (at-least-once semantics)</p>"},{"location":"artifacts/#6-examples","title":"6. Examples","text":"<p>Link to real ADRs or code that use this pattern.</p> <p>Example: - ADR-023: Booking Cancellation Event Publishing - ADR-031: User Profile Update Events - Reference Implementation: [github.com/example/outbox-pattern-go]</p>"},{"location":"artifacts/#7-related-patterns","title":"7. Related Patterns","text":"<ul> <li>Saga Pattern: For distributed transactions</li> <li>Event Sourcing: For complete audit trail</li> <li>CQRS: For read-optimized views</li> </ul>"},{"location":"artifacts/#phase-3-artifacts-construction-operations","title":"Phase 3 Artifacts: Construction &amp; Operations","text":""},{"location":"artifacts/#7-bolt","title":"7. Bolt","text":"<p>Purpose: A discrete, focused implementation unit with a single goal.</p> <p>Generator: Engineer (breaks down ADR into Bolts)</p> <p>Validators: Code reviewer</p> <p>Consumers: Team (for tracking progress)</p> <p>Key Characteristics: - Completable in hours or days (not weeks) - Single, clear goal - Produces testable artifact - Maps directly to part of an ADR</p> <p>Structure:</p>"},{"location":"artifacts/#bolt-metadata","title":"Bolt Metadata","text":"<ul> <li>Bolt ID: BOLT-042</li> <li>ADR: ADR-023 (Booking Cancellation Implementation)</li> <li>Goal: Implement POST /bookings/{id}/cancel API endpoint</li> <li>Assignee: Engineer name</li> <li>Status: TODO | In Progress | In Review | Done</li> <li>Estimated Effort: 6 hours</li> <li>Actual Effort: (filled after completion)</li> </ul>"},{"location":"artifacts/#acceptance-criteria","title":"Acceptance Criteria","text":"<p>From the ADR: - [ ] API endpoint returns 200 for valid requests - [ ] Status is updated to 'cancelled' in database - [ ] Event is written to outbox table - [ ] Transaction is atomic (both or neither) - [ ] Unit tests cover happy path and error cases - [ ] Integration test validates full flow</p>"},{"location":"artifacts/#implementation-notes","title":"Implementation Notes","text":"<ul> <li>Started: 2024-01-15 10:00</li> <li>Completed: 2024-01-15 16:30</li> <li>PR: #123</li> <li>Challenges: Race condition in status check, fixed with SELECT FOR UPDATE</li> </ul>"},{"location":"artifacts/#8-deployment-unit","title":"8. Deployment Unit","text":"<p>Purpose: The final, operations-ready package containing code, tests, and infrastructure configurations.</p> <p>Generator: CI/CD pipeline (from completed Bolts)</p> <p>Validators: CI/CD checks, smoke tests</p> <p>Consumers: Operations team (for deployment)</p> <p>Contents: - Application Code: Compiled binaries or container images - Tests: Unit, integration, end-to-end test suites - IaC: Terraform, Kubernetes manifests, Helm charts - Configuration: Environment-specific config files - Documentation: Deployment guide, runbook - Rollback Plan: How to safely revert</p>"},{"location":"artifacts/#9-post-mortem","title":"9. Post-mortem","text":"<p>Purpose: Document learnings from production incidents to feed back into the Knowledge Repository.</p> <p>Generator: Incident commander (with team input)</p> <p>Validators: Team, management</p> <p>Consumers: Future designers (to avoid repeating mistakes), Knowledge Repository</p> <p>Structure:</p>"},{"location":"artifacts/#1-incident-summary","title":"1. Incident Summary","text":"<ul> <li>Incident ID: INC-2024-001</li> <li>Date: 2024-01-15</li> <li>Duration: 2 hours 15 minutes</li> <li>Severity: SEV-2 (service degraded)</li> <li>Impact: 15% of booking cancellation requests failed</li> </ul>"},{"location":"artifacts/#2-timeline","title":"2. Timeline","text":"<ul> <li>10:00 - Alert: Elevated error rate on booking cancellation API</li> <li>10:05 - Incident declared, on-call engineer investigating</li> <li>10:30 - Root cause identified: Outbox table deadlock</li> <li>11:00 - Hotfix deployed: Added query timeout</li> <li>12:15 - Incident resolved, monitoring normalized</li> </ul>"},{"location":"artifacts/#3-root-cause-analysis","title":"3. Root Cause Analysis","text":"<p>The outbox worker was holding long-running transactions, causing deadlocks when the API tried to insert new events.</p> <p>Contributing Factors: - Worker batch size was too large (1000 events) - Database connection pool was under-sized - ADR-023 did not specify transaction timeout requirements</p>"},{"location":"artifacts/#4-resolution","title":"4. Resolution","text":"<ul> <li>Reduced worker batch size to 100</li> <li>Increased database connection pool</li> <li>Added 5-second query timeout to all outbox operations</li> </ul>"},{"location":"artifacts/#5-learnings-action-items","title":"5. Learnings &amp; Action Items","text":"<ul> <li> ADR Amendment: Update ADR-023 to include transaction timeout guidelines</li> <li> Playbook Update: Add \"Outbox Performance Tuning\" entry</li> <li> Monitoring: Add alert for database lock wait time</li> <li> Documentation: Update runbook with deadlock troubleshooting</li> </ul>"},{"location":"artifacts/#6-traceability","title":"6. Traceability","text":"<ul> <li>ADR: ADR-023 (Outbox Pattern Implementation)</li> <li>Bolt: BOLT-042 (Outbox Worker)</li> <li>PRD: PRD-015 (Booking Management)</li> </ul>"},{"location":"artifacts/#10-fix-it-bolt","title":"10. Fix-It Bolt","text":"<p>Purpose: A micro-sized Bolt for rapid bug fixes during production incidents.</p> <p>Generator: AI (proposes fix based on traceability chain)</p> <p>Validators: On-call engineer</p> <p>Consumers: CI/CD pipeline (for deployment)</p> <p>Structure: Same as regular Bolt, but: - Scope: Single bug fix only - Timeline: Hours, not days - Process: Expedited review (pair programming or immediate merge for hotfixes)</p> <p>Example: - Fix-It Bolt ID: FIX-001 - Related Incident: INC-2024-001 - Root Cause: Outbox worker deadlock - Fix: Reduce batch size from 1000 to 100, add query timeout - Estimated Risk: Low (reduces load, improves performance) - Rollback Plan: Revert to previous worker configuration</p>"},{"location":"artifacts/#artifact-relationships","title":"Artifact Relationships","text":"<pre><code>graph TD\n    PRD[PRD] --&gt; DAA[AI-DAA]\n    PRD --&gt; TIP[TIP]\n    DAA --&gt; RFC[RFC]\n    TIP --&gt; RFC\n    Playbook[Architectural Playbook] -.references.-&gt; RFC\n    RFC --&gt; ADR[AI-ADR]\n    ADR --&gt; Bolt1[Bolt 1]\n    ADR --&gt; Bolt2[Bolt 2]\n    Bolt1 --&gt; Deployment[Deployment Unit]\n    Bolt2 --&gt; Deployment\n    Deployment --&gt; Incident[Production Incident]\n    Incident --&gt; Postmortem[Post-mortem]\n    Incident --&gt; FixIt[Fix-It Bolt]\n    Postmortem -.feeds back.-&gt; Playbook\n    FixIt --&gt; ADR</code></pre>"},{"location":"artifacts/#validation-matrix","title":"Validation Matrix","text":"Artifact Validator Validation Method Acceptance Criteria PRD Product Manager Stakeholder review Clear user stories, measurable success metrics AI-DAA Domain Expert / Architect Domain accuracy review All PRD stories mapped, invariants explicit TIP Engineer / Architect Feasibility review Addresses all PRD requirements, realistic estimate RFC Architecture Team Design review Trade-offs documented, alternatives considered AI-ADR Architect Final approval Aligned with DAA, implementable, risks mitigated Bolt Code Reviewer PR review Meets acceptance criteria, tests pass Post-mortem Team Retrospective Root cause identified, action items defined <p>Next: Workflow - Step-by-step process for using these artifacts</p>"},{"location":"core/","title":"The AirSDLC: An Actionable Framework for AI-Driven Development","text":"<p>Note: This is the comprehensive, single-document reference for the AirSDLC framework. For easier navigation, the content has been split into focused chapters: - Overview - Introduction and key concepts - Philosophy - Core principles and AI-DLC foundation - Lifecycle - The three phases explained - Artifacts - DAA, ADR, TIP, RFC specifications - Workflow - Step-by-step process and rituals - Operations - Post-deployment and incident handling - Extensibility - How to adapt and extend - Examples - Sample artifacts and use cases</p>"},{"location":"core/#introduction-philosophy","title":"Introduction &amp; Philosophy","text":""},{"location":"core/#my-journey","title":"My Journey","text":"<p>This document formalizes a series of successful experiments in applying a structured, AI-driven lifecycle to real-world software projects. Starting with the theoretical concepts of the AI-Driven Development Lifecycle (AI-DLC), I developed a practical workflow that demonstrated remarkable success in bridging the gap between ambiguous business requirements and production-ready architectural decisions. This framework, the \"AI-Responsible Software Development Lifecycle\" (AirSDLC), is the codification of that proven process.</p>"},{"location":"core/#core-principle","title":"Core Principle","text":"<p>AirSDLC is built on the core AI-DLC paradigm: AI-Driven Execution with Human Oversight.</p> <p>In this model, the AI is not merely an assistant or a code-completion tool. It is a central collaborator that generates plans, models domains, and proposes solutions. The human expert's role is elevated from a generator of artifacts to a validator, curator, and strategic decision-maker. Our primary cognitive load is shifted from creation to evaluation\u2014a much higher-leverage activity.</p>"},{"location":"core/#the-goal","title":"The Goal","text":"<p>The goal of AirSDLC is to provide a practical, repeatable methodology that creates a fully traceable, high-fidelity chain from initial business intent to a final, actionable architectural decision record.</p>"},{"location":"core/#core-ai-dlc-principles-the-foundation-of-airsdlc","title":"Core AI-DLC Principles: The Foundation of AirSDLC","text":"<p>The AirSDLC is a practical and actionable implementation of the theoretical AI-DLC framework. To ensure our design remains grounded in its foundational principles, this section summarizes the core concepts derived from the AI-DLC source documents. The <code>airsdlc</code> crate and its associated tools must adhere to these principles.</p>"},{"location":"core/#analysis-of-the-core-ai-dlc-framework","title":"Analysis of the Core AI-DLC Framework","text":"<p>Based on the provided notebooks, the AI-DLC is a complete, AI-native software development methodology designed to replace traditional SDLCs like Agile. Its philosophy is AI-Driven, with Human-in-the-Loop Governance. The AI is not an assistant; it is the primary executor, while humans are the validators and decision-makers.</p>"},{"location":"core/#1-the-three-sequential-phases","title":"1. The Three Sequential Phases","text":"<p>The framework is built on a \"sequential knowledge handoff\" across three distinct phases. Each phase's validated output becomes the non-negotiable input for the next.</p> <ol> <li>Inception: The \"WHAT and WHY\" phase. Translates an initial <code>Business Intent</code> into a locked, buildable contract.</li> <li>Construction: The \"HOW\" phase. Transforms the contract from Inception into tested, deployable software artifacts.</li> <li>Operation: The \"MAINTAIN\" phase. Deploys, monitors, and fixes the software in production, using the full context from the previous phases.</li> </ol>"},{"location":"core/#2-the-core-artifacts-the-nouns-of-the-framework","title":"2. The Core Artifacts (The \"Nouns\" of the Framework)","text":"<p>These are the key data structures that flow through the lifecycle.</p> <ul> <li> <p>Unit of Work (UOW): The primary container for a major piece of functionality, replacing the \"Epic.\" It is the main output of the Inception phase.</p> <ul> <li>Core Composition: Every UOW must contain five \"problem-defining\" artifacts:<ol> <li>PR/FAQ</li> <li>User Stories</li> <li>Non-Functional Requirements (NFRs)</li> <li>Risk Descriptions</li> <li>Measurement Criteria</li> </ol> </li> <li>Extensibility: The framework explicitly allows for custom artifacts (e.g., Sequence Diagrams, Domain Models) to be added to a UOW, but the five above are the mandatory core.</li> </ul> </li> <li> <p>Bolt: A \"single workable-unit that only has a single goal,\" replacing the \"Sprint.\" Bolts are the sequential, tactical steps to build a UOW, measured in hours or days.</p> <ul> <li>Core Composition: Bolts produce \"solution-defining\" artifacts:<ol> <li>Validated Logical Design &amp; Architecture Decision Records (ADRs)</li> <li>Generated Code &amp; Comprehensive Test Suite</li> <li>Deployment Unit</li> </ol> </li> </ul> </li> <li> <p>Deployment Unit: The final, \"operations-ready\" package from the Construction phase, containing code, tests, and IaC configurations.</p> </li> <li> <p>Fix-It Bolt: A special, micro-sized Bolt generated by the AI for bug fixing during the Operation phase. It follows a structured process of RCA, proposal, validation, and execution.</p> </li> </ul>"},{"location":"core/#3-the-core-rituals-the-verbs-of-the-framework","title":"3. The Core Rituals (The \"Verbs\" of the Framework)","text":"<p>These are the mandatory, synchronous \"Mob\" collaborations that serve as the human-in-the-loop validation gates.</p> <ol> <li> <p>Mob Elaboration (Inception): A cross-functional team convenes to review, refine, and ultimately grant \"human validation\" on the AI-generated draft UOW. The output is a \"Validated Unit of Work.\"</p> </li> <li> <p>Mob Construction (Construction): A technical team convenes to review and validate the AI's proposed architecture and ADRs for a specific Bolt before any code is generated. The output is a \"Validated Logical Design &amp; ADRs.\"</p> </li> <li> <p>Continuous Oversight (Operation): An ongoing series of expedited validation rituals where the human mob provides the final \"go/no-go\" decision on any AI-proposed action that would change the production environment (e.g., deploying a new <code>Deployment Unit</code> or a <code>Fix-It Bolt</code>).</p> </li> </ol>"},{"location":"core/#4-the-foundational-interaction-loop","title":"4. The Foundational Interaction Loop","text":"<p>Underpinning everything is a repeating, four-stage cycle that defines the human-AI partnership:</p> <ol> <li>[AI] Propose &amp; Decompose: The AI analyzes an input and creates a detailed plan/artifact.</li> <li>[AI -&gt; Human] Clarify &amp; Question: The AI actively seeks context and defers critical decisions.</li> <li>[Human] Validate &amp; Direct: The \"Mob\" provides judgment, makes decisions, and gives approval.</li> <li>[AI] Implement &amp; Update: Only after validation, the AI executes the plan and generates the final artifacts.</li> </ol>"},{"location":"core/#the-airsdlc-as-an-extensible-framework","title":"The AirSDLC as an Extensible Framework","text":"<p>While this document describes a specific, opinionated workflow for software development, the <code>AirSDLC</code> itself is designed as an abstract, extensible framework. It is a specification for a workflow engine that can be implemented by higher-level tools and extended by engineers to fit their specific needs.</p> <p>Any tool that implements this framework must adhere to its core concepts and state machine, ensuring a consistent and predictable process.</p>"},{"location":"core/#core-abstract-concepts","title":"Core Abstract Concepts","text":"<p>An <code>AirSDLC</code> implementation is built on four fundamental concepts:</p> <ul> <li><code>Phase</code>: A distinct stage of the lifecycle with a clear objective (e.g., Inception, Design).</li> <li><code>Artifact</code>: A structured data object that serves as the input or output of a <code>Phase</code> (e.g., <code>AI-DAA</code>, <code>AI-ADR</code>). Each artifact has a defined schema.</li> <li><code>State</code>: The status of an <code>Artifact</code> within the workflow (e.g., <code>draft</code>, <code>review</code>, <code>validated</code>, <code>finalized</code>).</li> <li><code>Transition</code>: An action that changes the <code>State</code> of an <code>Artifact</code>, moving it from one <code>Phase</code> to the next.</li> </ul>"},{"location":"core/#the-workflow-as-a-state-machine","title":"The Workflow as a State Machine","text":"<p>At its core, the <code>AirSDLC</code> is a state machine that operates on <code>Artifacts</code>. A workflow engine is responsible for managing the state of these artifacts and executing the transitions between them.</p> <pre><code>graph TD\n    subgraph \"Phase: Inception\"\n        A[Artifact: DAA &lt;br/&gt; State: draft] --&gt; B{Validate DAA};\n        B -- Approved --&gt; C[Artifact: DAA &lt;br/&gt; State: validated];\n    end\n    subgraph \"Phase: Design\"\n        C --&gt; D[Artifact: ADR &lt;br/&gt; State: draft];\n        D --&gt; E{Validate ADR};\n        E -- Approved --&gt; F[Artifact: ADR &lt;br/&gt; State: finalized];\n    end</code></pre>"},{"location":"core/#extension-points","title":"Extension Points","text":"<p>The framework is designed to be extensible. A compliant workflow engine should provide mechanisms for users to add custom functionality through well-defined \"extension points\":</p> <ol> <li>Custom Artifacts: Engineers can define their own <code>Artifact</code> types with custom schemas. For example, a team could introduce a <code>SecurityReview</code> artifact required before the <code>Construction</code> phase.</li> <li>Custom Templates: The generation of any <code>Artifact</code> should be driven by a template. The engine should allow users to override default templates or register new ones for their custom artifacts. This allows for tailoring the output to specific team standards or languages.</li> <li>Lifecycle Hooks: The engine should expose hooks at critical points in the state machine (e.g., <code>pre-validation</code>, <code>post-transition</code>). Plugins can listen for these hooks to inject custom logic, such as sending a notification to Slack, running a compliance check, or archiving an artifact.</li> </ol> <p>By adhering to this abstract framework, implementation tools can provide a robust and predictable core experience while still offering the flexibility for teams to adapt the process to their unique requirements. The remainder of this document describes the default, reference implementation of this framework.</p>"},{"location":"core/#the-airsdlc-lifecycle-an-overview","title":"The AirSDLC Lifecycle: An Overview","text":"<p>The AirSDLC is a sequential knowledge handoff, where each phase enriches the context for the next, ensuring that technical decisions are always grounded in the business domain.</p> <pre><code>graph TD\n    A[Business Intent] --&gt; B(Phase 1: Inception);\n    B --&gt; C[Artifact: AI-DAA];\n    C --&gt; D(Phase 2: Collaborative Design);\n    D --&gt; E[Artifact: AI-ADR];\n    E --&gt; F(Phase 3: Construction);</code></pre>"},{"location":"core/#phase-1-inception-the-what","title":"Phase 1: Inception (The \"What\")","text":"<p>The objective of this phase is to translate an ambiguous business goal into a pure, technology-agnostic, and validated model of the business domain.</p>"},{"location":"core/#phase-2-collaborative-design-the-how","title":"Phase 2: Collaborative Design (The \"How\")","text":"<p>This phase is a human-AI collaborative ritual designed to synthesize the \"what\" from the Inception phase with the \"how\" of a technical implementation, resulting in a robust architectural decision.</p>"},{"location":"core/#phase-3-construction-operation","title":"Phase 3: Construction &amp; Operation","text":"<p>This phase uses the final architectural decision to generate, test, and deploy the code, and then provides context-aware monitoring in production.</p>"},{"location":"core/#the-knowledge-repository-the-single-source-of-truth","title":"The Knowledge Repository: The Single Source of Truth","text":"<p>The primary output of the AirSDLC is not just code, but a living, interconnected Knowledge Repository. This repository serves as the \"single source of truth\" for the entire system, documenting the full lifecycle of every feature from business intent to technical implementation.</p> <p>It is the central \"brain\" that enables end-to-end traceability, facilitates AI-driven analysis and code generation, and provides the foundational context for the AI-augmented on-call process described in the operational playbook.</p>"},{"location":"core/#the-virtuous-cycle-of-knowledge","title":"The Virtuous Cycle of Knowledge","text":"<p>The following diagram illustrates the central role of the Knowledge Repository. The AirSDLC development workflow continuously writes to and enriches the repository. In contrast, the operational workflows (like on-call incident response) primarily read from the repository to gain context and accelerate resolution. This creates a virtuous cycle where design decisions inform operations, and operational learnings (as Post-mortems) are fed back into the repository to inform future design.</p> <pre><code>graph LR\n    subgraph \"Writes to Repository\"\n        direction TB\n        Dev(AirSDLC Development)\n    end\n\n    subgraph \"Reads from Repository\"\n        direction TB\n        Ops(On-Call Incident Response)\n    end\n\n    subgraph \"Knowledge Repository\"\n        direction TB\n        Repo(fa:fa-database Single Source of Truth)\n        Repo -- Contains --&gt; Artifacts[PRDs, DAAs, ADRs, Code, Playbooks, Post-mortems]\n    end\n\n    Dev -- Creates &amp; Enriches --&gt; Repo;\n    Ops -- Reads &amp; Correlates --&gt; Repo;\n    Ops -- Creates --&gt; Postmortem((Post-mortem));\n    Postmortem -- Feeds Back Into --&gt; Repo;</code></pre>"},{"location":"core/#core-components","title":"Core Components","text":"<p>The repository contains all artifacts generated by the AirSDLC and subsequent operations:</p> <ul> <li>Product Requirements Documents (PRDs): The \"why\" from a business perspective.</li> <li>Domain Architecture Analyses (AI-DAAs): The \"what\" of the business logic.</li> <li>Requests for Comments (RFCs): The forum for collaborative design.</li> <li>Architectural Decision Records (AI-ADRs): The \"how\" of the technical implementation.</li> <li>Architectural Playbooks: The library of standard solutions to common problems.</li> <li>Bolts / Bolt Execution Logs: A record of all implemented features and their corresponding code commits.</li> <li>Post-mortems: A searchable library of past incidents and their resolutions, closing the loop from operations back to design.</li> </ul>"},{"location":"core/#the-core-airsdlc-workflow-a-step-by-step-guide","title":"The Core AirSDLC Workflow: A Step-by-Step Guide","text":"<p>This section provides a detailed, prescriptive guide for how to apply the AirSDLC framework, connecting the core artifacts into a cohesive, actionable workflow.</p>"},{"location":"core/#the-workflow-diagram","title":"The Workflow Diagram","text":"<pre><code>graph TD\n    subgraph \"Phase 1: Inception\"\n        A[Start: New Business Intent/PRD] --&gt; B{Complex or High-Risk Feature?};\n        B -- Yes --&gt; C[Full Workflow: Generate AI-DAA];\n        B -- No --&gt; D[Lightweight Workflow: Engineer writes TIP];\n        C --&gt; E[Validated DAA];\n        D --&gt; F[Draft TIP];\n    end\n\n    subgraph \"Phase 2: Collaborative Design\"\n        E --&gt; G(Input: DAA + Engineer's RFC);\n        F --&gt; G;\n        G --&gt; H[Start Collaborative Discussion];\n        H --&gt; I{Consult Architectural Playbook};\n        I --&gt; J[Engage AI as Socratic Sparring Partner];\n        J --&gt; K[Challenge, Visualize, and Refine Design];\n        K --&gt; L[Finalize Design];\n    end\n\n    subgraph \"Phase 3: Finalization &amp; Construction\"\n        L --&gt; M[Generate Final AI-ADR];\n        M --&gt; N[Execute Bolts: Generate Code from ADR];\n        N --&gt; O((End: Production-Ready Code));\n    end</code></pre>"},{"location":"core/#step-by-step-explanation","title":"Step-by-Step Explanation","text":"<p>Step 1: The Fork - Choose the Right Path The workflow begins with a critical decision point based on the principles of Pragmatism &amp; Adaptability (see the \"Pragmatism &amp; Adaptability\" section below). - Input: A new Business Intent or Product Requirements Document (PRD). - Action: The lead engineer or architect assesses the feature's context. Using the Decision Matrix described in the \"Pragmatism &amp; Adaptability\" section, they determine the appropriate level of upfront modeling required. - Path A (Full Workflow): For complex, high-risk, or unfamiliar domains, the process starts with generating a formal AI-DAA. This investment is crucial to de-risk the project. - Path B (Lightweight Workflow): For simpler, well-understood features, the engineer reads the PRD and writes a TIP (Technical Implementation Proposal). This is a more direct, less abstract document focusing on concrete implementation details like database schemas and API endpoints.</p> <p>Step 2: The Merge - Prepare for Collaborative Design The outputs of the Inception phase, whether a DAA or a TIP, are prepared as the primary input for the design discussion. - Action: The engineer assembles a draft RFC (Request for Comments) document. This document contains the DAA or TIP, along with any initial technical ideas, constraints, or questions the engineer has.</p> <p>Step 3: The Ritual - The Collaborative Discussion This is the core \"Mob Construction\" ritual where the human architect and the AI collaborate to produce a robust design. - Action: The architect initiates a session with the AI, providing the draft RFC as context. - Consult the Playbook: The architect identifies the key architectural challenges (e.g., data consistency, service communication) and consults the Architectural Playbook (described under \"The Core Artifacts of AirSDLC\") for established patterns and solutions. - Engage the Sparring Partner: The architect prompts the AI to act as a \"Socratic Sparring Partner.\" Using the patterns from the Playbook, the architect directs the AI to challenge the design, propose alternatives, and analyze trade-offs. This is an iterative loop of questioning, generating diagrams-as-code to clarify thinking, and refining the design until it is robust and well-vetted.</p> <p>Step 4: The Record - Generate the Final AI-ADR Once the design is stable and all major risks have been addressed, the decisions are codified. - Action: The architect prompts the AI to generate the final AI-ADR (Architectural Decision Record). This document is the immutable source of truth for the implementation, capturing the final architecture, the rationale behind the decisions, and the trade-offs that were accepted.</p> <p>Step 5: The Build - Execute \"Bolts\" The ADR is now an executable specification. - Action: The project is broken down into \"Bolts\" (as defined in the \"Integrating AI-DLC Rituals\" section), where each Bolt represents a discrete piece of the ADR (e.g., \"implement the <code>cancel_booking</code> endpoint\"). The engineer prompts the AI to generate the boilerplate code, tests, and configurations for one Bolt at a time, focusing their own energy on implementing the core, complex business logic.</p>"},{"location":"core/#the-core-artifacts-of-airsdlc","title":"The Core Artifacts of AirSDLC","text":""},{"location":"core/#the-ai-daa-domain-architecture-analysis","title":"The AI-DAA (Domain Architecture Analysis)","text":"<p>The AI-DAA is the cornerstone of the AirSDLC's \"Full Workflow.\" It is a strictly technology- and vendor-agnostic blueprint of the business domain. Generated by the AI from the structured PRD, it is a 100% pure pseudo-abstraction of the business logic. It contains no specific technical solutions: no databases, no frameworks, and no programming languages. Its primary purpose is to ensure a deep, shared understanding of the problem space before any technical solutions are considered. A single, well-formed DAA can be implemented in any number of ways\u2014for example, as a Python-based monolith or as a set of Golang-based microservices.</p>"},{"location":"core/#why-domain-driven-design-ddd","title":"Why Domain-Driven Design (DDD)?","text":"<p>The AirSDLC adopts DDD as its foundational modeling methodology for several key reasons: - Focus on Business Domain: DDD places the primary focus on the core business logic. It provides a set of tools for tackling complexity in the heart of the software. - Shared Understanding (Ubiquitous Language): DDD insists on a common, rigorous language shared between domain experts, product managers, and developers. This \"Ubiquitous Language\" reduces ambiguity and ensures everyone is talking about the same concepts. - Strategic Boundaries: DDD provides patterns (like Bounded Contexts and Context Maps) to strategically break down a large, complex system into smaller, more manageable, and loosely coupled parts. This is essential for building scalable and maintainable software. - AI-Friendliness: The structured and explicit nature of DDD artifacts (Aggregates, Entities, Value Objects, Domain Events) makes it an ideal methodology for an AI to work with. The AI can be trained to identify and generate these patterns from a well-structured PRD.</p>"},{"location":"core/#the-daa-generation-process","title":"The DAA Generation Process","text":"<p>The AI-DAA is the result of a systematic mapping process, executed by the AI, that translates product goals into DDD patterns.</p> <pre><code>graph TD\n    A[Product Goals &amp; User Stories in PRD] --&gt; B{AI Analysis: Identify Verbs &amp; Nouns};\n    B --&gt; C[Map Nouns to Potential Entities/Aggregates];\n    B --&gt; D[Map Verbs to Potential Operations/Domain Events];\n    C &amp; D --&gt; E{AI Strategic Analysis: Group related concepts};\n    E --&gt; F[Propose Bounded Contexts];\n    F --&gt; G[Define Context Map];\n    E --&gt; H[Propose Aggregates &amp; Value Objects];\n    H --&gt; I[Define Aggregate Operations &amp; Invariants];\n    I --&gt; J[Define Domain Events];\n    subgraph \"Strategic Design\"\n        F &amp; G\n    end\n    subgraph \"Tactical Design\"\n        H &amp; I &amp; J\n    end\n    J --&gt; K[Output: Full AI-DAA Document];</code></pre> <ol> <li>Analysis of the PRD: The AI first parses the structured PRD, identifying the key \"nouns\" (e.g., \"Booking,\" \"Room,\" \"User,\" \"Reservation\") and \"verbs\" (e.g., \"reserve,\" \"cancel,\" \"confirm,\" \"check-in\").</li> <li>Strategic Design (The Big Picture): The AI groups related concepts to propose logical boundaries (<code>Bounded Contexts</code>) and defines the relationships between them (<code>Context Map</code>).</li> <li>Tactical Design (The Details): Within each context, the AI applies tactical DDD patterns, identifying <code>Aggregates</code>, <code>Entities</code>, <code>Value Objects</code>, and modeling the \"verbs\" as <code>Operations</code> with <code>Invariants</code> and <code>Domain Events</code>.</li> </ol>"},{"location":"core/#the-daa-as-an-executable-specification","title":"The DAA as an Executable Specification","text":"<p>The final AI-DAA document, with its detailed pseudocode, serves as a precise, executable specification for the business logic. Because it is 100% technology-agnostic, it is structurally rigorous but maximally flexible, making it the perfect input for the next phase where concrete technical decisions will be applied.</p> <p>Example Snippet: An Aggregate from a DAA <pre><code>AGGREGATE: Booking\n  AGGREGATE_ROOT: Booking\n    IDENTITY: booking_id (UUID)\n\n    ATTRIBUTES:\n      user_id: UserID\n      room_id: RoomID\n      status: BookingStatus (value object)\n      time_slot: TimeSlot (value object, with start_time and end_time)\n\n    INVARIANTS:\n      - Booking status must follow valid state machine transitions.\n      - Only confirmed bookings can be cancelled.\n      - A room cannot have overlapping bookings for the same time slot.\n      - Completed bookings are terminal.\n\n    OPERATIONS:\n      cancel(reason: String) \u2192 BookingCancelled\n        PRECONDITION: status = confirmed\n        POSTCONDITION: status = cancelled\n        DOMAIN_EVENT: BookingCancelled\n</code></pre></p>"},{"location":"core/#the-architectural-playbook","title":"The Architectural Playbook","text":"<p>The Architectural Playbook is a living document that serves as the codified architectural wisdom of an engineering organization. It is a curated library of approved solutions to common, recurring cross-cutting concerns. Its primary purpose is to empower the AI to be a more effective \"Socratic Sparring Partner\" during the Collaborative Design phase.</p> <ul> <li> <p>Purpose: To ensure consistency, share knowledge, and accelerate design by providing a set of vetted, reusable patterns. It is the \"how\" to the \"what\" of a high-level technical strategy.</p> </li> <li> <p>Structure of a Playbook Entry: Each pattern in the playbook should be a self-contained guide with a clear, consistent structure:</p> <ul> <li>Pattern: A descriptive name (e.g., \"Transactional Outbox Pattern,\" \"Idempotent API Endpoint Design\").</li> <li>Problem: A clear description of the recurring problem this pattern solves (e.g., \"How to guarantee atomicity between a database write and an asynchronous message publish?\").</li> <li>Context: When is this pattern applicable? What are the prerequisites? When should it not be used?</li> <li>Solution: A detailed description of the implementation, often including diagrams-as-code.</li> <li>Checklist for Edge Cases: A list of critical details to consider during implementation (e.g., \"How will the message relay handle poison pills? What monitoring is required for the outbox table size?\").</li> <li>Trade-offs: An honest assessment of the pros (e.g., \"Guarantees at-least-once delivery\") and cons (e.g., \"Increases implementation complexity, introduces potential for message latency\").</li> </ul> </li> <li> <p>Benefits:</p> <ul> <li>Consistency: Ensures all teams solve common problems in the same, approved way.</li> <li>Knowledge Sharing: Captures senior engineering expertise in a format that is accessible to all, including the AI.</li> <li>Empowers the AI: Provides a high-quality, curated knowledge base that the AI can use to challenge designs and suggest well-vetted alternatives, significantly improving the quality of the human-AI collaboration.</li> </ul> </li> </ul>"},{"location":"core/#tip-vs-rfc-from-proposal-to-peer-review","title":"TIP vs. RFC: From Proposal to Peer Review","text":"<p>A TIP (Technical Implementation Proposal) is the engineer's initial, self-generated proposal for how to build a feature. It is the starting point for the Lightweight Workflow. An RFC (Request for Comments) is the formal document used for collaborative review and refinement; it is the forum for the design discussion.</p> <p>A TIP is often the seed that grows into an RFC.</p> Aspect TIP (Technical Implementation Proposal) RFC (Request for Comments) Author A single engineer. Collaborative. Starts with a TIP or DAA, then refined by the team. Purpose To be an engineer's first-pass design draft; their initial thoughts on \"how.\" To solicit feedback and drive discussion toward a final, approved design. Scope Represents one perspective. Often a \"brain dump\" of schema, APIs, etc. A more formal document that incorporates wider architectural constraints (ADRs). Analogy An engineer's detailed personal notes or a draft proposal. The official document circulated for peer review. Workflow Step An input to the design process. The forum for the design process."},{"location":"core/#example-use-case-the-journey-of-a-feature","title":"Example Use Case: The Journey of a Feature","text":"<p>Let's trace a simple \"Booking Notes\" feature in the Lightweight Workflow.</p> <ol> <li> <p>The PRD: A new PRD arrives: \"As a user, I want to add notes to my booking so I can remember special requests.\"</p> </li> <li> <p>The Engineer's TIP: The engineer decides this is a simple feature and creates a <code>TIP</code> to structure their thoughts.</p> <ul> <li><code>add_booking_notes_tip.md</code> (Excerpt):     &gt; DB Change: Add a <code>notes TEXT</code> column to the <code>bookings</code> table.     &gt; API Endpoint: <code>PUT /v1/bookings/{booking_id}/notes</code>     &gt; Validation: Notes must be 0-500 characters.     &gt; Question: Do we need to audit-log notes changes?</li> </ul> </li> <li> <p>The Draft RFC: The engineer formalizes this by creating <code>RFC-002_Booking_Notes.md</code>. They copy the TIP into the \"Proposed Implementation\" section and add the other standard RFC sections. The \"Open Questions\" section now includes the auditing question.</p> </li> <li> <p>The Collaborative Review (RFC stage): The RFC is shared with the team and the AI.</p> <ul> <li>A teammate comments: \"Good point on auditing. Given our compliance rules, we should add an <code>audit_events</code> table.\"</li> <li>The architect prompts the AI: \"Review this RFC. Does the proposed <code>PUT</code> endpoint align with our API standards in the Playbook?\"</li> <li>The AI responds: \"Our Playbook prefers <code>PATCH</code> for partial updates to align with JSON Patch standards (RFC 6902). Consider changing to <code>PATCH /v1/bookings/{booking_id}</code>.\"</li> </ul> </li> <li> <p>The Final RFC &amp; ADR: The engineer updates the RFC with the feedback. This refined design is approved, and the key decisions are recorded in a new <code>AI-ADR</code>. The feature is now ready for construction.</p> </li> </ol>"},{"location":"core/#the-ai-adr-architectural-decision-record","title":"The AI-ADR (Architectural Decision Record)","text":"<p>The AI-ADR is the final, immutable output of the Collaborative Design phase. It is more than just a document; it is the executable specification for the technical implementation. Generated by the AI after the \"Socratic Sparring\" session is complete, it represents the consensus reached between the engineer's proposal, the AI's challenges, and the guidance from the Architectural Playbook.</p>"},{"location":"core/#purpose-and-value","title":"Purpose and Value","text":"<ul> <li>Clarity and Alignment: It provides a single source of truth for the development team on how a system should be built, eliminating ambiguity before implementation begins.</li> <li>Traceability: Crucially, it links the chosen technical solution directly back to the business requirements in the DAA. Each decision should be justifiable in the context of the domain model.</li> <li>Onboarding and Knowledge Sharing: ADRs serve as a historical record of the project's architectural evolution. New team members can read them to quickly understand not just what was built, but why it was built that way.</li> <li>Input for Construction: The AI-ADR is the direct input for the AI during the Construction phase. Its structured nature allows the AI to generate code, tests, and infrastructure configurations with high fidelity.</li> </ul>"},{"location":"core/#structure-of-an-ai-adr","title":"Structure of an AI-ADR","text":"<p>An AI-ADR should be a clear, structured document. The AI can be prompted to generate it using a standard template:</p> <ul> <li>Title: A descriptive name for the decision (e.g., \"ADR-003: Asynchronous Event-Driven Communication for User Notifications\").</li> <li>Status: Proposed, Accepted, Deprecated.</li> <li>Context: What is the problem or feature we are designing? (This section should link directly to the relevant parts of the DAA or PRD).</li> <li>Decision: A clear and concise statement of the chosen architectural approach.<ul> <li>Example: \"We will implement a Transactional Outbox Pattern to ensure reliable, at-least-once delivery of <code>BookingConfirmed</code> events to a Kafka topic. The <code>Notification</code> service will be the consumer.\"</li> </ul> </li> <li>Rationale &amp; Trade-offs: This is the most important section. It explains why this decision was made and what alternatives were considered.<ul> <li>Example: \"A synchronous API call was considered but rejected due to the risk of tight coupling and cascading failures (as identified in the Collaborative Discussion). While the Outbox pattern adds implementation complexity, the requirement for guaranteed notification delivery outweighs this cost. The trade-off of potential message latency is acceptable for this use case.\"</li> </ul> </li> <li>Implementation Details: High-level details for the construction phase, such as database schema changes, API contracts, or diagrams-as-code illustrating the final flow.</li> </ul>"},{"location":"core/#the-adr-as-an-executable-spec","title":"The ADR as an \"Executable Spec\"","text":"<p>The AI-ADR is not just documentation that gets filed away. Because it is so structured and detailed, it becomes the direct specification for the AI in the next phase. The engineer can take a specific part of the ADR (like an API contract) and prompt the AI: \"Based on this ADR, generate the Go boilerplate for this API handler.\" This makes the ADR a living, executable artifact that directly guides code generation.</p>"},{"location":"core/#pragmatism-adaptability","title":"Pragmatism &amp; Adaptability","text":"<p>The AirSDLC is not a rigid, one-size-fits-all process. The level of ceremony should match the complexity and risk of the feature being built. The goal is to invest time where it yields the highest return in clarity and quality.</p>"},{"location":"core/#the-hybrid-model-smart-selectivity","title":"The Hybrid Model: Smart Selectivity","text":"<p>Based on the context (feature complexity, team maturity, timeline), choose the appropriate workflow:</p> <ul> <li>For Simple/Well-Understood Features: A Lightweight Workflow is often sufficient. The engineer reads the PRD and writes a TIP (Technical Implementation Proposal) directly. The formal DAA is skipped, but the process is still structured.</li> <li>For Complex/Unfamiliar Features: The Full Workflow (including the AI-DAA) is recommended to de-risk the project and ensure a deep domain understanding.</li> <li>For Critical/High-Risk Features: The Full Workflow is essential. The upfront investment in domain modeling and risk analysis prevents costly errors downstream.</li> </ul>"},{"location":"core/#the-decision-matrix","title":"The Decision Matrix","text":"<p>Use a simple matrix to decide which path to take:</p> Context Recommended Approach Feature Complexity: Simple CRUD Lightweight (PRD \u2192 TIP \u2192 RFC) Feature Complexity: Complex Business Logic Full (PRD \u2192 DAA \u2192 RFC) Team Maturity: Senior Engineers Lightweight Team Maturity: Junior Engineers Full (to teach structured thinking) Timeline: Urgent Lightweight Timeline: Strategic/Long-Term Full"},{"location":"core/#the-principle-of-validation","title":"The Principle of Validation","text":"<p>While the level of upfront design can be adapted, validation should never be skipped. AI-driven validation is a high-leverage, low-cost safety net that should be applied in all workflow variants.</p> <ul> <li>RFC-to-PRD Coverage: Even in a lightweight workflow, use the AI to generate a \"Coverage Report\" that compares the engineer's TIP/RFC against the original PRD. This catches misunderstandings before a line of code is written.</li> <li>Code-to-RFC Compliance: After implementation, use the AI to generate a \"Compliance Report\" that verifies the final code adheres to the decisions in the ADR.</li> </ul> <p>This validation-first approach ensures that even when moving fast, we are still building the right thing correctly.</p>"},{"location":"core/#the-payoff-end-to-end-traceability","title":"The Payoff: End-to-End Traceability","text":"<p>A key benefit of the AirSDLC is the creation of a fully traceable chain of artifacts. This allows for unprecedented \"coverage metrics,\" providing clear insight into complexity, effort, and the direct link between business goals and technical strategy.</p> <p>Traceability Chain: <code>Business Goal \u2192 AI-PRD Feature \u2192 AI-DAA Aggregate/Operation \u2192 AI-ADR Technology Choice \u2192 Implementation Effort</code></p> <p>This chain is not just documentation; it is a machine-readable graph of the entire project. This opens up the possibility of automated metrics and reporting, allowing for real-time analysis of project complexity and progress.</p>"},{"location":"core/#integrating-ai-dlc-rituals-into-the-airsdlc-workflow","title":"Integrating AI-DLC Rituals into the AirSDLC Workflow","text":"<p>The AirSDLC is a practical implementation of the theoretical AI-DLC framework. This section describes how the core AI-DLC rituals and concepts are integrated into the day-to-day AirSDLC workflow.</p>"},{"location":"core/#the-unit-of-work-as-a-validated-daa","title":"The \"Unit of Work\" as a Validated DAA","text":"<p>In formal AI-DLC, the <code>Unit of Work (UoW)</code> is the primary, validated output of the Inception phase. In AirSDLC, this is concretely represented by the Validated AI-DAA (and its source AI-PRD). The DAA serves as the immutable technical contract and single source of truth for what needs to be built, perfectly fulfilling the role of the UoW.</p>"},{"location":"core/#the-mob-elaboration-ritual","title":"The \"Mob Elaboration\" Ritual","text":"<ul> <li>AI-DLC Theory: A \"mob\" of stakeholders convenes to validate and refine AI-generated requirements in real-time.</li> <li>AirSDLC Practice: This ritual is implemented during Phase 1: Inception. After the AI generates the initial <code>AI-PRD</code> and <code>AI-DAA</code>, the human expert (the \"mob,\" which can be a single architect or a small team) reviews these artifacts. The key activity is the validation and refinement of the DAA, ensuring it accurately models the business domain. This focused session replaces weeks of traditional backlog grooming and clarification meetings.</li> </ul>"},{"location":"core/#the-mob-construction-ritual","title":"The \"Mob Construction\" Ritual","text":"<ul> <li>AI-DLC Theory: A technical \"mob\" reviews and validates AI-proposed architecture and code.</li> <li>AirSDLC Practice: This is the heart of Phase 2: Collaborative Design. The \"mob\" (the architect or senior engineer) engages the AI as a \"Socratic Sparring Partner.\" Using the <code>Architectural Playbook</code>, the mob directs the AI to explore alternatives, identify risks, and challenge assumptions in the initial RFC. This is an active, collaborative design session that results in a robust <code>AI-ADR</code>.</li> </ul>"},{"location":"core/#bolts-as-actionable-adr-components","title":"\"Bolts\" as Actionable ADR Components","text":"<ul> <li>AI-DLC Theory: <code>Bolts</code> are short, focused implementation cycles measured in hours or days.</li> <li>AirSDLC Practice: A <code>Bolt</code> corresponds to a specific, actionable component from the finalized <code>AI-ADR</code>. For example, after the ADR for the \"Room Booking System\" is approved, a single Bolt could be \"Implement the <code>POST /bookings</code> endpoint and its service logic.\" During Phase 3: Construction, the engineer prompts the AI to generate the code for one Bolt at a time, ensuring focus and quality.</li> </ul>"},{"location":"core/#continuous-oversight-in-operations","title":"\"Continuous Oversight\" in Operations","text":"<ul> <li>AI-DLC Theory: Humans validate the AI's operational proposals in production.</li> <li>AirSDLC Practice: This is implemented in the latter part of Phase 3: Operation. The AI uses the full traceability chain (from DAA to ADR to code) to provide context-aware monitoring. For example, if it detects a latency spike, it can correlate it to the specific NFR in the original PRD and the service defined in the ADR, allowing it to propose a highly relevant scaling action for human approval.</li> </ul>"},{"location":"core/#post-deployment-bug-incident-handling","title":"Post-Deployment: Bug &amp; Incident Handling","text":"<p>A key advantage of the AirSDLC is its ability to handle post-deployment issues with unprecedented context and speed. The end-to-end traceability established during the design phase becomes a powerful tool for debugging and resolution. The process follows the core principle of \"AI-Driven Execution with Human Oversight.\"</p>"},{"location":"core/#the-context-aware-incident-response-loop","title":"The Context-Aware Incident Response Loop","text":"<p>When a bug or production incident occurs, the response is not a manual scramble through logs. Instead, it's a structured, human-initiated, AI-assisted investigation that leverages the entire chain of artifacts.</p> <pre><code>graph TD\n    A[Alert: Production Error Detected] --&gt; B(Human Engineer: Gathers Logs &amp; Context);\n    B --&gt; C{AI Triage &amp; Correlation};\n    C --&gt; D[Correlate Error to Code, Bolt, ADR, DAA, &amp; PRD];\n    D --&gt; E[Propose Root Cause &amp; Initial Fix];\n    E --&gt; F{Human Validation};\n    F -- Approve --&gt; G[AI Generates Hotfix PR];\n    F -- Reject/Refine --&gt; E;\n    G --&gt; H[Standard CI/CD &amp; Deployment];</code></pre> <p>Step 1: Human-Led Triage &amp; AI Correlation - Human Action (Proactive Gathering): The process begins with the on-call engineer. Upon receiving a production alert, the engineer's first step is to proactively gather the relevant artifacts. This includes specific error messages, relevant log snippets from the time of the incident, and the stack trace. - Input for AI: The engineer provides this curated set of information to the AI. - AI Action (Correlation): With this high-quality input, the AI's task becomes much more precise. It uses the stack trace to pinpoint the exact line of code and then leverages the full traceability chain:     1.  It identifies the \"Bolt\" that produced this code during the Construction phase.     2.  It compares the code with the intent of the Bolt and the final AI-ADR. This is crucial for detecting \"implementation drift.\"     3.  It traces the ADR back to the governing principles in the AI-DAA and the original PRD requirement. - Output: The AI presents a \"Triage Summary\" that now includes implementation-vs-design analysis.     - Example: \"Based on the logs provided, the error is <code>DB-Constraint-Violation</code> in <code>booking_service.go:152</code>.       - Correlation: This code was generated as part of Bolt-007 ('Implement Booking Creation').       - Analysis: The governing design, ADR-002, specifies that booking time slot uniqueness should be enforced at the database level to prevent double-booking. However, the code generated for Bolt-007 only implemented an application-level check. This mismatch between the ADR and the implementation is the likely root cause.       - Origin: This requirement traces back to the DAA invariant <code>A room cannot have overlapping bookings for the same time slot</code>.\"</p> <p>Step 2: AI-Proposed Remediation - AI Action: Based on its contextual understanding, the AI proposes a holistic solution.     - Root Cause Analysis: It explains the likely logical flaw (e.g., \"The ADR did not specify a database-level unique constraint for overlapping time slots, relying only on an application-level check which is susceptible to race conditions.\").     - Proposed Fix: It suggests a code change (e.g., \"Add a database constraint or exclusion constraint to prevent overlapping bookings for the same room and time slot, and update the repository code to handle the potential database error gracefully.\").</p> <p>Step 3: Human Validation and Decision - Human Role: The engineer's role is to validate the AI's analysis and decision, not hunt for the problem. - Action: The engineer reviews the Triage Summary and the proposed fix. They might ask the AI to refine it (\"What if we handle this at the application layer with distributed locking instead?\"). Once the engineer approves a course of action, they give the command to proceed.</p> <p>Step 4: AI-Generated Hotfix - AI Action: Upon approval, the AI generates a pull request containing the code changes, updates to unit tests, and an updated version of the AI-ADR to reflect the new architectural reality. This keeps the documentation from going stale. - Human Role: The engineer reviews the PR, merges it, and monitors the deployment.</p> <p>This process transforms bug handling from a reactive investigation into a structured, efficient, and context-rich review process, dramatically reducing the Mean Time To Resolution (MTTR).</p>"},{"location":"core/#operational-readiness-the-on-call-playbook","title":"Operational Readiness: The On-Call Playbook","text":"<p>The AirSDLC framework extends beyond deployment into operations. The same principles of AI-augmentation and end-to-end traceability are applied to incident management through a dedicated On-Call Playbook.</p> <p>The philosophy is to transform on-call from a reactive, stressful process into a structured, context-aware investigation. The on-call engineer acts as an \"Incident Commander,\" directing the AI which serves as a powerful SRE, using the full Knowledge Repository to rapidly correlate problems and propose solutions.</p> <p>This operational framework is detailed in its own document, which provides a complete guide to AI-augmented incident response, including specific runbooks for common alerts.</p> <p>For the complete framework, see the [[notebooks/ai/ai-on-call-playbook.md]].</p>"},{"location":"core/#the-airsdlc-ecosystem-from-framework-to-platform","title":"The AirSDLC Ecosystem: From Framework to Platform","text":"<p>It is critical to distinguish between the AirSDLC Framework and the tools that implement it. This document describes the framework\u2014a set of conventions, artifacts, and state-management rules. To bring this framework to life, an ecosystem of tools can be built on top of it.</p> <p>This separation allows for flexibility and a phased approach to adoption. Different tools can serve different roles, all operating on the same standardized repository of artifacts.</p>"},{"location":"core/#future-vision-the-knowledge-hub","title":"Future Vision: The Knowledge Hub","text":"<p>The long-term vision is to build a comprehensive web platform\u2014a Knowledge Hub\u2014that consumes the artifacts produced by implementation tools. This Hub would serve as the central nervous system for an entire engineering organization, providing:</p> <ul> <li>Visual Knowledge Graph Exploration: Allowing anyone from a PM to an on-call engineer to trace the full lifecycle of a feature.</li> <li>AI-Enhanced Collaboration: Facilitating design reviews and team coordination with an AI as an active participant.</li> <li>Portfolio and Project Management: Offering a true, AI-native alternative to traditional project management tools like Jira by providing automated status tracking, AI-powered forecasting, and high-level roadmap planning.</li> </ul> <p>This platform represents the ultimate goal: a fully integrated environment that replaces the friction of the traditional software development lifecycle with an intelligent, streamlined, and knowledge-centric workflow.</p>"},{"location":"extensibility/","title":"AirSDLC Extensibility","text":""},{"location":"extensibility/#overview","title":"Overview","text":"<p>The AirSDLC is designed as an extensible framework, not a rigid prescription. While it provides opinionated defaults based on proven practices, it recognizes that different teams, domains, and organizations have unique needs.</p> <p>This document describes how to adapt and extend the framework while maintaining its core principles and benefits.</p>"},{"location":"extensibility/#core-vs-extensions","title":"Core vs. Extensions","text":""},{"location":"extensibility/#the-immutable-core","title":"The Immutable Core","text":"<p>These aspects of AirSDLC should NOT be changed, as they define the framework's identity:</p> Core Principle Why Immutable AI-Driven Execution with Human Oversight This is the foundational paradigm Sequential Knowledge Handoff Ensures traceability from business to code Validation Gates Human validation is mandatory for quality Knowledge Repository Single source of truth is essential Phase Structure Inception \u2192 Design \u2192 Construction flow"},{"location":"extensibility/#extension-points","title":"Extension Points","text":"<p>These aspects CAN and SHOULD be adapted to your context:</p> Extension Point Examples Artifact Types Add custom artifacts (e.g., Security Review, Compliance Checklist) Artifact Templates Customize section names, add company-specific fields Workflow Ceremonies Adjust team review cadence, add approval steps Tool Integration Integrate with Jira, Linear, GitHub, Slack, etc. Playbook Patterns Add domain-specific or company-specific patterns DDD Interpretation Adapt tactical patterns to your domain complexity"},{"location":"extensibility/#extension-mechanism-1-custom-artifacts","title":"Extension Mechanism 1: Custom Artifacts","text":""},{"location":"extensibility/#when-to-add-a-custom-artifact","title":"When to Add a Custom Artifact","text":"<p>Add a new artifact type when: - Your organization has unique compliance requirements (e.g., SOC2 audit trail) - Your domain has specialized documentation needs (e.g., API Gateway configs for microservices) - Your team has proven that a specific artifact improves quality or speed</p> <p>Example: A hospitality company might add a \"Regulatory Impact Assessment\" artifact.</p>"},{"location":"extensibility/#how-to-define-a-custom-artifact","title":"How to Define a Custom Artifact","text":"<p>Follow the same structure as core artifacts:</p>"},{"location":"extensibility/#1-define-metadata","title":"1. Define Metadata","text":"<ul> <li>Artifact Name: Regulatory Impact Assessment (RIA)</li> <li>Acronym: RIA</li> <li>Phase: Design (between RFC and ADR)</li> <li>Generator: Compliance Officer (with AI assistance)</li> <li>Validator: Legal team</li> <li>Mandatory or Optional: Mandatory for features touching PII or booking transactions</li> </ul>"},{"location":"extensibility/#2-define-purpose","title":"2. Define Purpose","text":"<p>Purpose: Assess regulatory compliance implications of a proposed design before finalization.</p>"},{"location":"extensibility/#3-define-structure","title":"3. Define Structure","text":"<pre><code>## RIA Template\n\n### 1. Feature Summary\n- Feature Name\n- ADR Reference\n- Business Justification\n\n### 2. Data Classification\n- [ ] Handles Personally Identifiable Information (PII)\n- [ ] Handles booking data (reservations, guest information)\n- [ ] Handles authentication credentials\n\n### 3. Regulatory Frameworks\nWhich regulations apply?\n- [ ] GDPR (EU data protection)\n- [ ] PCI-DSS (payment card security if applicable)\n- [ ] SOC2 (security controls)\n- [ ] CCPA (California privacy)\n\n### 4. Compliance Requirements\nFor each applicable framework:\n- **Requirement**: Right to be forgotten (GDPR Article 17)\n- **Implementation**: User data deletion API in ADR-023\n- **Evidence**: Link to code implementing deletion\n\n### 5. Risk Assessment\n| Risk | Likelihood | Impact | Mitigation |\n|------|------------|--------|------------|\n| Data breach | Low | High | Encryption at rest and in transit |\n| Unauthorized access | Medium | High | Role-based access control |\n\n### 6. Approval\n- [ ] Compliance Officer sign-off\n- [ ] Legal team review\n- [ ] Date: ___________\n</code></pre>"},{"location":"extensibility/#4-integrate-into-workflow","title":"4. Integrate into Workflow","text":"<p>Update your team's workflow to include RIA generation:</p> <pre><code>Phase 2: Design\n  \u2193\nStep 8: Generate AI-ADR (existing)\n  \u2193\n**Step 8.5: Generate RIA** (NEW)\n  - Compliance Officer reviews ADR\n  - AI assists in identifying regulated data\n  - Legal team validates compliance\n  \u2193\nStep 9: Finalize ADR (existing, now conditional on RIA approval)\n</code></pre>"},{"location":"extensibility/#5-update-traceability-chain","title":"5. Update Traceability Chain","text":"<pre><code>PRD \u2192 DAA \u2192 RFC \u2192 ADR \u2192 **RIA** \u2192 Bolt \u2192 Code\n</code></pre>"},{"location":"extensibility/#extension-mechanism-2-custom-templates","title":"Extension Mechanism 2: Custom Templates","text":""},{"location":"extensibility/#customizing-existing-artifacts","title":"Customizing Existing Artifacts","text":"<p>All AirSDLC artifacts can be customized by: 1. Adding sections: Insert company-specific fields 2. Removing sections: Skip fields that don't apply (with caution) 3. Reordering sections: Prioritize what matters to your team</p>"},{"location":"extensibility/#example-custom-adr-template-for-microservices","title":"Example: Custom ADR Template for Microservices","text":"<p>Standard ADR: <pre><code># ADR-XXX: Title\n\n## 1. Metadata\n## 2. Context\n## 3. Decision\n## 4. Rationale\n## 5. Implementation Details\n## 6. Edge Cases\n## 7. Monitoring\n## 8. Rejected Alternatives\n</code></pre></p> <p>Custom ADR for microservices-heavy architecture: <pre><code># ADR-XXX: Title\n\n## 1. Metadata\n## 2. Context\n## 3. Service Boundaries  &lt;-- NEW: Which services are affected?\n## 4. Decision\n## 5. Rationale\n## 6. API Contracts  &lt;-- NEW: Inter-service communication\n## 7. Implementation Details\n## 8. Service Mesh Configuration  &lt;-- NEW: Istio/Linkerd configs\n## 9. Edge Cases\n## 10. Monitoring &amp; Distributed Tracing  &lt;-- MODIFIED\n## 11. Rejected Alternatives\n</code></pre></p>"},{"location":"extensibility/#template-versioning","title":"Template Versioning","text":"<p>As your team evolves, template needs change. Use versioning: - <code>adr-template-v1.0.md</code>: Original - <code>adr-template-v2.0.md</code>: Added Service Boundaries section - <code>adr-template-v3.0.md</code>: Added security review checklist</p> <p>Migration Strategy: - New ADRs use latest template - Existing ADRs are NOT retrofitted (too costly) - Major ADRs can be updated during significant amendments</p>"},{"location":"extensibility/#extension-mechanism-3-custom-playbook-patterns","title":"Extension Mechanism 3: Custom Playbook Patterns","text":""},{"location":"extensibility/#domain-specific-patterns","title":"Domain-Specific Patterns","text":"<p>The Architectural Playbook should grow with your team's experience. Add patterns that solve YOUR recurring problems.</p> <p>Example Categories: - E-commerce: Cart abandonment recovery, inventory synchronization - Hospitality: Idempotent booking processing, reservation consistency - Healthcare: HIPAA-compliant logging, patient data anonymization - SaaS: Multi-tenant data isolation, usage-based billing</p>"},{"location":"extensibility/#how-to-add-a-playbook-entry","title":"How to Add a Playbook Entry","text":"<p>Follow the standard Playbook structure (see Artifacts):</p> <pre><code>## PLAYBOOK-042: Idempotent Booking Processing\n\n### Problem\nHow do we prevent duplicate bookings when a client retries a booking API call?\n\n### Context\n**Use when**:\n- Handling reservation transactions\n- Client may retry on network timeout\n- Consequences of duplication are severe (overbooking, guest dissatisfaction)\n\n**Do NOT use when**:\n- Operations are naturally idempotent (e.g., GET requests)\n- Duplicate processing is acceptable\n\n### Solution\nUse idempotency keys:\n1. Client generates unique key (UUID) and sends with request\n2. Server stores key in database with transaction result\n3. On retry, server checks if key exists\n4. If exists, return cached result (do not re-process)\n5. Keys expire after 24 hours\n\n### Implementation Checklist\n- [ ] Database table: `idempotency_keys(key, result, created_at)`\n- [ ] API requires `Idempotency-Key` header\n- [ ] Server returns `409 Conflict` if result differs from cached\n- [ ] Background job cleans up keys &gt; 24 hours old\n- [ ] Monitoring: Track duplicate key hits\n\n### Trade-offs\n**Pros**:\n- \u2705 Prevents duplicate bookings\n- \u2705 Client can safely retry\n\n**Cons**:\n- \u274c Adds database dependency\n- \u274c Requires client cooperation (must send key)\n- \u274c Storage cost for key cache\n\n### Example\nADR-087: Booking Processing API\n</code></pre>"},{"location":"extensibility/#playbook-governance","title":"Playbook Governance","text":"<p>As the Playbook grows: - Review Regularly: Quarterly architecture review - Deprecate Obsolete Patterns: Mark as \"Deprecated\" if technology changes - Version Patterns: If a pattern evolves significantly, create a new version - Cross-Reference: Link related patterns (e.g., \"See also: Circuit Breaker Pattern\")</p>"},{"location":"extensibility/#extension-mechanism-4-workflow-customization","title":"Extension Mechanism 4: Workflow Customization","text":""},{"location":"extensibility/#adjusting-ceremony-cadence","title":"Adjusting Ceremony Cadence","text":"<p>The framework suggests specific validation rituals (Mob Elaboration, Mob Construction). Adapt the frequency and format to your team size and maturity:</p> Team Size Suggested Ceremony 1-3 engineers Async review (PR comments, Slack threads) 4-10 engineers Weekly design review meeting (1 hour) 10+ engineers Dedicated design review sessions per feature"},{"location":"extensibility/#adding-approval-gates","title":"Adding Approval Gates","text":"<p>Some organizations require additional sign-offs:</p> <p>Example: Enterprise Approval Workflow <pre><code>Standard AirSDLC:\n  RFC \u2192 Collaborative Design \u2192 AI-ADR \u2192 Construction\n\nEnterprise Extension:\n  RFC \u2192 Collaborative Design \u2192 AI-ADR \n    \u2192 **Architecture Board Review** (NEW)\n    \u2192 **Security Team Approval** (NEW)\n    \u2192 **Budget Approval** (NEW)\n    \u2192 Construction\n</code></pre></p> <p>Implementation: 1. Add ADR status: <code>awaiting-approval</code> 2. Document required approvals in ADR metadata:    <pre><code>## Approvals\n- [ ] Architecture Board: Pending (scheduled for 2024-01-20)\n- [ ] Security Team: Approved (2024-01-18, signed by @jane)\n- [ ] Budget: Pending (waiting for Q1 allocation)\n</code></pre> 3. ADR transitions to <code>accepted</code> only after all approvals</p>"},{"location":"extensibility/#lightweight-vs-full-workflow-threshold","title":"Lightweight vs. Full Workflow Threshold","text":"<p>The framework provides a Decision Matrix for choosing workflow paths. Customize thresholds for your domain:</p> <p>Standard Thresholds: - Complex domain \u2192 Full Workflow - Simple feature \u2192 Lightweight Workflow</p> <p>Custom Thresholds for a High-Compliance Hospitality System: - Touches PII or booking data \u2192 Full Workflow (always) - Integrates with external property management system \u2192 Full Workflow - Internal admin tool \u2192 Lightweight Workflow - Performance optimization (no logic change) \u2192 Lightweight Workflow</p> <p>Document your custom matrix: <pre><code>## Our Workflow Decision Matrix\n\n| Feature Characteristic | Workflow |\n|------------------------|----------|\n| Handles bookings/PII | Full (AI-DAA required) |\n| Third-party integration | Full |\n| Internal tools | Lightweight (TIP) |\n| Bug fix (no new logic) | Lightweight (TIP) |\n| Performance tuning | Lightweight (TIP) |\n</code></pre></p>"},{"location":"extensibility/#extension-mechanism-5-tool-integration","title":"Extension Mechanism 5: Tool Integration","text":"<p>The AirSDLC is tool-agnostic. Integrate with your existing toolchain:</p>"},{"location":"extensibility/#project-management-integration","title":"Project Management Integration","text":"<p>Jira / Linear / Asana: - PRD \u2192 Epic in Jira - DAA/ADR \u2192 Attached as PDF or link to git repo - Bolt \u2192 Jira Story with link to ADR - Fix-It Bolt \u2192 Jira Bug with link to incident</p> <p>Custom Fields: - <code>ADR Reference</code>: Link to ADR document - <code>Bolt ID</code>: BOLT-042 - <code>Phase</code>: Inception, Design, Construction, Operations</p>"},{"location":"extensibility/#cicd-integration","title":"CI/CD Integration","text":"<p>Automated Checks: - On PR: Check if code references a Bolt - On Merge: Update Bolt status to \"Completed\" - On Deploy: Create Deployment Unit artifact</p> <p>GitHub Actions Example: <pre><code>name: Validate Bolt Reference\non: pull_request\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check PR has Bolt reference\n        run: |\n          if ! grep -q \"BOLT-[0-9]\" ${{ github.event.pull_request.body }}; then\n            echo \"Error: PR must reference a Bolt ID\"\n            exit 1\n          fi\n</code></pre></p>"},{"location":"extensibility/#notification-integration","title":"Notification Integration","text":"<p>Slack / Teams: - ADR Approved \u2192 Notify #engineering channel - Incident Declared \u2192 Ping @oncall in #incidents - Post-Mortem Published \u2192 Share in #learning channel</p> <p>Example Slack Integration: <pre><code># Post ADR approval to Slack\ncurl -X POST -H 'Content-type: application/json' \\\n  --data '{\"text\":\"\ud83c\udf89 ADR-023 (Booking Cancellation) has been approved! Ready for construction.\"}' \\\n  https://hooks.slack.com/services/YOUR/WEBHOOK/URL\n</code></pre></p>"},{"location":"extensibility/#ai-tool-integration","title":"AI Tool Integration","text":"<p>OpenAI API / Claude API: - Automate DAA generation from PRD - Automate Coverage Report generation - Automate Compliance Report generation</p> <p>Example Script: <pre><code>import openai\n\ndef generate_daa(prd_text):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-4\",\n        messages=[{\n            \"role\": \"system\",\n            \"content\": \"You are a DDD expert. Generate an AI-DAA from this PRD.\"\n        }, {\n            \"role\": \"user\",\n            \"content\": prd_text\n        }]\n    )\n    return response['choices'][0]['message']['content']\n\nprd = open('docs/prds/booking-cancel.md').read()\ndaa = generate_daa(prd)\nopen('docs/daas/booking-cancel-daa.md', 'w').write(daa)\nprint(\"DAA generated: docs/daas/booking-cancel-daa.md\")\n</code></pre></p>"},{"location":"extensibility/#extension-mechanism-6-state-machine-customization","title":"Extension Mechanism 6: State Machine Customization","text":"<p>The AirSDLC workflow can be modeled as a state machine. Extend the states and transitions for your needs.</p>"},{"location":"extensibility/#standard-state-machine-simplified","title":"Standard State Machine (Simplified)","text":"<pre><code>PRD \u2192 DAA (draft) \u2192 DAA (validated) \u2192 RFC (draft) \u2192 RFC (under_review) \n  \u2192 RFC (approved) \u2192 ADR (accepted) \u2192 Bolt (in_progress) \u2192 Bolt (done) \n  \u2192 Deployed\n</code></pre>"},{"location":"extensibility/#extended-state-machine-enterprise","title":"Extended State Machine (Enterprise)","text":"<pre><code>PRD \u2192 DAA (draft) \u2192 DAA (validated) \u2192 RFC (draft) \u2192 RFC (under_review) \n  \u2192 RFC (approved) \u2192 ADR (proposed) \n  \u2192 ADR (awaiting_security_review)  &lt;-- NEW STATE\n  \u2192 ADR (awaiting_budget_approval)  &lt;-- NEW STATE\n  \u2192 ADR (accepted) \u2192 Bolt (in_progress) \u2192 Bolt (done) \n  \u2192 Staging_Deployed  &lt;-- NEW STATE\n  \u2192 Production_Deployed\n</code></pre>"},{"location":"extensibility/#defining-custom-transitions","title":"Defining Custom Transitions","text":"<p>Define who can trigger each transition:</p> Transition Trigger Required Action <code>DAA (draft) \u2192 DAA (validated)</code> Architect Review + approval comment <code>RFC (approved) \u2192 ADR (proposed)</code> AI + Engineer Generate ADR from RFC <code>ADR (proposed) \u2192 ADR (awaiting_security_review)</code> Engineer Submit to security team <code>ADR (awaiting_security_review) \u2192 ADR (awaiting_budget_approval)</code> Security Team Approve + sign-off <code>ADR (awaiting_budget_approval) \u2192 ADR (accepted)</code> Finance/PM Budget allocated <p>Implementation: Use git tags or metadata files to track state: <pre><code># Tag ADR as \"awaiting security review\"\ngit tag adr-023-awaiting-security-review\ngit push --tags\n</code></pre></p> <p>Or use YAML frontmatter: <pre><code>---\nadr_id: ADR-023\ntitle: Booking Cancellation Implementation\nstatus: awaiting_security_review\napprovals:\n  - security: pending\n  - budget: not_required\n---\n\n# ADR-023: Booking Cancellation Implementation\n...\n</code></pre></p>"},{"location":"extensibility/#extension-mechanism-7-metrics-and-reporting","title":"Extension Mechanism 7: Metrics and Reporting","text":"<p>Extend the framework with custom metrics that matter to YOUR organization.</p>"},{"location":"extensibility/#standard-metrics","title":"Standard Metrics","text":"<p>AirSDLC inherently provides: - Traceability Coverage: % of code with traceable Bolt \u2192 ADR \u2192 DAA \u2192 PRD - Lead Time: Time from PRD to production deployment - Change Failure Rate: % of deployments causing incidents</p>"},{"location":"extensibility/#custom-metrics-examples","title":"Custom Metrics Examples","text":"<p>For Product Teams: - Feature ROI: Business metric improvement per feature (from PRD success metrics) - Requirement Drift: % of user stories that changed after DAA validation</p> <p>For Engineering Teams: - ADR Reuse: % of ADRs that reference existing Playbook patterns - Bolt Size: Average effort per Bolt (target: &lt; 2 days) - Code-to-ADR Divergence: % of PRs that don't match their ADR</p> <p>For Operations Teams: - Context-Assisted Incident Resolution: % of incidents where AI correlation accelerated MTTR - Knowledge Repository Queries: How often is the repo accessed during incidents?</p>"},{"location":"extensibility/#reporting-dashboard","title":"Reporting Dashboard","text":"<p>Build a dashboard that visualizes AirSDLC metrics:</p> <p>Example Sections: 1. Pipeline Health:    - PRDs in progress    - DAAs awaiting validation    - ADRs awaiting approval    - Bolts in progress</p> <ol> <li>Quality Indicators:</li> <li>Traceability coverage</li> <li>ADR compliance rate</li> <li> <p>Test coverage per Bolt</p> </li> <li> <p>Operational Excellence:</p> </li> <li>MTTR trend</li> <li>Incident recurrence rate</li> <li>Post-mortem completion rate</li> </ol> <p>Implementation: - Parse git repo metadata (tags, file paths) - Query project management tool APIs (Jira, Linear) - Aggregate in dashboard tool (Grafana, Datadog, custom webapp)</p>"},{"location":"extensibility/#extension-mechanism-8-multi-team-coordination","title":"Extension Mechanism 8: Multi-Team Coordination","text":"<p>For organizations with multiple teams, extend the framework to coordinate dependencies.</p>"},{"location":"extensibility/#cross-team-adrs","title":"Cross-Team ADRs","text":"<p>When a feature spans multiple teams:</p> <p>Example: A booking feature requires changes to: - Team A: Booking Service (cancel bookings before checkout) - Team B: Reservation Service (process cancellation) - Team C: Notification Service (alert guest)</p> <p>Approach: 1. Primary ADR (owned by Team B, the coordinating team):    - ADR-050: Multi-Service Booking Flow    - Describes overall architecture</p> <ol> <li>Dependent ADRs (owned by each team):</li> <li>ADR-051: Booking Cancellation Integration (Team A)</li> <li>ADR-052: Reservation Processor Integration (Team B)</li> <li> <p>ADR-053: Booking Notification Trigger (Team C)</p> </li> <li> <p>Cross-Reference:    Each dependent ADR references the primary ADR:    <pre><code>## Context\nThis ADR implements the Booking Service portion of ADR-050 (Multi-Service Booking Flow).\n\n**Dependencies**:\n- ADR-052 must complete before integration testing\n- ADR-053 consumes events published by this service\n</code></pre></p> </li> </ol>"},{"location":"extensibility/#shared-playbook","title":"Shared Playbook","text":"<p>Multiple teams can contribute to a shared Architectural Playbook: - Governance: Architecture guild reviews and approves new entries - Ownership: Each pattern has a designated owner/team - Versioning: Use semantic versioning for breaking changes</p>"},{"location":"extensibility/#conformance-criteria","title":"Conformance Criteria","text":"<p>To be considered \"AirSDLC-compliant,\" a tool or process MUST:</p>"},{"location":"extensibility/#mandatory-requirements","title":"Mandatory Requirements","text":"<ol> <li>\u2705 Implement Core Artifacts:</li> <li>PRD or equivalent requirement document</li> <li>DAA or TIP (domain model or technical proposal)</li> <li> <p>ADR (architectural decision record)</p> </li> <li> <p>\u2705 Support Sequential Phases:</p> </li> <li>Phase 1: Requirements \u2192 Domain/Technical Understanding</li> <li>Phase 2: Design with human validation</li> <li> <p>Phase 3: Construction with traceability</p> </li> <li> <p>\u2705 Enforce Validation Gates:</p> </li> <li>Human must approve artifacts before phase transitions</li> <li> <p>AI-generated artifacts cannot auto-proceed without review</p> </li> <li> <p>\u2705 Maintain Traceability:</p> </li> <li>Code must be traceable to ADR</li> <li>ADR must be traceable to DAA/TIP</li> <li> <p>DAA/TIP must be traceable to PRD</p> </li> <li> <p>\u2705 Store in Knowledge Repository:</p> </li> <li>All artifacts are persisted and queryable</li> <li>Repository is the single source of truth</li> </ol>"},{"location":"extensibility/#optional-extensions-recommended-but-not-required","title":"Optional Extensions (Recommended but not required)","text":"<ul> <li>Custom artifact types</li> <li>Custom workflow ceremonies</li> <li>Tool integrations</li> <li>Advanced metrics and reporting</li> </ul>"},{"location":"extensibility/#adoption-strategy-start-small-extend-gradually","title":"Adoption Strategy: Start Small, Extend Gradually","text":""},{"location":"extensibility/#phase-1-pilot-weeks-1-4","title":"Phase 1: Pilot (Weeks 1-4)","text":"<ul> <li>Choose 1-2 features</li> <li>Use core artifacts only (PRD, DAA, ADR)</li> <li>Manual workflow (no tooling yet)</li> <li>Gather feedback</li> </ul>"},{"location":"extensibility/#phase-2-refine-weeks-5-8","title":"Phase 2: Refine (Weeks 5-8)","text":"<ul> <li>Customize templates based on pilot learnings</li> <li>Add 3-5 Playbook entries</li> <li>Introduce TIP for simple features (Lightweight Workflow)</li> <li>Formalize validation process</li> </ul>"},{"location":"extensibility/#phase-3-scale-weeks-9-16","title":"Phase 3: Scale (Weeks 9-16)","text":"<ul> <li>Roll out to all teams</li> <li>Build tool integrations (Jira, CI/CD, Slack)</li> <li>Add custom artifacts if needed</li> <li>Establish metrics and reporting</li> </ul>"},{"location":"extensibility/#phase-4-mature-month-4","title":"Phase 4: Mature (Month 4+)","text":"<ul> <li>Continuous Playbook growth</li> <li>AI-assisted generation becomes standard</li> <li>Knowledge Repository enables powerful queries</li> <li>Operational excellence (context-aware incidents)</li> </ul>"},{"location":"extensibility/#summary","title":"Summary","text":"<p>AirSDLC is a framework, not a straitjacket. Its power comes from: 1. Immutable core principles (AI-driven, human-validated, traceable) 2. Flexible extension points (artifacts, templates, workflows, tools) 3. Pragmatic adoption (start small, extend as you learn)</p> <p>By respecting the core while customizing the extensions, teams can achieve both consistency (across teams) and flexibility (for unique needs).</p> <p>End of Core Documentation</p> <p>You've now completed the core AirSDLC framework documentation. For practical examples, see Examples.</p>"},{"location":"lifecycle/","title":"AirSDLC Lifecycle","text":""},{"location":"lifecycle/#overview","title":"Overview","text":"<p>The AirSDLC lifecycle is built on a sequential knowledge handoff model. Each phase transforms and enriches the context from the previous phase, creating an unbroken chain of traceability from business intent to production code.</p> <pre><code>graph TD\n    A[Business Intent] --&gt; B(Phase 1: Inception)\n    B --&gt; C[Artifact: AI-DAA]\n    C --&gt; D(Phase 2: Collaborative Design)\n    D --&gt; E[Artifact: AI-ADR]\n    E --&gt; F(Phase 3: Construction &amp; Operations)\n    F --&gt; G[Production Code &amp; Monitoring]</code></pre>"},{"location":"lifecycle/#phase-1-inception-the-what","title":"Phase 1: Inception (The \"WHAT\")","text":""},{"location":"lifecycle/#objective","title":"Objective","text":"<p>Translate an ambiguous business goal into a pure, technology-agnostic, and validated model of the business domain.</p>"},{"location":"lifecycle/#input","title":"Input","text":"<ul> <li>Business Intent: A high-level description of what needs to be built (e.g., \"We need a room booking system\")</li> <li>Product Requirements Document (PRD): Structured requirements including user stories, acceptance criteria, and success metrics</li> </ul>"},{"location":"lifecycle/#process","title":"Process","text":""},{"location":"lifecycle/#step-1-choose-the-workflow-path","title":"Step 1: Choose the Workflow Path","text":"<p>The lead engineer or architect assesses the feature's context to determine the appropriate level of upfront modeling:</p> <p>Decision Matrix:</p> <pre><code>graph TD\n    Start[Assess Feature Context] --&gt; Q1{Is domain complex&lt;br/&gt;or unfamiliar?}\n    Q1 --&gt;|Yes| Full1[Full Workflow&lt;br/&gt;AI-DAA]\n    Q1 --&gt;|No| Q2{Is feature&lt;br/&gt;high-risk or&lt;br/&gt;mission-critical?}\n\n    Q2 --&gt;|Yes| Full2[Full Workflow&lt;br/&gt;AI-DAA]\n    Q2 --&gt;|No| Q3{Are junior team&lt;br/&gt;members involved?}\n\n    Q3 --&gt;|Yes, for learning| Full3[Full Workflow&lt;br/&gt;AI-DAA]\n    Q3 --&gt;|No| Q4{Is feature simple&lt;br/&gt;and well-understood?}\n\n    Q4 --&gt;|Yes| Light1[Lightweight Workflow&lt;br/&gt;TIP]\n    Q4 --&gt;|No| Q5{Tight deadline?}\n\n    Q5 --&gt;|Yes| Light2[Lightweight Workflow&lt;br/&gt;TIP with validation]\n    Q5 --&gt;|No| Full4[Full Workflow&lt;br/&gt;AI-DAA]</code></pre>"},{"location":"lifecycle/#step-2a-full-workflow-generate-ai-daa","title":"Step 2A: Full Workflow - Generate AI-DAA","text":"<p>For complex or high-risk features, the AI generates a Domain Architecture Analysis (AI-DAA):</p> <ol> <li>Parse the PRD: AI identifies key \"nouns\" (entities) and \"verbs\" (operations)</li> <li>Apply Strategic DDD: AI proposes Bounded Contexts and Context Maps</li> <li>Apply Tactical DDD: AI defines Aggregates, Entities, Value Objects, and Domain Events</li> <li>Generate Pseudocode: AI writes technology-agnostic pseudocode for all operations</li> <li>Validate Invariants: AI explicitly documents business rules and constraints</li> </ol> <p>Key Characteristics of a Well-Formed DAA: - \u2705 100% technology-neutral (no databases, frameworks, or languages mentioned) - \u2705 Uses DDD patterns consistently - \u2705 All business invariants are explicit - \u2705 Every user story from the PRD maps to at least one operation - \u2705 Written in clear pseudocode understandable by non-technical domain experts</p>"},{"location":"lifecycle/#step-2b-lightweight-workflow-write-tip","title":"Step 2B: Lightweight Workflow - Write TIP","text":"<p>For simple, well-understood features, the engineer creates a Technical Implementation Proposal (TIP):</p> <ol> <li>Read the PRD: Engineer understands requirements</li> <li>Draft Technical Details: Engineer proposes:</li> <li>Database schema changes</li> <li>API endpoints</li> <li>Service modifications</li> <li>Integration points</li> <li>Identify Questions: Engineer flags unknowns or concerns</li> </ol> <p>Key Difference from DAA: - \u2705 Technology-specific (mentions actual databases, APIs, etc.) - \u2705 More direct and concrete - \u2705 Skips abstract domain modeling - \u2705 Faster to create for simple features</p>"},{"location":"lifecycle/#human-validation-gate","title":"Human Validation Gate","text":"<p>Regardless of workflow path, the output must pass human validation:</p> <p>For AI-DAA: - Does it accurately model the business domain? - Are all PRD requirements addressed? - Are the proposed Bounded Contexts sensible? - Do the invariants reflect real business rules? - Can a domain expert understand the pseudocode?</p> <p>For TIP: - Does it address all PRD requirements? - Are the technical choices appropriate? - Are integration points clearly defined? - Are edge cases considered?</p> <p>Validation Technique: Use AI to generate a \"Coverage Report\" that compares the DAA/TIP against the PRD, highlighting any gaps.</p>"},{"location":"lifecycle/#output","title":"Output","text":"<ul> <li>Full Workflow: Validated AI-DAA - The locked domain model</li> <li>Lightweight Workflow: Draft TIP - The engineer's initial technical proposal</li> </ul>"},{"location":"lifecycle/#when-to-use-full-vs-lightweight","title":"When to Use Full vs. Lightweight","text":"<p>Use Full Workflow when: - The domain is unfamiliar to the team - The feature has high business complexity - The feature is mission-critical or high-risk - You want to teach junior engineers structured thinking - The feature will likely evolve significantly</p> <p>Use Lightweight Workflow when: - The feature is a simple CRUD operation - The domain is well-understood by the team - The technical implementation is obvious - Timeline pressure requires speed - The team is experienced with the technology</p> <p>Non-Negotiable: Even in the Lightweight Workflow, validation is mandatory.</p>"},{"location":"lifecycle/#phase-2-collaborative-design-the-how","title":"Phase 2: Collaborative Design (The \"HOW\")","text":""},{"location":"lifecycle/#objective_1","title":"Objective","text":"<p>Synthesize the \"what\" from the Inception phase with the \"how\" of a technical implementation, resulting in a robust architectural decision.</p>"},{"location":"lifecycle/#input_1","title":"Input","text":"<ul> <li>From Phase 1: Validated AI-DAA (Full Workflow) or Draft TIP (Lightweight Workflow)</li> <li>Engineer's RFC: A draft Request for Comments containing:</li> <li>The DAA or TIP</li> <li>Initial technical thoughts</li> <li>Open questions</li> <li>Constraints (budget, timeline, team skills)</li> </ul>"},{"location":"lifecycle/#process_1","title":"Process","text":""},{"location":"lifecycle/#step-1-prepare-the-rfc","title":"Step 1: Prepare the RFC","text":"<p>The engineer formalizes the output from Inception into an RFC document:</p> <p>RFC Structure: - Title &amp; Metadata: Feature name, author, date, status - Context: Link to PRD, business justification - Problem Statement: From the DAA (if Full Workflow) or PRD summary (if Lightweight) - Proposed Implementation: Initial technical approach - Open Questions: What needs discussion? - Constraints: Non-negotiables (timeline, budget, compliance, etc.)</p>"},{"location":"lifecycle/#step-2-consult-the-architectural-playbook","title":"Step 2: Consult the Architectural Playbook","text":"<p>Before the collaborative session, the architect identifies applicable patterns from the Architectural Playbook:</p> <p>Example Playbook Patterns: - Transactional Outbox Pattern (for reliable event publishing) - Idempotent API Design (for at-least-once delivery guarantees) - Circuit Breaker Pattern (for resilient service calls) - CQRS Pattern (for read-heavy workloads) - Saga Pattern (for distributed transactions)</p> <p>The Playbook provides: - Problem description: When to use this pattern - Solution details: How to implement it - Trade-offs: Pros and cons - Edge case checklist: What to watch for</p>"},{"location":"lifecycle/#step-3-the-collaborative-discussion-ai-as-socratic-sparring-partner","title":"Step 3: The Collaborative Discussion - AI as Socratic Sparring Partner","text":"<p>This is the heart of Phase 2. The architect engages in an active dialogue with the AI:</p> <p>The Process: 1. Provide Context: Feed the AI the RFC, DAA/TIP, and relevant Playbook patterns 2. Prompt for Challenge: \"Review this design. Challenge it. What could go wrong?\" 3. Explore Alternatives: \"Propose 3 alternative approaches and compare trade-offs.\" 4. Deep Dive on Risks: \"How should we handle [specific edge case]?\" 5. Generate Diagrams: \"Create a sequence diagram showing the event flow.\" 6. Iterate: Refine the design based on AI's feedback and architect's judgment</p> <p>Key Technique: Use diagrams-as-code (Mermaid, PlantUML) to clarify thinking. Visual representations often surface hidden assumptions.</p> <p>Example Dialogue: <pre><code>Architect: \"I'm proposing to use synchronous HTTP calls for booking confirmations.\"\n\nAI: \"This creates tight coupling and a potential single point of failure. If the \nnotification service is down, the booking creation will fail. Have you considered \nan asynchronous, event-driven approach using the Transactional Outbox Pattern \nfrom your Playbook?\"\n\nArchitect: \"Good point. But won't that add latency to confirmations?\"\n\nAI: \"Yes, there will be a slight delay (typically seconds). However, the trade-off \nis increased reliability and decoupling. Given your NFR states '99.9% uptime for \nbooking creation,' this trade-off is favorable. The confirmation latency is acceptable \nfor this use case based on your PRD.\"\n\nArchitect: \"Agreed. Generate a sequence diagram showing the outbox pattern flow.\"\n\nAI: [Generates Mermaid diagram]\n\nArchitect: \"Perfect. How do we handle poison pills in the outbox relay?\"\n\nAI: \"You should implement a dead-letter queue pattern. After 3 retry attempts, \nmessages should be moved to a DLQ for manual investigation. This is covered in \nPlaybook entry 'DLQ-001.'\"\n</code></pre></p>"},{"location":"lifecycle/#step-4-finalize-the-design","title":"Step 4: Finalize the Design","text":"<p>Once the architect is satisfied that the design is robust and all major risks are addressed:</p> <ol> <li>The RFC is updated with final decisions</li> <li>Open questions are resolved</li> <li>Trade-offs are explicitly documented</li> </ol>"},{"location":"lifecycle/#human-validation-gate_1","title":"Human Validation Gate","text":"<p>The architect (or senior engineer) must validate: - \u2705 Does the design respect the domain invariants from the DAA? - \u2705 Are all trade-offs explicitly documented? - \u2705 Have applicable Playbook patterns been considered? - \u2705 Are edge cases addressed? - \u2705 Is the design implementable given constraints (team skills, timeline)? - \u2705 Have alternatives been considered and rejected with clear rationale?</p>"},{"location":"lifecycle/#output_1","title":"Output","text":"<p>AI-ADR (Architectural Decision Record): The finalized, immutable specification for implementation.</p> <p>The ADR contains: - Decision: The chosen technical approach - Rationale: Why this approach (referencing the DAA and trade-off analysis) - Implementation Details: High-level technical specification - Diagrams: Sequence diagrams, architecture diagrams (as code) - Rejected Alternatives: What was considered and why it was rejected - Edge Cases: How specific scenarios will be handled</p>"},{"location":"lifecycle/#phase-3-construction-operations-the-build-run","title":"Phase 3: Construction &amp; Operations (The \"BUILD &amp; RUN\")","text":""},{"location":"lifecycle/#objective_2","title":"Objective","text":"<p>Use the finalized AI-ADR to generate, test, and deploy production-ready code, then provide context-aware monitoring and incident response.</p>"},{"location":"lifecycle/#part-a-construction","title":"Part A: Construction","text":""},{"location":"lifecycle/#input_2","title":"Input","text":"<ul> <li>Finalized AI-ADR from Phase 2</li> </ul>"},{"location":"lifecycle/#process_2","title":"Process","text":"<p>Step 1: Break into Bolts The project is decomposed into discrete, focused implementation units called Bolts:</p> <p>Characteristics of a Good Bolt: - \u2705 Single goal (e.g., \"Implement the POST /bookings endpoint\") - \u2705 Completable in hours or days (not weeks) - \u2705 Has clear acceptance criteria from the ADR - \u2705 Produces a testable artifact</p> <p>Example Bolt Breakdown for \"Room Booking System\": - Bolt 1: Create database migration for <code>bookings</code> and <code>rooms</code> tables - Bolt 2: Implement <code>POST /bookings</code> API handler - Bolt 3: Implement <code>BookingAggregate</code> business logic with conflict detection - Bolt 4: Implement Transactional Outbox relay worker for booking events - Bolt 5: Add monitoring dashboards for booking success/conflict metrics</p> <p>Step 2: Implement Each Bolt For each Bolt, the engineer leverages AI for boilerplate generation:</p> <ol> <li>Prompt AI: \"Based on ADR-003, generate the Go boilerplate for the POST /bookings handler.\"</li> <li>AI Generates: Route definition, handler function, input validation, error handling</li> <li>Engineer Implements: Core business logic (conflict detection, availability checks), complex algorithms, domain-specific rules</li> <li>AI Generates Tests: Unit tests, integration tests based on the ADR's acceptance criteria</li> <li>Engineer Reviews: Validate tests are comprehensive</li> </ol> <p>Division of Labor: - AI: Boilerplate, CRUD operations, standard patterns, test scaffolding - Human: Business logic, complex algorithms, performance optimization, security reviews</p> <p>Step 3: Validate Against ADR After implementation, use AI to generate a \"Compliance Report\": - Does the code match the design in the ADR? - Are all edge cases from the ADR handled? - Do tests cover the scenarios described in the ADR?</p>"},{"location":"lifecycle/#output_2","title":"Output","text":"<ul> <li>Production-Ready Code: Fully tested, reviewed code</li> <li>Tests: Unit, integration, and end-to-end tests</li> <li>Deployment Artifacts: IaC configurations, container images, deployment scripts</li> </ul>"},{"location":"lifecycle/#part-b-operations","title":"Part B: Operations","text":""},{"location":"lifecycle/#objective_3","title":"Objective","text":"<p>Deploy and monitor the system using the full traceability chain for context-aware incident response.</p>"},{"location":"lifecycle/#deployment","title":"Deployment","text":"<ol> <li>Code is deployed through standard CI/CD pipelines</li> <li>Monitoring is configured based on the success metrics from the PRD and NFRs</li> </ol>"},{"location":"lifecycle/#context-aware-monitoring","title":"Context-Aware Monitoring","text":"<p>The AI has access to the full Knowledge Repository: - PRD (what success looks like) - DAA (domain model and invariants) - ADR (technical implementation details) - Code (actual implementation) - Bolt history (what was built when)</p> <p>When an alert fires, the AI can: - Correlate metrics to specific features and design decisions - Identify which Bolt introduced a change - Trace requirements back to the original PRD</p>"},{"location":"lifecycle/#incident-response-process","title":"Incident Response Process","text":"<p>See Operations for the complete incident handling workflow.</p> <p>High-Level Flow: 1. Alert Triggered: Production error or metric breach 2. Human Gathers Context: On-call engineer collects logs, stack traces 3. AI Correlation: AI traces error to Bolt \u2192 ADR \u2192 DAA \u2192 PRD 4. AI Proposes Fix: Based on design intent, AI suggests a Fix-It Bolt 5. Human Validates: Engineer reviews and approves 6. AI Generates Hotfix PR: Code change + updated tests + ADR amendment 7. Human Deploys: Standard CI/CD process</p>"},{"location":"lifecycle/#the-knowledge-repository-the-connecting-thread","title":"The Knowledge Repository: The Connecting Thread","text":"<p>Throughout all three phases, every artifact is stored in a centralized Knowledge Repository:</p> <pre><code>graph LR\n    PRD[PRD] --&gt; DAA[AI-DAA]\n    DAA --&gt; ADR[AI-ADR]\n    ADR --&gt; Bolt1[Bolt 1]\n    ADR --&gt; Bolt2[Bolt 2]\n    ADR --&gt; Bolt3[Bolt 3]\n    Bolt1 --&gt; Code[Production Code]\n    Bolt2 --&gt; Code\n    Bolt3 --&gt; Code\n    Code --&gt; Incident[Production Incident]\n    Incident --&gt; Postmortem[Post-mortem]\n    Postmortem --&gt; PRD</code></pre> <p>This repository enables: - Traceability: Follow any feature from business goal to deployed code - Impact Analysis: \"Which PRD features are affected by this service outage?\" - Complexity Metrics: \"How many Aggregates does this feature touch?\" - Knowledge Capture: Design decisions are never lost</p>"},{"location":"lifecycle/#lifecycle-summary","title":"Lifecycle Summary","text":"Phase Input Process Output Duration Inception PRD AI generates DAA or Engineer writes TIP Validated DAA or Draft TIP Hours to 1 day Design DAA/TIP + RFC Human-AI collaborative design Finalized AI-ADR Hours to 2 days Construction AI-ADR Break into Bolts, AI generates boilerplate Production code Days to weeks Operations Deployed code + Repository Monitor, correlate, respond Stable production + Post-mortems Ongoing <p>Next: Artifacts - Detailed specifications for each artifact type</p>"},{"location":"operations/","title":"AirSDLC Operations","text":""},{"location":"operations/#overview","title":"Overview","text":"<p>The AirSDLC framework extends beyond deployment into production operations. The same principles of AI-augmentation and end-to-end traceability that accelerate development also transform incident management from a reactive scramble into a structured, context-aware investigation.</p> <p>This document describes how to leverage the full Knowledge Repository for faster, more effective operational response.</p>"},{"location":"operations/#core-principle-context-aware-operations","title":"Core Principle: Context-Aware Operations","text":"<p>Traditional incident response: <pre><code>Alert \u2192 Engineer wakes up \u2192 Reads logs \u2192 Searches code \u2192 Guesses root cause\n\u2192 Trial-and-error fixes \u2192 Eventually resolves (hours/days)\n</code></pre></p> <p>AirSDLC incident response: <pre><code>Alert \u2192 Engineer gathers context \u2192 AI correlates to DAA/ADR/PRD \u2192 AI proposes fix\n\u2192 Human validates \u2192 AI generates Fix-It Bolt \u2192 Deploy (minutes/hours)\n</code></pre></p> <p>Key Difference: The AI has access to the entire design context, not just the code.</p>"},{"location":"operations/#the-incident-response-workflow","title":"The Incident Response Workflow","text":""},{"location":"operations/#phase-1-detection-and-triage","title":"Phase 1: Detection and Triage","text":""},{"location":"operations/#step-1-alert-fires","title":"Step 1: Alert Fires","text":"<p>Trigger: Monitoring system detects anomaly - Metric breach (error rate &gt; threshold) - Performance degradation (latency spike) - Availability issue (service down) - Business metric failure (transaction success rate drop)</p> <p>Example Alert: <pre><code>ALERT: Booking Cancel API Error Rate &gt; 5%\nSeverity: SEV-2\nTime: 2024-01-15 10:00 UTC\nAffected: POST /v1/bookings/{id}/cancel\nError Count: 150 errors in last 5 minutes\nPrimary Error: \"database connection timeout\"\n</code></pre></p>"},{"location":"operations/#step-2-human-gathers-initial-context","title":"Step 2: Human Gathers Initial Context","text":"<p>Participant: On-call Engineer (Incident Commander)</p> <p>Actions: 1. Acknowledge the alert (stop paging) 2. Assess severity:    - SEV-1: Total outage, data loss, security breach    - SEV-2: Partial outage, degraded service    - SEV-3: Non-critical issue, workaround available 3. Gather artifacts:    - Error logs from affected service (last 15 minutes)    - Stack trace of representative error    - Affected API endpoint / service name    - Recent deployments (was anything changed recently?) 4. Declare incident (notify team via Slack/PagerDuty)</p> <p>Output: Incident ticket with initial context</p> <p>Time: 5 minutes</p> <p>Example Context Package: <pre><code>## Incident INC-2024-001\n\n**Severity**: SEV-2\n**Start Time**: 2024-01-15 10:00 UTC\n**Service**: booking-service\n**Endpoint**: POST /v1/bookings/{id}/cancel\n**Error**: Database connection timeout\n\n**Stack Trace**:\n</code></pre> panic: pq: connection timeout   at booking_service.go:152 in CancelBooking()   at api_handler.go:89 in HandleCancel() <pre><code>**Recent Changes**:\n- Deploy: booking-service v1.4.2 (2 hours ago)\n- Related Bolt: BOLT-045 (Outbox relay worker)\n</code></pre></p>"},{"location":"operations/#step-3-ai-correlation-and-root-cause-hypothesis","title":"Step 3: AI Correlation and Root Cause Hypothesis","text":"<p>Participant: Engineer + AI</p> <p>Input: Context package from Step 2</p> <p>Process:</p> <p>Prompt AI: <pre><code>You are an SRE assisting with incident response. I have a production error.\nYour task is to:\n1. Correlate this error to our Knowledge Repository (Bolt, ADR, DAA, PRD)\n2. Propose a root cause hypothesis\n3. Suggest immediate mitigation steps\n\nUse the full traceability chain.\n\nIncident Context:\n[Paste incident details from Step 2]\n\nKnowledge Repository Access:\n- Stack trace shows booking_service.go:152\n- Service: booking-service\n- Endpoint: POST /v1/bookings/{id}/cancel\n\nPlease analyze.\n</code></pre></p> <p>AI Response (example): <pre><code>## Correlation Analysis\n\n**Code Location**: booking_service.go:152\n- **Bolt**: BOLT-044 (Implement Booking Cancel API)\n- **ADR**: ADR-023 (Booking Cancel with Transactional Outbox)\n- **DAA**: Section 3.2 (Booking Aggregate cancel operation)\n- **PRD**: PRD-015, User Story 2 (Cancel booking)\n\n## Root Cause Hypothesis\n\nBased on ADR-023, the cancel operation writes to two tables atomically:\n1. Update `bookings` table (status = cancelled)\n2. Insert into `booking_outbox` table (BookingCancelled event)\n\nThe error \"database connection timeout\" suggests connection pool exhaustion.\n\n**Contributing Factors**:\n- Recent deploy: BOLT-045 introduced the outbox relay worker\n- ADR-023 does NOT specify connection pool size or transaction timeout\n- If the relay worker holds connections too long, API requests starve\n\n**Evidence to Gather**:\n- Current database connection count\n- Outbox table size (is relay keeping up?)\n- Average transaction duration for cancel operations\n\n## Immediate Mitigation\n\n**Option 1** (Low Risk): Increase database connection pool size\n- Pros: Quick, no code change\n- Cons: Doesn't fix root cause if worker is leaking connections\n\n**Option 2** (Medium Risk): Restart outbox relay worker\n- Pros: Releases any held connections\n- Cons: Temporary event publish delay (5-60 seconds)\n\n**Recommended**: Option 2 (restart worker), then investigate connection leak.\n</code></pre></p> <p>Output: AI-generated triage report with hypotheses</p> <p>Time: 5-10 minutes</p>"},{"location":"operations/#phase-2-mitigation-and-stabilization","title":"Phase 2: Mitigation and Stabilization","text":""},{"location":"operations/#step-4-apply-immediate-mitigation","title":"Step 4: Apply Immediate Mitigation","text":"<p>Participant: Engineer</p> <p>Process: 1. Review AI's mitigation suggestions 2. Choose lowest-risk option for immediate relief 3. Execute mitigation 4. Monitor for impact</p> <p>Example: <pre><code># Restart outbox relay worker\nkubectl rollout restart deployment/outbox-relay-worker -n production\n\n# Monitor error rate\nwatch -n 5 'curl -s https://metrics.example.com/booking-cancel-errors'\n</code></pre></p> <p>Output: Service stabilized (error rate returns to normal)</p> <p>Time: 5-15 minutes</p>"},{"location":"operations/#step-5-validate-hypothesis-root-cause-analysis","title":"Step 5: Validate Hypothesis (Root Cause Analysis)","text":"<p>Participant: Engineer + AI</p> <p>Process:</p> <p>Once immediate crisis is over, dig deeper:</p> <ol> <li> <p>Gather evidence <pre><code># Check database connection usage\npsql -h prod-db -c \"SELECT count(*) FROM pg_stat_activity;\"\n\n# Check outbox table size\npsql -h prod-db -c \"SELECT count(*) FROM booking_outbox WHERE processed_at IS NULL;\"\n</code></pre></p> </li> <li> <p>Share findings with AI    Prompt:    <pre><code>I've mitigated the incident by restarting the worker. Here's what I found:\n- Database had 95/100 connections in use (before restart)\n- Outbox table had 8,500 unprocessed events\n- After restart, connections dropped to 15/100\n\nThis confirms your hypothesis about connection exhaustion. What was the \nroot cause in the worker implementation?\n\nWorker Code:\n[Paste BOLT-045 implementation or link to file]\n</code></pre></p> </li> <li> <p>AI identifies bug <pre><code>Root Cause Found:\n\nIn outbox_worker.go:78, the worker queries events in batches of 1000,\nbut opens a new database transaction for EACH event rather than batching\nthem. This means:\n- 1000 events = 1000 concurrent connections\n- With slow Kafka, each transaction stays open for 5-10 seconds\n- Connection pool (size 100) is quickly exhausted\n\nFix: Batch events in a single transaction or reduce batch size to 10-20.\n\nADR-023 should be amended to specify:\n- Maximum batch size for outbox relay\n- Transaction timeout requirements\n- Connection pool sizing guidelines\n</code></pre></p> </li> </ol> <p>Output: Confirmed root cause with specific code location</p> <p>Time: 15-30 minutes</p>"},{"location":"operations/#phase-3-permanent-fix","title":"Phase 3: Permanent Fix","text":""},{"location":"operations/#step-6-generate-fix-it-bolt","title":"Step 6: Generate Fix-It Bolt","text":"<p>Participant: Engineer + AI</p> <p>Process:</p> <p>Prompt AI: <pre><code>Based on the root cause analysis, generate a Fix-It Bolt to permanently \nresolve this issue. The bolt should:\n- Reduce outbox batch size from 1000 to 20\n- Add transaction timeout of 5 seconds\n- Update monitoring to alert on pending outbox size\n\nFollow our Bolt structure (BOLT ID, goal, acceptance criteria, implementation).\n\nRoot Cause:\n[Paste RCA from Step 5]\n\nAffected Code:\noutbox_worker.go\n</code></pre></p> <p>AI generates Fix-It Bolt: <pre><code>## FIX-001: Outbox Worker Connection Pool Fix\n\n**Related Incident**: INC-2024-001\n**ADR**: ADR-023 (Booking Cancel Implementation)\n**Bolt**: BOLT-045 (Outbox Relay Worker)\n\n### Root Cause\nWorker processes 1000 events concurrently, exhausting connection pool during \nslow Kafka publishing.\n\n### Fix\n1. Reduce batch size from 1000 to 20 events\n2. Add 5-second query timeout to all DB operations\n3. Add monitoring alert: `outbox_pending_events &gt; 1000`\n\n### Acceptance Criteria\n- [ ] Batch size configurable via environment variable (default: 20)\n- [ ] All DB queries have 5s context timeout\n- [ ] Alert configured in monitoring system\n- [ ] Load test shows stable connection usage under 50 concurrent cancels/sec\n- [ ] Unit tests cover timeout scenarios\n\n### Estimated Risk\n**Low**: Reduces load on database, improves reliability\n\n### Rollback Plan\nRevert to BOLT-045 original implementation (worker restart required)\n</code></pre></p> <p>Output: Fix-It Bolt specification</p> <p>Time: 15 minutes</p>"},{"location":"operations/#step-7-implement-and-deploy-fix","title":"Step 7: Implement and Deploy Fix","text":"<p>Participant: Engineer</p> <p>Process: 1. Create hotfix branch (e.g., <code>hotfix/fix-001-outbox-worker</code>) 2. Implement fixes from Fix-It Bolt 3. Run tests (unit + integration) 4. Create Pull Request (expedited review for hotfixes) 5. Get approval (pair programming or architect review) 6. Merge and deploy via CI/CD</p> <p>Output: Fix deployed to production</p> <p>Time: 1-3 hours (depending on complexity)</p>"},{"location":"operations/#step-8-validate-fix-in-production","title":"Step 8: Validate Fix in Production","text":"<p>Participant: Engineer</p> <p>Process: 1. Monitor error rates (should remain at baseline) 2. Monitor database connections (should stay well below pool limit) 3. Trigger a load test (simulate booking cancel traffic) 4. Validate outbox processes events within SLA</p> <p>Output: Confirmed fix is effective</p> <p>Time: 30 minutes - 1 hour</p>"},{"location":"operations/#phase-4-learning-and-closing-the-loop","title":"Phase 4: Learning and Closing the Loop","text":""},{"location":"operations/#step-9-write-post-mortem","title":"Step 9: Write Post-Mortem","text":"<p>Participant: Incident Commander (with team input)</p> <p>Input: All incident artifacts (timeline, RCA, fix)</p> <p>Process: Following the Post-mortem structure:</p> <ol> <li>Incident Summary: SEV level, duration, impact</li> <li>Timeline: Key events from detection to resolution</li> <li>Root Cause Analysis: What went wrong and why</li> <li>Resolution: What fixed it</li> <li>Learnings &amp; Action Items:</li> <li>What went well (AI correlation was fast)</li> <li>What could improve (ADR didn't specify connection pool guidance)</li> <li>Action Items:<ul> <li> Update ADR-023 with connection pool sizing guidelines</li> <li> Add \"Database Connection Management\" entry to Playbook</li> <li> Create load testing protocol for event-heavy features</li> </ul> </li> <li>Traceability: Link to PRD, DAA, ADR, Bolt</li> </ol> <p>Output: Post-mortem document (e.g., <code>docs/postmortems/inc-2024-001.md</code>)</p> <p>Time: 1-2 hours</p>"},{"location":"operations/#step-10-update-knowledge-repository","title":"Step 10: Update Knowledge Repository","text":"<p>Participant: Architect or Senior Engineer</p> <p>Process:</p> <p>10.1 Amend ADR Since the original ADR-023 lacked guidance on connection management, create an amendment:</p> <pre><code>## ADR-023: Booking Cancel Implementation (Amendment 1)\n\n**Date**: 2024-01-15\n**Reason**: Post-incident learning from INC-2024-001\n\n### Added Guidance\n\n**Database Connection Management**:\n- Outbox relay batch size: 20 events (configurable)\n- All database operations: 5-second timeout\n- Connection pool sizing: `num_api_instances * 10 + num_workers * 5`\n- Monitoring: Alert if `outbox_pending_events &gt; 1000`\n\n**Rationale**: Incident INC-2024-001 revealed that large batch sizes (1000)\ncombined with slow Kafka publishing caused connection pool exhaustion. This\nguidance prevents recurrence.\n\n**References**: \n- Post-mortem: postmortems/inc-2024-001.md\n- Fix-It Bolt: FIX-001\n</code></pre> <p>10.2 Add Playbook Entry Create a new pattern for future engineers:</p> <pre><code>## PLAYBOOK-015: Database Connection Management for Event-Driven Services\n\n### Problem\nServices that write to a database AND publish events (e.g., using Transactional\nOutbox) can exhaust connection pools if not sized correctly.\n\n### Context\nUse when:\n- Service has both sync API and async workers\n- Event publishing has variable latency (e.g., Kafka is slow)\n- Multiple instances of workers are deployed\n\n### Solution\n1. **Size connection pool**: `API_instances * concurrent_requests_per_instance + workers * batch_size`\n2. **Set query timeouts**: 5-10 seconds for all DB operations\n3. **Limit worker batch size**: 10-50 events per batch\n4. **Monitor**: Alert on `active_connections &gt; 80% of pool_size`\n\n### Trade-offs\n- Smaller batch sizes \u2192 Higher worker overhead, but safer\n- Larger batch sizes \u2192 More efficient, but risk of connection exhaustion\n\n### Checklist\n- [ ] Connection pool sized based on formula\n- [ ] All queries have context deadline\n- [ ] Worker batch size configurable (for tuning)\n- [ ] Connection usage monitored and alerted\n\n### Example\nADR-023 (as amended after INC-2024-001)\n</code></pre> <p>Output: Updated Knowledge Repository</p> <p>Time: 1-2 hours</p>"},{"location":"operations/#step-11-resolve-incident","title":"Step 11: Resolve Incident","text":"<p>Participant: Incident Commander</p> <p>Process: 1. Mark incident as \"Resolved\" in incident management system 2. Share post-mortem with team (Slack, email, or meeting) 3. Schedule post-mortem review (optional, for major incidents) 4. Celebrate learnings (not blame)</p> <p>Output: Incident closed, team knowledge increased</p>"},{"location":"operations/#incident-response-diagram","title":"Incident Response Diagram","text":"<pre><code>graph TD\n    A[Alert Fires] --&gt; B[Engineer Gathers Context]\n    B --&gt; C[AI Correlates to DAA/ADR/PRD]\n    C --&gt; D[AI Proposes Root Cause + Mitigation]\n    D --&gt; E{Service Stable?}\n    E --&gt;|No| F[Apply Immediate Mitigation]\n    F --&gt; E\n    E --&gt;|Yes| G[Validate Root Cause]\n    G --&gt; H[AI Generates Fix-It Bolt]\n    H --&gt; I[Implement &amp; Deploy Fix]\n    I --&gt; J[Validate Fix in Production]\n    J --&gt; K[Write Post-Mortem]\n    K --&gt; L[Update Knowledge Repository]\n    L --&gt; M[Resolve Incident]</code></pre>"},{"location":"operations/#key-operational-metrics","title":"Key Operational Metrics","text":""},{"location":"operations/#response-time-metrics","title":"Response Time Metrics","text":"Metric Traditional SDLC AirSDLC Goal Time to Triage 15-30 min 5-10 min Time to Mitigation 1-4 hours 15-30 min Time to Root Cause 4-24 hours 30 min - 2 hours Time to Permanent Fix 1-3 days 2-8 hours Mean Time to Resolution (MTTR) 4-48 hours 3-12 hours"},{"location":"operations/#quality-metrics","title":"Quality Metrics","text":"Metric Description Target Incident Recurrence Rate % of incidents that repeat within 30 days &lt; 10% Post-Mortem Completion Rate % of incidents with completed post-mortem 100% for SEV-\u00bd Knowledge Repository Updates # of Playbook/ADR updates per incident \u2265 1 per major incident Fix Quality % of fixes that resolve issue permanently &gt; 90%"},{"location":"operations/#operational-best-practices","title":"Operational Best Practices","text":""},{"location":"operations/#1-proactive-monitoring-setup","title":"1. Proactive Monitoring Setup","text":"<p>During Phase 3 (Construction), ensure every ADR includes: - Metrics to Track: What indicates health? - Alert Thresholds: When to wake someone up? - Dashboards: Visual representation of service health</p> <p>Example from ADR-023: <pre><code>## Monitoring &amp; Observability\n\n**Metrics**:\n- `booking_cancel_requests_total` (counter)\n- `booking_cancel_duration_seconds` (histogram)\n- `outbox_pending_events` (gauge)\n- `database_connections_active` (gauge)\n\n**Alerts**:\n- Cancel API error rate &gt; 1% for 5 minutes \u2192 SEV-2\n- Outbox pending events &gt; 1000 \u2192 SEV-3\n- Database connections &gt; 80% of pool \u2192 SEV-3\n\n**Dashboards**:\n- Booking Operations: Cancel rates, latency percentiles\n- Event Publishing: Outbox lag, Kafka publish success rate\n</code></pre></p>"},{"location":"operations/#2-runbook-integration","title":"2. Runbook Integration","text":"<p>For each ADR, create an operational runbook: <pre><code>## Runbook: Booking Cancel API (ADR-023)\n\n### Common Issues\n\n**Issue**: High error rate on cancel endpoint\n**Symptoms**: `booking_cancel_errors` alert firing\n**Triage Steps**:\n1. Check database connection count\n2. Check outbox pending event count\n3. Review recent deployments\n**Escalation**: If DB connections &gt; 90%, page DBA team\n\n**Issue**: Slow cancel operations\n**Symptoms**: `booking_cancel_duration_seconds` p99 &gt; 2s\n**Triage Steps**:\n1. Check Kafka broker health\n2. Check outbox relay worker status\n3. Review database query performance\n**Escalation**: If Kafka is down, page Platform team\n</code></pre></p>"},{"location":"operations/#3-game-day-exercises","title":"3. Game Day Exercises","text":"<p>Periodically test incident response: 1. Simulate production incidents in staging 2. Measure response time 3. Validate AI correlation works correctly 4. Practice generating Fix-It Bolts under pressure</p> <p>Example Scenarios: - Database connection pool exhaustion - Kafka broker failure (event publishing blocked) - API rate limiting triggered - Data corruption (violates domain invariant)</p>"},{"location":"operations/#4-on-call-handoff-protocol","title":"4. On-Call Handoff Protocol","text":"<p>When rotating on-call: - Share Context: Recent incidents, ongoing issues - Review Recent ADRs: What changed in production recently? - Test AI Access: Ensure new on-call engineer can access Knowledge Repository - Practice Prompts: Have templates ready for AI correlation</p>"},{"location":"operations/#leveraging-the-knowledge-repository","title":"Leveraging the Knowledge Repository","text":""},{"location":"operations/#context-rich-debugging","title":"Context-Rich Debugging","text":"<p>When investigating a bug, use the full traceability chain:</p> <pre><code>Error Message\n   \u2193 (find in code)\nCode Line (e.g., booking_service.go:152)\n   \u2193 (git blame or Bolt log)\nBolt (e.g., BOLT-044: Implement Booking Cancel API)\n   \u2193 (Bolt references ADR)\nADR (e.g., ADR-023: Booking Cancel with Outbox Pattern)\n   \u2193 (ADR references DAA)\nDAA (e.g., Section 3.2: Booking Aggregate)\n   \u2193 (DAA references PRD)\nPRD (e.g., PRD-015, User Story 2: Cancel booking)\n</code></pre> <p>Benefit: Understand not just WHAT broke, but WHY it was built that way and WHAT business value it provides.</p>"},{"location":"operations/#ai-powered-impact-analysis","title":"AI-Powered Impact Analysis","text":"<p>Prompt AI: <pre><code>I need to perform emergency maintenance on the booking-service database.\nThis will cause 15 minutes of downtime for the /bookings endpoints.\n\nUsing the Knowledge Repository, identify:\n1. Which PRD features will be impacted?\n2. Which business KPIs will be affected?\n3. Which user stories will be blocked?\n4. What's the estimated business impact (revenue, user complaints)?\n</code></pre></p> <p>AI can correlate database \u2192 services \u2192 ADRs \u2192 DAAs \u2192 PRDs \u2192 business metrics.</p>"},{"location":"operations/#summary-the-operational-advantage","title":"Summary: The Operational Advantage","text":"<p>AirSDLC transforms operations from reactive firefighting to proactive, context-aware incident management:</p> <ol> <li>Faster Triage: AI correlates errors to design decisions in minutes</li> <li>Better Fixes: Understanding design intent leads to correct fixes, not workarounds</li> <li>Continuous Learning: Post-mortems feed back into Playbook and ADRs</li> <li>Reduced MTTR: Context-rich debugging eliminates guesswork</li> </ol> <p>The same AI that accelerates development now accelerates operational excellence.</p> <p>Next: Extensibility - How to adapt and extend the framework</p>"},{"location":"overview/","title":"AirSDLC Overview","text":""},{"location":"overview/#introduction","title":"Introduction","text":"<p>The AI-Responsible Software Development Lifecycle (AirSDLC) is an actionable framework for AI-driven software development. It provides a structured methodology for transforming ambiguous business requirements into production-ready code through a series of validated, traceable artifacts.</p>"},{"location":"overview/#the-problem-airsdlc-solves","title":"The Problem AirSDLC Solves","text":"<p>Traditional software development faces several persistent challenges:</p> <ul> <li>Requirements Gap: Business intent often gets lost in translation to technical implementation</li> <li>Premature Technical Decisions: Teams jump to \"how\" before fully understanding \"what\"</li> <li>Documentation Debt: Design decisions are poorly documented or quickly become stale</li> <li>Context Loss: When bugs occur, engineers lack the full context from inception to deployment</li> <li>Inconsistent Processes: Different teams solve the same architectural problems differently</li> </ul> <p>AirSDLC addresses these challenges by formalizing a structured, AI-augmented process with built-in traceability and validation.</p>"},{"location":"overview/#core-concept-ai-driven-with-human-oversight","title":"Core Concept: AI-Driven with Human Oversight","text":"<p>AirSDLC inverts the traditional human-AI relationship in software development:</p> <ul> <li>Traditional Model: Human writes code \u2192 AI assists with completion</li> <li>AirSDLC Model: AI generates artifacts \u2192 Human validates and directs</li> </ul> <p>In this model: - AI's Role: Generate plans, model domains, propose solutions, identify risks - Human's Role: Validate outputs, make strategic decisions, provide domain expertise, give final approval</p> <p>This shift moves the human expert from creator to curator\u2014a higher-leverage position that focuses cognitive energy on evaluation rather than generation.</p>"},{"location":"overview/#the-three-sequential-phases","title":"The Three Sequential Phases","text":"<p>AirSDLC is built on a sequential knowledge handoff where each phase enriches context for the next:</p> <pre><code>Business Intent \u2192 Inception \u2192 Design \u2192 Construction &amp; Operations\n                     \u2193           \u2193              \u2193\n                   AI-DAA     AI-ADR      Production Code\n</code></pre>"},{"location":"overview/#phase-1-inception-the-what","title":"Phase 1: Inception (The \"WHAT\")","text":"<p>Objective: Translate business goals into a pure, technology-agnostic domain model</p> <ul> <li>Input: Business Intent / Product Requirements Document (PRD)</li> <li>Process: AI analyzes requirements and applies Domain-Driven Design (DDD) patterns</li> <li>Output: AI-DAA (Domain Architecture Analysis) - a vendor-neutral domain model</li> <li>Validation: Human expert reviews and validates the domain understanding</li> </ul>"},{"location":"overview/#phase-2-collaborative-design-the-how","title":"Phase 2: Collaborative Design (The \"HOW\")","text":"<p>Objective: Synthesize domain understanding with technical implementation decisions</p> <ul> <li>Input: Validated AI-DAA + Engineer's RFC (Request for Comments)</li> <li>Process: Human-AI collaborative \"Socratic Sparring\" session using Architectural Playbook</li> <li>Output: AI-ADR (Architectural Decision Record) - finalized technical decisions</li> <li>Validation: Human architect approves architectural choices and trade-offs</li> </ul>"},{"location":"overview/#phase-3-construction-operations-the-build-run","title":"Phase 3: Construction &amp; Operations (The \"BUILD &amp; RUN\")","text":"<p>Objective: Generate code, deploy, and provide context-aware monitoring</p> <ul> <li>Input: Finalized AI-ADR</li> <li>Process: Break work into \"Bolts\" (focused implementation units), AI generates boilerplate</li> <li>Output: Production-ready code, tests, and deployment artifacts</li> <li>Operations: Context-aware incident response using full traceability chain</li> </ul>"},{"location":"overview/#key-principles","title":"Key Principles","text":""},{"location":"overview/#1-technology-agnosticism-in-domain-modeling","title":"1. Technology Agnosticism in Domain Modeling","text":"<p>The AI-DAA is intentionally 100% technology-neutral. It describes the business domain using DDD patterns without specifying databases, frameworks, or languages. This ensures domain understanding is not polluted by technical constraints.</p>"},{"location":"overview/#2-sequential-knowledge-handoff","title":"2. Sequential Knowledge Handoff","text":"<p>Each phase's validated output becomes the non-negotiable input for the next. This creates an unbroken chain of traceability:</p> <pre><code>Business Goal \u2192 PRD Feature \u2192 DAA Aggregate \u2192 ADR Decision \u2192 Code Implementation\n</code></pre>"},{"location":"overview/#3-validation-as-first-class-activity","title":"3. Validation as First-Class Activity","text":"<p>Validation is never skipped. Every AI-generated artifact passes through human review before proceeding. This includes: - PRD-to-DAA Coverage: Does the domain model address all requirements? - DAA-to-ADR Alignment: Do technical decisions respect domain invariants? - ADR-to-Code Compliance: Does implementation match the design?</p>"},{"location":"overview/#4-pragmatism-adaptability","title":"4. Pragmatism &amp; Adaptability","text":"<p>AirSDLC provides two workflow paths: - Full Workflow: PRD \u2192 AI-DAA \u2192 RFC \u2192 AI-ADR (for complex/risky features) - Lightweight Workflow: PRD \u2192 TIP \u2192 RFC \u2192 AI-ADR (for simple/well-understood features)</p> <p>Teams choose based on feature complexity, risk, and domain familiarity.</p>"},{"location":"overview/#5-living-knowledge-repository","title":"5. Living Knowledge Repository","text":"<p>All artifacts are stored in a \"Knowledge Repository\" that serves as the single source of truth. This repository enables: - End-to-end traceability - Context-aware operations - AI-powered analysis and reporting - Post-mortem correlation</p>"},{"location":"overview/#core-artifacts","title":"Core Artifacts","text":"<p>AirSDLC defines several key artifact types:</p> Artifact Purpose Phase Technology-Specific? PRD Business requirements Inception No AI-DAA Domain model (DDD-based) Inception No TIP Technical proposal (lightweight) Inception Yes RFC Design discussion forum Design Yes AI-ADR Finalized architecture decisions Design Yes Bolt Discrete implementation unit Construction Yes Playbook Library of approved patterns Design (reference) Yes <p>See Artifacts for detailed specifications.</p>"},{"location":"overview/#the-workflow-at-a-glance","title":"The Workflow at a Glance","text":"<pre><code>graph TD\n    A[Business Intent/PRD] --&gt; B{Complex Feature?}\n    B --&gt;|Yes| C[Generate AI-DAA]\n    B --&gt;|No| D[Write TIP]\n    C --&gt; E[Create RFC]\n    D --&gt; E\n    E --&gt; F[Collaborative Design Session]\n    F --&gt; G[Consult Playbook]\n    G --&gt; H[AI as Socratic Partner]\n    H --&gt; I[Generate AI-ADR]\n    I --&gt; J[Break into Bolts]\n    J --&gt; K[Generate Code]\n    K --&gt; L[Deploy &amp; Monitor]</code></pre> <p>See Workflow for step-by-step details.</p>"},{"location":"overview/#benefits","title":"Benefits","text":""},{"location":"overview/#for-engineering-teams","title":"For Engineering Teams","text":"<ul> <li>Faster Design Cycles: AI generates first drafts, humans focus on validation</li> <li>Better Documentation: Design decisions are captured by default, not as an afterthought</li> <li>Consistent Patterns: Architectural Playbook ensures team-wide consistency</li> <li>Reduced Context Switching: Full traceability from business goal to code</li> </ul>"},{"location":"overview/#for-architects","title":"For Architects","text":"<ul> <li>Strategic Focus: Spend time on high-level decisions, not boilerplate</li> <li>Knowledge Capture: Architectural wisdom is codified in reusable patterns</li> <li>AI-Augmented Review: AI challenges designs using organizational knowledge</li> </ul>"},{"location":"overview/#for-operations","title":"For Operations","text":"<ul> <li>Context-Rich Debugging: Correlate production errors to DAA/ADR/PRD</li> <li>Faster MTTR: AI proposes fixes using full design context</li> <li>Post-Mortem Integration: Learnings feed back into Knowledge Repository</li> </ul>"},{"location":"overview/#for-product-teams","title":"For Product Teams","text":"<ul> <li>Requirements Validation: AI-generated DAA surfaces misunderstandings early</li> <li>Traceability: Track which features map to which technical components</li> <li>Predictable Estimates: Complexity metrics based on domain model</li> </ul>"},{"location":"overview/#framework-vs-implementation","title":"Framework vs. Implementation","text":"<p>Important Distinction: - AirSDLC (this repository): The framework specification, manifesto, and guidelines - Implementation Tools: Concrete software that implements the framework</p> <p>This separation ensures: - Multiple implementations can exist - The framework evolves independently from tools - Teams can adapt implementations to their needs while maintaining conformance</p>"},{"location":"overview/#next-steps","title":"Next Steps","text":"<ul> <li>Understand the Foundation: Read Philosophy for core AI-DLC principles</li> <li>Learn the Process: Study Workflow for practical guidance</li> <li>Explore Artifacts: Review Artifacts for detailed specifications</li> <li>See Examples: Browse Examples for sample artifacts</li> </ul>"},{"location":"overview/#extensibility","title":"Extensibility","text":"<p>AirSDLC is designed to be extended. Teams can: - Add custom artifact types - Define additional validation steps - Integrate domain-specific patterns into the Playbook - Customize templates and workflows</p> <p>See Extensibility for guidelines on adapting the framework.</p> <p>Next: Philosophy - Core principles and AI-DLC foundation</p>"},{"location":"philosophy/","title":"AirSDLC Philosophy","text":""},{"location":"philosophy/#the-foundation-aws-ai-dlc-principles","title":"The Foundation: AWS AI-DLC Principles","text":"<p>The AirSDLC is a practical, open-source implementation of the AI-Driven Development Lifecycle (AI-DLC) framework developed by Amazon Web Services. </p> <p>The AI-DLC was introduced by Raja SP, Principal Solutions Architect at AWS, as \"an AI-centric transformative approach to software development\" designed to fully integrate AI capabilities into the fabric of software development.</p> <p>Note: For complete information about the original AWS AI-DLC framework, see the official AWS blog post and the AI-DLC white paper. For attribution details, see AI-DLC-ATTRIBUTION.md.</p> <p>To understand AirSDLC's design, it's essential to understand the foundational AI-DLC principles from which it derives.</p>"},{"location":"philosophy/#the-core-paradigm-ai-driven-execution-with-human-oversight","title":"The Core Paradigm: AI-Driven Execution with Human Oversight","text":"<p>Traditional software development treats AI as an assistant to humans. The AI-DLC\u2014and by extension, AirSDLC\u2014inverts this relationship:</p> <p>AI is the primary executor. Humans are the validators and strategic decision-makers.</p> <p>This paradigm shift has profound implications:</p> Traditional SDLC AI-DLC / AirSDLC Human creates artifacts AI generates artifacts AI assists with code completion AI proposes complete designs Human is the bottleneck AI is the accelerator Validation is optional Validation is mandatory Documentation is an afterthought Documentation is generated by default <p>The human expert's cognitive load shifts from creation to evaluation\u2014a much higher-leverage activity.</p>"},{"location":"philosophy/#core-ai-dlc-concepts","title":"Core AI-DLC Concepts","text":""},{"location":"philosophy/#1-the-three-sequential-phases","title":"1. The Three Sequential Phases","text":"<p>AI-DLC defines a strict \"sequential knowledge handoff\" across three distinct phases. Each phase's validated output becomes the non-negotiable input for the next:</p> <ol> <li>Inception: The \"WHAT and WHY\" phase</li> <li>Translates <code>Business Intent</code> into a locked, buildable contract</li> <li> <p>Output: A validated domain model (Unit of Work)</p> </li> <li> <p>Construction: The \"HOW\" phase</p> </li> <li>Transforms the contract into tested, deployable software artifacts</li> <li> <p>Output: Validated designs and production code (Deployment Unit)</p> </li> <li> <p>Operation: The \"MAINTAIN\" phase</p> </li> <li>Deploys, monitors, and fixes software using full context</li> <li>Output: Context-aware incident response (Fix-It Bolts)</li> </ol>"},{"location":"philosophy/#2-the-core-artifacts","title":"2. The Core Artifacts","text":"<p>AI-DLC defines specific artifact types that flow through the lifecycle:</p>"},{"location":"philosophy/#unit-of-work-uow","title":"Unit of Work (UOW)","text":"<p>The primary container for a major piece of functionality, replacing the traditional \"Epic.\" It is the main output of the Inception phase.</p> <p>Mandatory Core Composition (the five \"problem-defining\" artifacts): 1. PR/FAQ (Press Release / Frequently Asked Questions) 2. User Stories 3. Non-Functional Requirements (NFRs) 4. Risk Descriptions 5. Measurement Criteria</p> <p>Extensibility: Custom artifacts (e.g., Sequence Diagrams, Domain Models) can be added, but the five core artifacts are mandatory.</p>"},{"location":"philosophy/#bolt","title":"Bolt","text":"<p>A \"single workable unit that only has a single goal,\" replacing the traditional \"Sprint.\" Bolts are sequential, tactical steps to build a UOW, measured in hours or days.</p> <p>Core Composition (the \"solution-defining\" artifacts): 1. Validated Logical Design &amp; Architecture Decision Records (ADRs) 2. Generated Code &amp; Comprehensive Test Suite 3. Deployment Unit</p>"},{"location":"philosophy/#deployment-unit","title":"Deployment Unit","text":"<p>The final, \"operations-ready\" package from the Construction phase, containing code, tests, and Infrastructure-as-Code (IaC) configurations.</p>"},{"location":"philosophy/#fix-it-bolt","title":"Fix-It Bolt","text":"<p>A special, micro-sized Bolt generated by AI for bug fixing during the Operation phase. It follows a structured process: Root Cause Analysis (RCA) \u2192 Proposal \u2192 Validation \u2192 Execution.</p>"},{"location":"philosophy/#3-the-core-rituals","title":"3. The Core Rituals","text":"<p>AI-DLC mandates specific \"Mob\" collaborations that serve as human-in-the-loop validation gates. These are synchronous, collaborative sessions:</p>"},{"location":"philosophy/#mob-elaboration-inception","title":"Mob Elaboration (Inception)","text":"<ul> <li>Participants: Cross-functional team (Product, Engineering, Domain Experts)</li> <li>Purpose: Review, refine, and validate the AI-generated draft UOW</li> <li>Output: Validated Unit of Work</li> <li>Cadence: As-needed for new major features</li> </ul>"},{"location":"philosophy/#mob-construction-construction","title":"Mob Construction (Construction)","text":"<ul> <li>Participants: Technical team (Architects, Senior Engineers)</li> <li>Purpose: Review and validate AI's proposed architecture and ADRs for a Bolt before code generation</li> <li>Output: Validated Logical Design &amp; ADRs</li> <li>Cadence: Before starting each Bolt</li> </ul>"},{"location":"philosophy/#continuous-oversight-operation","title":"Continuous Oversight (Operation)","text":"<ul> <li>Participants: On-call team, SRE</li> <li>Purpose: Expedited validation of AI-proposed operational actions (deployments, fixes, scaling)</li> <li>Output: Go/No-Go decision on production changes</li> <li>Cadence: Real-time during incidents or deployments</li> </ul>"},{"location":"philosophy/#4-the-foundational-interaction-loop","title":"4. The Foundational Interaction Loop","text":"<p>Underpinning all AI-DLC rituals is a four-stage cycle that defines the human-AI partnership:</p> <pre><code>1. [AI] Propose &amp; Decompose\n   \u2193\n2. [AI \u2192 Human] Clarify &amp; Question\n   \u2193\n3. [Human] Validate &amp; Direct\n   \u2193\n4. [AI] Implement &amp; Update\n   \u2193\n   (Loop repeats)\n</code></pre> <p>Stage 1: Propose &amp; Decompose The AI analyzes input and creates a detailed plan or artifact.</p> <p>Stage 2: Clarify &amp; Question The AI actively seeks context, identifies ambiguities, and defers critical decisions to humans.</p> <p>Stage 3: Validate &amp; Direct The \"Mob\" (human expert or team) provides judgment, makes strategic decisions, and gives approval or refinement feedback.</p> <p>Stage 4: Implement &amp; Update Only after validation, the AI executes the plan and generates final artifacts.</p> <p>This loop ensures that AI never proceeds with critical decisions without human oversight.</p>"},{"location":"philosophy/#airsdlcs-interpretation-of-ai-dlc","title":"AirSDLC's Interpretation of AI-DLC","text":"<p>AirSDLC takes these theoretical AI-DLC concepts and makes them actionable for real-world software teams. Here's how AirSDLC interprets and extends the core framework:</p>"},{"location":"philosophy/#the-unit-of-work-validated-ai-daa","title":"The \"Unit of Work\" \u2192 Validated AI-DAA","text":"<p>In formal AI-DLC, the <code>Unit of Work (UOW)</code> is an abstract container for problem-defining artifacts. In AirSDLC, this is concretely represented by:</p> <ul> <li>AI-PRD (AI-generated Product Requirements Document) - Contains User Stories, NFRs, Risks, Success Metrics</li> <li>AI-DAA (Domain Architecture Analysis) - The technology-agnostic domain model using DDD patterns</li> </ul> <p>Together, these form the Validated Unit of Work that locks in the \"what\" before proceeding to \"how.\"</p>"},{"location":"philosophy/#mob-elaboration-inception-phase-validation","title":"\"Mob Elaboration\" \u2192 Inception Phase Validation","text":"<p>The AI-DLC \"Mob Elaboration\" ritual is implemented in AirSDLC's Phase 1: Inception. After the AI generates the AI-PRD and AI-DAA:</p> <ul> <li>The architect/team reviews for domain accuracy</li> <li>The AI is prompted to generate a \"Coverage Report\" (does the DAA address all PRD requirements?)</li> <li>The human validates or requests refinement</li> <li>Once approved, the DAA is locked as the input to Phase 2</li> </ul>"},{"location":"philosophy/#mob-construction-collaborative-design-session","title":"\"Mob Construction\" \u2192 Collaborative Design Session","text":"<p>The AI-DLC \"Mob Construction\" ritual is the heart of AirSDLC's Phase 2: Collaborative Design. This is where the framework introduces a unique pattern:</p> <p>The AI as \"Socratic Sparring Partner\"</p> <p>Instead of a traditional design review, the human architect engages in an active dialogue with the AI:</p> <ol> <li>The architect provides the DAA and an initial RFC</li> <li>The architect prompts the AI to challenge the design using patterns from the Architectural Playbook</li> <li>The AI asks probing questions, proposes alternatives, and analyzes trade-offs</li> <li>The human refines the design iteratively</li> <li>Once robust, the AI generates the finalized AI-ADR</li> </ol> <p>This is not passive code review\u2014it's active, AI-augmented design thinking.</p>"},{"location":"philosophy/#bolts-actionable-adr-components","title":"\"Bolts\" \u2192 Actionable ADR Components","text":"<p>In AirSDLC, a Bolt corresponds to a discrete, implementable component from the finalized AI-ADR. For example:</p> <ul> <li>ADR: \"Implement a Room Booking System with an Outbox Pattern\"</li> <li>Bolt 1: \"Create the <code>POST /bookings</code> API endpoint\"</li> <li>Bolt 2: \"Implement the Outbox relay worker for booking events\"</li> <li>Bolt 3: \"Add monitoring for booking conflicts and availability checks\"</li> </ul> <p>Each Bolt is small enough to complete in hours or days, making progress visible and reducing risk.</p>"},{"location":"philosophy/#continuous-oversight-context-aware-operations","title":"\"Continuous Oversight\" \u2192 Context-Aware Operations","text":"<p>AirSDLC extends AI-DLC's operational vision by leveraging the full traceability chain. When a production incident occurs:</p> <ol> <li>The AI correlates the error to the specific Bolt, ADR, DAA, and PRD</li> <li>It provides a \"Triage Summary\" with full context</li> <li>It proposes a Fix-It Bolt (hotfix) based on design intent</li> <li>The human validates and approves deployment</li> </ol> <p>This transforms on-call from a manual scramble into a structured, AI-assisted investigation.</p>"},{"location":"philosophy/#key-philosophical-decisions-in-airsdlc","title":"Key Philosophical Decisions in AirSDLC","text":""},{"location":"philosophy/#1-domain-driven-design-as-the-modeling-language","title":"1. Domain-Driven Design as the Modeling Language","text":"<p>AirSDLC adopts Domain-Driven Design (DDD) as the standard for domain modeling. Why DDD?</p> <ul> <li>Business-Centric: DDD focuses on the core business logic, not technical implementation</li> <li>Ubiquitous Language: Ensures shared understanding between domain experts and developers</li> <li>Strategic Boundaries: Bounded Contexts and Context Maps manage complexity</li> <li>AI-Friendly: Structured patterns (Aggregates, Entities, Value Objects, Domain Events) are explicit and machine-readable</li> </ul> <p>The AI can be trained to identify and generate DDD patterns from a well-structured PRD, making the Inception phase highly automatable.</p>"},{"location":"philosophy/#2-technology-agnosticism-in-the-daa","title":"2. Technology Agnosticism in the DAA","text":"<p>A critical principle: The AI-DAA is 100% technology-neutral.</p> <p>It describes the business domain using pseudocode and DDD patterns without specifying: - Databases (SQL, NoSQL, etc.) - Programming languages (Go, Python, Java, etc.) - Frameworks (Spring, Django, Express, etc.) - Deployment platforms (AWS, GCP, Kubernetes, etc.)</p> <p>Rationale: This ensures domain understanding is not polluted by technical constraints. A single DAA can be implemented as a Python monolith or as Golang microservices\u2014the business logic remains the same.</p>"},{"location":"philosophy/#3-pragmatism-over-dogma","title":"3. Pragmatism Over Dogma","text":"<p>While AI-DLC provides a comprehensive framework, AirSDLC recognizes that context matters. Not every feature requires the full ceremony.</p> <p>AirSDLC introduces the Hybrid Model: - Full Workflow (PRD \u2192 AI-DAA \u2192 RFC \u2192 AI-ADR): For complex, high-risk, or unfamiliar domains - Lightweight Workflow (PRD \u2192 TIP \u2192 RFC \u2192 AI-ADR): For simple, well-understood features</p> <p>The decision is based on a simple matrix considering: - Feature complexity - Team maturity - Timeline pressure - Risk level</p> <p>Non-Negotiable: Validation is never skipped, regardless of workflow choice.</p>"},{"location":"philosophy/#4-validation-as-a-first-class-activity","title":"4. Validation as a First-Class Activity","text":"<p>In AirSDLC, validation is not an afterthought\u2014it is a mandatory gate at every phase:</p> <ul> <li>PRD-to-DAA Coverage: Does the domain model address all requirements?</li> <li>DAA-to-ADR Alignment: Do technical decisions respect domain invariants?</li> <li>ADR-to-Code Compliance: Does implementation match the design?</li> </ul> <p>AI-driven validation reports make this fast and consistent, turning what was once a manual checklist into an automated safety net.</p>"},{"location":"philosophy/#5-the-knowledge-repository-as-the-central-artifact","title":"5. The Knowledge Repository as the Central Artifact","text":"<p>Traditional SDLCs produce: - Code (in version control) - Documentation (in wikis, often stale) - Decisions (in meeting notes or people's heads)</p> <p>AirSDLC produces a single, interconnected Knowledge Repository: - All artifacts (PRD, DAA, RFC, ADR, Bolts) are stored and linked - The repository is machine-readable and queryable - It serves as the \"brain\" for AI-driven operations - Post-mortems feed back into the repository, closing the learning loop</p> <p>This repository is not just documentation\u2014it is the single source of truth for the entire system.</p>"},{"location":"philosophy/#the-virtuous-cycle-of-knowledge","title":"The Virtuous Cycle of Knowledge","text":"<p>AirSDLC creates a feedback loop between development and operations:</p> <pre><code>Design (Writes to Repository)\n   \u2193\n[Knowledge Repository]\n   \u2193\nOperations (Reads from Repository)\n   \u2193\nPost-Mortems (Write back to Repository)\n   \u2193\nFuture Design (Informed by operational learnings)\n</code></pre> <p>This cycle ensures that: - Design decisions inform operations - Operational learnings improve future designs - Architectural knowledge compounds over time</p>"},{"location":"philosophy/#summary-the-airsdlc-mindset","title":"Summary: The AirSDLC Mindset","text":"<p>To successfully adopt AirSDLC, teams must embrace a fundamental mindset shift:</p> <ol> <li>Trust AI to Generate: Let AI create first drafts of domain models, designs, and code</li> <li>Validate Rigorously: Human expertise focuses on evaluation, not creation</li> <li>Model Before Implementing: Invest in understanding the \"what\" before deciding \"how\"</li> <li>Capture Knowledge: Treat documentation as a first-class artifact, not a chore</li> <li>Trace Everything: Maintain an unbroken chain from business goal to code</li> <li>Learn Continuously: Feed operational insights back into design knowledge</li> </ol> <p>The result is faster development, better designs, and more maintainable systems.</p> <p>Next: Lifecycle - The three phases in detail</p>"},{"location":"philosophy/#references","title":"References","text":""},{"location":"philosophy/#original-aws-ai-dlc-framework","title":"Original AWS AI-DLC Framework","text":"<ul> <li>AWS Blog Post: AI-Driven Development Life Cycle: Reimagining Software Engineering</li> <li>White Paper: https://prod.d13rzhkk8cj2z0.amplifyapp.com/</li> <li>Author: Raja SP, Principal Solutions Architect, AWS</li> <li>Published: July 31, 2025</li> </ul> <p>Attribution: The AI-DLC methodology is \u00a9 Amazon Web Services, Inc. AirSDLC is an independent, open-source implementation of the AI-DLC framework.</p> <p>Next: Lifecycle - The three phases in detail</p>"},{"location":"workflow/","title":"AirSDLC Workflow","text":""},{"location":"workflow/#overview","title":"Overview","text":"<p>This document provides a practical, step-by-step guide to applying the AirSDLC framework. It walks through the complete workflow from receiving a new business requirement to deploying production-ready code.</p>"},{"location":"workflow/#workflow-diagram","title":"Workflow Diagram","text":"<pre><code>graph TD\n    subgraph \"Phase 1: Inception\"\n        A[Start: New Business Intent/PRD] --&gt; B{Complex or High-Risk Feature?}\n        B -- Yes --&gt; C[Full Workflow: Generate AI-DAA]\n        B -- No --&gt; D[Lightweight Workflow: Engineer writes TIP]\n        C --&gt; E[Validated DAA]\n        D --&gt; F[Draft TIP]\n    end\n\n    subgraph \"Phase 2: Collaborative Design\"\n        E --&gt; G(Input: DAA + Engineer's RFC)\n        F --&gt; G\n        G --&gt; H[Start Collaborative Discussion]\n        H --&gt; I{Consult Architectural Playbook}\n        I --&gt; J[Engage AI as Socratic Sparring Partner]\n        J --&gt; K[Challenge, Visualize, and Refine Design]\n        K --&gt; L[Finalize Design]\n    end\n\n    subgraph \"Phase 3: Finalization &amp; Construction\"\n        L --&gt; M[Generate Final AI-ADR]\n        M --&gt; N[Execute Bolts: Generate Code from ADR]\n        N --&gt; O((End: Production-Ready Code))\n    end</code></pre>"},{"location":"workflow/#detailed-step-by-step-process","title":"Detailed Step-by-Step Process","text":""},{"location":"workflow/#phase-1-inception","title":"Phase 1: Inception","text":""},{"location":"workflow/#step-1-receive-and-review-prd","title":"Step 1: Receive and Review PRD","text":"<p>Participants: Product Manager, Lead Engineer, Architect</p> <p>Input: New Product Requirements Document (PRD)</p> <p>Actions: 1. Read the PRD thoroughly    - Understand the business objective    - Review user stories and acceptance criteria    - Note NFRs (performance, availability, security)    - Identify constraints (timeline, budget, technical)</p> <ol> <li>Clarify ambiguities</li> <li>Schedule a quick sync with PM if needed</li> <li>Document assumptions</li> <li>Flag any missing information</li> </ol> <p>Output: Clear understanding of requirements</p> <p>Time: 30 minutes - 1 hour</p>"},{"location":"workflow/#step-2-choose-workflow-path","title":"Step 2: Choose Workflow Path","text":"<p>Decision Maker: Lead Engineer or Architect</p> <p>Process: Use the Decision Matrix from Lifecycle</p> <pre><code>Ask yourself:\n- Is the domain familiar to the team?\n- How complex are the business rules?\n- What's the risk level (financial, reputation, compliance)?\n- How tight is the deadline?\n- What's the team's experience level?\n</code></pre> <p>Decision: - Path A (Full): Complex/unfamiliar/high-risk \u2192 Generate AI-DAA - Path B (Lightweight): Simple/familiar/low-risk \u2192 Write TIP</p> <p>Output: Decision documented (in commit message, Jira ticket, or project log)</p> <p>Time: 5-15 minutes</p>"},{"location":"workflow/#step-3a-full-workflow-generate-and-validate-ai-daa","title":"Step 3A: Full Workflow - Generate and Validate AI-DAA","text":"<p>Participants: Engineer + AI, then Domain Expert for validation</p> <p>Process:</p> <p>3A.1 Generate AI-DAA 1. Open your AI tool (e.g., ChatGPT, Claude, or any AI assistant) 2. Provide the PRD as context 3. Prompt:    <pre><code>You are a Domain-Driven Design expert. Analyze this PRD and generate\na complete AI-DAA (Domain Architecture Analysis). The DAA must be:\n- 100% technology-agnostic (no databases, frameworks, or languages)\n- Use DDD patterns (Bounded Contexts, Aggregates, Value Objects, Domain Events)\n- Written in clear pseudocode\n- Explicitly state all business invariants\n\nPRD:\n[Paste full PRD here]\n</code></pre> 4. Review AI output for:    - Completeness (all user stories addressed)    - Clarity (understandable by domain experts)    - Correctness (accurate domain model)</p> <p>3A.2 Validate AI-DAA 1. Share DAA with domain expert (PM, business analyst, or senior engineer) 2. Walk through the proposed Aggregates and operations 3. Verify invariants match business rules 4. Request AI to generate a \"Coverage Report\":    <pre><code>Compare this AI-DAA against the original PRD. Create a coverage report\nshowing:\n- Which user stories are addressed by which operations\n- Any PRD requirements not yet covered\n- Any DAA elements not traceable to PRD\n</code></pre> 5. Iterate if gaps are found</p> <p>3A.3 Lock the DAA Once validated: - Commit the DAA to the Knowledge Repository (e.g., <code>docs/daas/booking-cancel-daa.md</code>) - Tag as \"validated\" (e.g., git tag <code>daa-booking-cancel-v1.0</code>) - Link to PRD in metadata</p> <p>Output: Validated AI-DAA document</p> <p>Time: 2-4 hours (including validation session)</p>"},{"location":"workflow/#step-3b-lightweight-workflow-write-tip","title":"Step 3B: Lightweight Workflow - Write TIP","text":"<p>Participant: Engineer</p> <p>Process:</p> <p>3B.1 Draft TIP 1. Create a new TIP document (e.g., <code>docs/tips/booking-notes-tip.md</code>) 2. Following the TIP structure, write:    - Database changes (schema modifications, indexes)    - API changes (new endpoints, request/response formats)    - Service modifications (which services need updates)    - Testing plan (unit, integration tests) 3. Flag any open questions or uncertainties</p> <p>3B.2 Self-Review Before sharing: - Does it address all PRD requirements? - Are edge cases considered? - Is the estimate realistic?</p> <p>Output: Draft TIP document</p> <p>Time: 1-2 hours</p>"},{"location":"workflow/#phase-2-collaborative-design","title":"Phase 2: Collaborative Design","text":""},{"location":"workflow/#step-4-create-rfc","title":"Step 4: Create RFC","text":"<p>Participant: Engineer</p> <p>Input:  - Validated DAA (from Path A) or Draft TIP (from Path B) - Initial technical thoughts</p> <p>Process: 1. Create RFC document (e.g., <code>docs/rfcs/rfc-042-booking-cancel.md</code>) 2. Follow RFC structure:    - Add metadata (RFC number, author, date, status: \"Draft\")    - Context: Link to PRD, paste or reference DAA/TIP    - Proposed Solution: Your initial technical approach    - Open Questions: What needs team input?    - Constraints: Timeline, budget, must-use technologies 3. Add initial diagrams (architecture, sequence) using Mermaid or PlantUML</p> <p>Output: Draft RFC document</p> <p>Time: 1-2 hours</p>"},{"location":"workflow/#step-5-consult-architectural-playbook","title":"Step 5: Consult Architectural Playbook","text":"<p>Participant: Engineer or Architect</p> <p>Process: 1. Review the RFC and identify key architectural challenges    - Data consistency (ACID, eventual consistency)    - Service communication (sync, async, events)    - Failure handling (retries, circuit breakers)    - Performance (caching, indexing)    - Security (authentication, authorization, encryption)</p> <ol> <li>Search the Architectural Playbook for relevant patterns</li> <li>Example: If you need reliable event delivery \u2192 \"Transactional Outbox Pattern\"</li> <li> <p>Example: If you need resilient service calls \u2192 \"Circuit Breaker Pattern\"</p> </li> <li> <p>Add Playbook references to RFC:    <pre><code>## Applicable Patterns\n- OUTBOX-001: Transactional Outbox (for event publishing)\n- IDEMPOTENT-002: Idempotent API Design (for retry safety)\n</code></pre></p> </li> </ol> <p>Output: RFC updated with Playbook references</p> <p>Time: 30 minutes - 1 hour</p>"},{"location":"workflow/#step-6-collaborative-design-session-ai-as-socratic-partner","title":"Step 6: Collaborative Design Session - AI as Socratic Partner","text":"<p>Participants: Architect/Senior Engineer + AI</p> <p>Input: Draft RFC with Playbook references</p> <p>Process:</p> <p>6.1 Setup the Session 1. Open AI tool with long context window 2. Load context:    <pre><code>You are an expert software architect and my Socratic Sparring Partner.\nI will share an RFC for a new feature. Your role is to:\n- Challenge the design\n- Propose alternatives\n- Analyze trade-offs\n- Ask probing questions\n- Help me explore edge cases\n\nUse the attached Architectural Playbook as your knowledge base.\n\nRFC:\n[Paste full RFC]\n\nPlaybook Patterns:\n[Paste relevant Playbook entries]\n</code></pre></p> <p>6.2 The Dialogue (Iterative)</p> <p>Round 1: Initial Challenge <pre><code>Prompt: \"Review this RFC. What are the weaknesses in my proposed design? \nWhat could go wrong?\"\n\nAI: [Identifies risks, tight coupling, single points of failure, etc.]\n\nYou: [Consider feedback, ask follow-up questions]\n</code></pre></p> <p>Round 2: Explore Alternatives <pre><code>Prompt: \"Propose 3 alternative approaches for [specific component]. \nCompare their trade-offs in terms of complexity, performance, and \nreliability.\"\n\nAI: [Presents alternatives with pros/cons]\n\nYou: [Evaluate options, ask for clarification]\n</code></pre></p> <p>Round 3: Deep Dive on Edge Cases <pre><code>Prompt: \"How should we handle [specific scenario, e.g., partial failure, \nconcurrent requests, data inconsistency]?\"\n\nAI: [Proposes solutions, references Playbook patterns]\n\nYou: [Refine approach]\n</code></pre></p> <p>Round 4: Visualize the Design <pre><code>Prompt: \"Generate a sequence diagram showing the full flow from API request \nto event publishing, including failure scenarios.\"\n\nAI: [Generates Mermaid diagram]\n\nYou: [Review, identify gaps, request refinements]\n</code></pre></p> <p>6.3 Iteration Repeat the above rounds until: - All major risks are addressed - Edge cases have clear handling strategies - Trade-offs are explicitly documented - You feel confident the design is robust</p> <p>Output: Refined RFC with: - Updated technical approach - Diagrams showing final design - Documented trade-offs - Answers to all open questions</p> <p>Time: 2-4 hours (can be broken into multiple sessions)</p>"},{"location":"workflow/#step-7-team-review-optional-but-recommended","title":"Step 7: Team Review (Optional but Recommended)","text":"<p>Participants: Architect, Senior Engineers, Domain Experts</p> <p>Input: Refined RFC from Step 6</p> <p>Process: 1. Share RFC with team (via PR, email, or design review meeting) 2. Gather feedback:    - Are there concerns about the approach?    - Have we missed any edge cases?    - Are the trade-offs acceptable? 3. Incorporate feedback into RFC</p> <p>Output: RFC status updated to \"Under Review\"</p> <p>Time: 1-2 days (async) or 1 hour (sync meeting)</p>"},{"location":"workflow/#step-8-finalize-design-and-generate-ai-adr","title":"Step 8: Finalize Design and Generate AI-ADR","text":"<p>Participant: Architect/Senior Engineer</p> <p>Input: Reviewed and refined RFC</p> <p>Process:</p> <p>8.1 Final Approval - Mark RFC status as \"Approved\" - Document final decisions</p> <p>8.2 Generate AI-ADR Prompt AI: <pre><code>Based on this approved RFC, generate a formal AI-ADR (Architectural \nDecision Record). The ADR should follow this structure:\n- Metadata (ADR number, title, status, links to PRD/DAA/RFC)\n- Context (problem statement from DAA)\n- Decision (clear statement of chosen approach)\n- Rationale (why this approach, referencing DAA invariants and NFRs)\n- Implementation Details (tech stack, schemas, API contracts, diagrams)\n- Edge Cases (how we handle failures, concurrency, etc.)\n- Monitoring (metrics, alerts)\n- Rejected Alternatives (what we considered and why rejected)\n\nRFC:\n[Paste approved RFC]\n</code></pre></p> <p>8.3 Review and Lock ADR 1. Review AI-generated ADR for accuracy 2. Ensure it contains enough detail for implementation 3. Commit to Knowledge Repository (e.g., <code>docs/adrs/adr-023-booking-cancel.md</code>) 4. Tag as \"accepted\" (e.g., git tag <code>adr-booking-cancel-v1.0</code>)</p> <p>Output: Finalized, immutable AI-ADR</p> <p>Time: 1-2 hours</p>"},{"location":"workflow/#phase-3-construction","title":"Phase 3: Construction","text":""},{"location":"workflow/#step-9-break-down-into-bolts","title":"Step 9: Break Down into Bolts","text":"<p>Participant: Engineer</p> <p>Input: Finalized AI-ADR</p> <p>Process: 1. Read ADR thoroughly, especially \"Implementation Details\" section 2. Identify discrete, testable components:    - Example: \"API endpoint implementation\"    - Example: \"Database migration\"    - Example: \"Background worker for outbox relay\"    - Example: \"Monitoring dashboard\" 3. For each component, create a Bolt:    - Bolt ID (sequential, e.g., BOLT-042)    - Goal (one-sentence description)    - Acceptance criteria (from ADR)    - Estimated effort (hours/days) 4. Order Bolts by dependency (what must be done first)</p> <p>Output: Bolt backlog (can be managed in Jira, Linear, or markdown file)</p> <p>Example Bolt Breakdown: <pre><code>## Bolts for ADR-023: Booking Cancellation Feature\n\n1. **BOLT-042**: Create database migration for booking status\n   - Estimated: 2 hours\n   - Dependencies: None\n   - AC: Migration adds `status` column with proper constraints and transitions\n\n2. **BOLT-043**: Implement Booking aggregate and cancel operation\n   - Estimated: 4 hours\n   - Dependencies: BOLT-042\n   - AC: cancel() method enforces invariants, returns domain event\n\n3. **BOLT-044**: Implement POST /bookings/{id}/cancel API endpoint\n   - Estimated: 6 hours\n   - Dependencies: BOLT-043\n   - AC: Endpoint validates input, calls aggregate, writes to outbox\n\n4. **BOLT-045**: Implement outbox relay worker for booking events\n   - Estimated: 8 hours\n   - Dependencies: BOLT-044\n   - AC: Worker polls outbox, publishes to Kafka, handles errors\n\n5. **BOLT-046**: Add monitoring and alerts\n   - Estimated: 3 hours\n   - Dependencies: BOLT-045\n   - AC: Dashboards show cancellation metrics, alerts configured\n</code></pre></p> <p>Time: 1-2 hours</p>"},{"location":"workflow/#step-10-implement-each-bolt","title":"Step 10: Implement Each Bolt","text":"<p>Participant: Engineer</p> <p>Input: Single Bolt from backlog</p> <p>Process (for each Bolt):</p> <p>10.1 Start Bolt - Update Bolt status to \"In Progress\" - Create feature branch (e.g., <code>feature/bolt-042-booking-status-migration</code>)</p> <p>10.2 Use AI for Boilerplate Generation Prompt AI: <pre><code>Based on ADR-023, generate [specific component] for BOLT-042. I need:\n- [Database migration, API handler, service method, etc.]\n- Follow our team's coding standards\n- Include input validation and error handling\n\nADR Section:\n[Paste relevant ADR section]\n\nBolt Goal:\n[Paste Bolt description]\n</code></pre></p> <p>AI generates scaffolding code.</p> <p>10.3 Implement Core Logic - Review AI-generated boilerplate - Implement complex business logic yourself (this is where human expertise shines) - Refactor as needed</p> <p>10.4 Generate Tests Prompt AI: <pre><code>Generate comprehensive unit tests for this code. Cover:\n- Happy path\n- Edge cases (e.g., invalid input, concurrent modifications)\n- Error scenarios\n\nCode:\n[Paste your implementation]\n</code></pre></p> <p>Review and supplement AI-generated tests.</p> <p>10.5 Self-Review - Does code match ADR specification? - Are all acceptance criteria met? - Are edge cases handled per ADR? - Are tests comprehensive?</p> <p>10.6 Submit for Review - Create Pull Request - Link to ADR and Bolt in PR description - Request review from peer or architect</p> <p>10.7 Address Feedback and Merge - Incorporate review feedback - Merge when approved</p> <p>10.8 Update Bolt Status - Mark Bolt as \"Done\" - Record actual effort</p> <p>Output: Merged code for one Bolt</p> <p>Time: Varies (hours to days per Bolt)</p>"},{"location":"workflow/#step-11-validate-against-adr","title":"Step 11: Validate Against ADR","text":"<p>Participant: Engineer (with AI assistance)</p> <p>Input: Completed Bolts</p> <p>Process: After all Bolts for an ADR are complete, perform final validation:</p> <p>Prompt AI: <pre><code>I've completed all Bolts for ADR-023. Generate a Compliance Report:\n- Compare the final implementation against the ADR specification\n- Identify any discrepancies\n- Verify all edge cases from ADR are handled\n- Check if monitoring/alerts are configured as specified\n\nADR:\n[Paste ADR]\n\nCode:\n[Link to code repo or paste relevant files]\n</code></pre></p> <p>Review AI's compliance report. If discrepancies found: - Create Fix-It Bolts for missing items - OR update ADR if implementation revealed better approaches (create ADR amendment)</p> <p>Output: Compliance report, with action items if needed</p> <p>Time: 1-2 hours</p>"},{"location":"workflow/#step-12-deploy","title":"Step 12: Deploy","text":"<p>Participant: Engineer, DevOps/SRE</p> <p>Input: Completed, tested code</p> <p>Process: 1. Staging Deployment    - Deploy to staging environment    - Run smoke tests    - Validate monitoring/alerts are working</p> <ol> <li>Production Deployment</li> <li>Deploy via standard CI/CD pipeline</li> <li>Monitor dashboards during rollout</li> <li> <p>Validate success metrics from PRD</p> </li> <li> <p>Rollback Plan</p> </li> <li>Document rollback steps</li> <li>Keep previous version available for quick revert</li> </ol> <p>Output: Feature live in production</p> <p>Time: Varies (minutes to hours, depending on CI/CD maturity)</p>"},{"location":"workflow/#phase-3-operations-ongoing","title":"Phase 3: Operations (Ongoing)","text":"<p>See Operations for detailed incident response workflow.</p> <p>High-Level Process: 1. Monitoring: Dashboards track metrics from ADR 2. Alerting: Alerts fire on threshold breaches 3. Incident Response: AI-assisted triage using full traceability chain 4. Post-Mortem: Document learnings, feed back into Knowledge Repository</p>"},{"location":"workflow/#workflow-cheat-sheet","title":"Workflow Cheat Sheet","text":""},{"location":"workflow/#for-new-features","title":"For New Features","text":"Step Artifact Time Key Decision 1. Review PRD - 30min-1hr Understand requirements 2. Choose Path - 15min Full or Lightweight? 3A. Generate DAA AI-DAA 2-4hrs Domain modeling 3B. Write TIP TIP 1-2hrs Technical proposal 4. Create RFC RFC 1-2hrs Formalize design 5. Consult Playbook - 30min-1hr Identify patterns 6. AI Sparring Refined RFC 2-4hrs Challenge design 7. Team Review - 1-2 days Gather feedback 8. Generate ADR AI-ADR 1-2hrs Lock design 9. Plan Bolts Bolt Backlog 1-2hrs Break down work 10. Implement Code Days-weeks Build feature 11. Validate Compliance Report 1-2hrs Verify against ADR 12. Deploy Deployment Unit Minutes-hours Go live"},{"location":"workflow/#decision-points","title":"Decision Points","text":"<p>Full vs. Lightweight Workflow - Complex domain \u2192 Full (AI-DAA) - Simple feature \u2192 Lightweight (TIP) - When in doubt \u2192 Full (invest in understanding)</p> <p>When to Generate Diagrams - Always during Collaborative Design (Step 6) - For complex flows, edge cases, or state machines - Use diagrams-as-code (Mermaid, PlantUML) for version control</p> <p>When to Update Architectural Playbook - When you solve a recurring problem in a novel way - After post-mortems reveal patterns - When team develops new best practices</p>"},{"location":"workflow/#tips-for-success","title":"Tips for Success","text":""},{"location":"workflow/#1-start-small","title":"1. Start Small","text":"<p>Don't try to adopt the full workflow on day one. Start with: - Week 1: Use AI to generate DAAs for 1-2 features - Week 2: Try the Collaborative Design session (Step 6) - Week 3: Implement ADR-driven construction with Bolts</p>"},{"location":"workflow/#2-iterate-on-templates","title":"2. Iterate on Templates","text":"<p>Customize the artifact templates to fit your team: - Add your tech stack to ADR template - Include your company's code style in Bolt templates - Tailor Playbook entries to your common challenges</p>"},{"location":"workflow/#3-build-your-playbook-gradually","title":"3. Build Your Playbook Gradually","text":"<p>Start with 3-5 core patterns: - Transactional Outbox Pattern - Idempotent API Design - Circuit Breaker Pattern - Retry with Exponential Backoff - Database Migration Strategy</p> <p>Add new patterns as your team encounters new challenges.</p>"},{"location":"workflow/#4-treat-ai-as-a-junior-engineer","title":"4. Treat AI as a Junior Engineer","text":"<ul> <li>Always review AI output critically</li> <li>Use AI for boilerplate, you handle complex logic</li> <li>Teach AI your context (PRD, DAA, Playbook)</li> </ul>"},{"location":"workflow/#5-maintain-the-knowledge-repository","title":"5. Maintain the Knowledge Repository","text":"<ul> <li>Commit every artifact (DAA, ADR, RFC, Bolt, Post-mortem)</li> <li>Use meaningful commit messages</li> <li>Tag major versions (e.g., <code>adr-booking-cancel-v1.0</code>)</li> <li>Keep it searchable (markdown + git grep is powerful)</li> </ul>"},{"location":"workflow/#6-celebrate-traceability","title":"6. Celebrate Traceability","text":"<p>When debugging, show your team: <pre><code>This error in booking_service.go:152 \n\u2192 was implemented in BOLT-043 \n\u2192 based on ADR-023 \n\u2192 which implements the DAA from booking-cancel-daa.md \n\u2192 which fulfills User Story 3 in PRD-015\n</code></pre></p> <p>This demonstrates the power of AirSDLC.</p> <p>Next: Operations - Post-deployment and incident handling</p>"},{"location":"examples/","title":"AirSDLC Examples","text":"<p>This directory contains practical examples of AirSDLC artifacts. These examples are based on a fictional \"Booking Management\" feature for a reservation application.</p>"},{"location":"examples/#example-feature-booking-cancellation","title":"Example Feature: Booking Cancellation","text":"<p>We'll walk through a complete feature implementation from PRD to deployment, demonstrating all core artifacts.</p>"},{"location":"examples/#scenario","title":"Scenario","text":"<p>Business Need: Users need the ability to cancel their bookings for various reasons (e.g., change of plans, double booking, user-initiated cancellation).</p>"},{"location":"examples/#artifacts-in-this-flow","title":"Artifacts in this Flow","text":"<ol> <li>example-prd.md - Product Requirements Document for booking cancellation</li> <li>example-daa.md - Domain Architecture Analysis using DDD patterns (AI-generated)</li> <li>example-tip.md - Technical Implementation Proposal (lightweight workflow alternative)</li> <li>example-rfc.md - Request for Comments with design discussion</li> <li>example-adr.md - Architectural Decision Record (finalized design)</li> <li>example-playbook-entry.md - Transactional Outbox Pattern (reusable)</li> </ol>"},{"location":"examples/#traceability-chain-full-workflow","title":"Traceability Chain (Full Workflow)","text":"<pre><code>example-prd.md (Business Requirements)\n     \u2193\nexample-daa.md (Domain Model using DDD)\n     \u2193\nexample-rfc.md (Design Discussion)\n     \u2193\nexample-adr.md (Finalized Architecture)\n     \u2193\nBolts \u2192 Code \u2192 Deployment\n</code></pre>"},{"location":"examples/#alternative-path-lightweight-workflow","title":"Alternative Path (Lightweight Workflow)","text":"<p>For simpler features, skip the DAA:</p> <pre><code>example-prd.md (Business Requirements)\n     \u2193\nexample-tip.md (Technical Proposal)\n     \u2193\nexample-rfc.md (Design Discussion)\n     \u2193\nexample-adr.md (Finalized Architecture)\n     \u2193\nBolts \u2192 Code \u2192 Deployment\n</code></pre>"},{"location":"examples/#understanding-the-examples","title":"Understanding the Examples","text":"<p>These examples walk through a complete booking cancellation feature from start to finish.</p>"},{"location":"examples/#full-workflow-path","title":"Full Workflow Path","text":"<ol> <li>example-prd.md: Business stakeholder defines need for booking cancellation</li> <li>example-daa.md: AI analyzes domain, identifies <code>Booking</code> aggregate, <code>cancel()</code> operation, and invariants</li> <li>example-rfc.md: Engineer proposes technical approach with outbox pattern for reliability</li> <li>example-adr.md: Team finalizes design after collaborative discussion with AI</li> <li>Bolts: Feature broken into discrete tasks (API endpoint, worker, monitoring)</li> </ol>"},{"location":"examples/#key-learning-points","title":"Key Learning Points","text":"<ul> <li>Start with the PRD to understand business requirements and success metrics</li> <li>Notice how the DAA remains technology-agnostic (no database, framework, or language mentioned)</li> <li>See the RFC capture open questions and initial technical thinking</li> <li>The ADR becomes concrete with PostgreSQL, Go, Kafka, specific tables and endpoints</li> <li>Each artifact builds on and traces back to the previous one</li> <li>The Playbook provides reusable patterns that inform multiple designs</li> </ul>"},{"location":"examples/#how-to-use-these-examples","title":"How to Use These Examples","text":"<ul> <li>For Learning: Read the examples in order (PRD \u2192 DAA \u2192 RFC \u2192 ADR)</li> <li>For Your Team: Use these as templates and adapt to your domain</li> <li>For Tool Builders: Use as test fixtures for validation logic</li> </ul>"},{"location":"examples/#additional-resources","title":"Additional Resources","text":"<p>For more context on each artifact type:</p> <ul> <li>artifacts.md - Complete specifications for all artifact types</li> <li>workflow.md - Step-by-step process guide with additional examples</li> <li>lifecycle.md - Phase-by-phase breakdown of the framework</li> <li>operations.md - Post-deployment incident response examples</li> </ul> <p>Note: The booking cancellation examples are fictional and simplified for educational purposes. Real-world implementations would include more detail specific to your domain, tech stack, and team context.</p>"},{"location":"examples/example-adr/","title":"ADR-023: Booking Cancellation Implementation Architecture","text":"<p>Status: Accepted Author: Jane Smith (Senior Engineer) Reviewers: Engineering Team, Architecture Board Decision Date: 2024-01-25 Supersedes: None  </p> <p>Related Documents: - PRD: PRD-015 (Booking Cancellation Feature) - DAA: AI-DAA Booking Cancellation Domain Model - RFC: RFC-023 (Booking Cancellation Implementation)</p>"},{"location":"examples/example-adr/#1-context-and-problem-statement","title":"1. Context and Problem Statement","text":"<p>Users currently cannot cancel their bookings through the application, requiring them to contact customer support. This results in high support costs (60% of tickets are cancellation requests) and poor user experience.</p> <p>The booking cancellation feature needs to: 1. Allow users to self-service cancel their confirmed bookings 2. Meet strict reliability requirements (99.9% uptime, zero event loss) 3. Maintain performance standards (p95 latency &lt; 500ms) 4. Ensure reliable notification delivery to downstream services 5. Handle high concurrency (1000 concurrent requests, 50,000 cancellations/day)</p>"},{"location":"examples/example-adr/#key-technical-challenges","title":"Key Technical Challenges","text":"<ul> <li>Reliability: How to guarantee event delivery to downstream services even during failures?</li> <li>Consistency: How to ensure atomicity between database updates and event publishing?</li> <li>Concurrency: How to handle race conditions from multiple simultaneous cancellation attempts?</li> <li>Performance: How to meet latency SLAs while maintaining reliability?</li> </ul>"},{"location":"examples/example-adr/#2-decision-drivers","title":"2. Decision Drivers","text":""},{"location":"examples/example-adr/#functional-requirements-from-prd-015","title":"Functional Requirements (from PRD-015)","text":"<ul> <li>Users can cancel confirmed bookings via REST API</li> <li>Cancellation reason must be provided</li> <li>System sends notifications to user and property owner</li> <li>Cancelled bookings remain in history for 12+ months</li> </ul>"},{"location":"examples/example-adr/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>NFR-015-1: API response time &lt; 500ms (p95)</li> <li>NFR-015-2: Notification delivery within 30 seconds</li> <li>NFR-015-3: 99.9% uptime for cancellation endpoint</li> <li>NFR-015-4: Zero data loss for cancellation events</li> <li>NFR-015-5: Guaranteed notification delivery (at-least-once)</li> <li>NFR-015-9: Support 1000 concurrent cancellation requests</li> </ul>"},{"location":"examples/example-adr/#technical-constraints","title":"Technical Constraints","text":"<ul> <li>Existing microservices architecture (Go-based)</li> <li>PostgreSQL database for booking state</li> <li>Kafka for event streaming</li> <li>Multiple downstream consumers (Notification, Property Management)</li> </ul>"},{"location":"examples/example-adr/#3-considered-options","title":"3. Considered Options","text":""},{"location":"examples/example-adr/#option-1-synchronous-event-publishing-direct-kafka-publish","title":"Option 1: Synchronous Event Publishing (Direct Kafka Publish)","text":"<p>Architecture: <pre><code>API Handler \u2192 Database Update \u2192 Kafka Publish \u2192 Return Response\n</code></pre></p> <p>Pros: - Simple implementation - No additional infrastructure - Immediate event delivery</p> <p>Cons: - \u274c Violates atomicity - if Kafka is down, booking is cancelled but event is lost - \u274c Increases API latency (Kafka publish blocks response) - \u274c Does not meet NFR-015-4 (zero data loss) - \u274c Single point of failure</p> <p>Verdict: REJECTED - Does not meet reliability requirements</p>"},{"location":"examples/example-adr/#option-2-transactional-outbox-pattern-selected","title":"Option 2: Transactional Outbox Pattern (SELECTED)","text":"<p>Architecture: <pre><code>API Handler \u2192 Database + Outbox Write (Transaction) \u2192 Return Response\nOutbox Worker \u2192 Poll Outbox \u2192 Kafka Publish \u2192 Mark Processed\n</code></pre></p> <p>Pros: - \u2705 Guarantees atomicity (database + outbox in same transaction) - \u2705 Zero event loss (events persisted before acknowledgment) - \u2705 Fast API response (async event publishing) - \u2705 Resilient to Kafka downtime - \u2705 Meets all reliability NFRs</p> <p>Cons: - Additional complexity (outbox table + relay worker) - Eventual consistency (slight delay in event delivery) - Requires monitoring of outbox backlog</p> <p>Verdict: SELECTED - Best balance of reliability and performance</p>"},{"location":"examples/example-adr/#option-3-saga-pattern-with-orchestration","title":"Option 3: Saga Pattern with Orchestration","text":"<p>Architecture: <pre><code>API \u2192 Saga Orchestrator \u2192 Database \u2192 Notification Service \u2192 PMS\n</code></pre></p> <p>Pros: - Strong consistency guarantees - Explicit compensation logic</p> <p>Cons: - \u274c Massive overkill for one-way cancellation operation - \u274c High implementation complexity - \u274c Increased latency - \u274c Not needed - no distributed transaction required</p> <p>Verdict: REJECTED - Over-engineered for this use case</p>"},{"location":"examples/example-adr/#option-4-two-phase-commit-2pc","title":"Option 4: Two-Phase Commit (2PC)","text":"<p>Architecture: <pre><code>API \u2192 2PC Coordinator \u2192 Database + Kafka (distributed transaction)\n</code></pre></p> <p>Pros: - Strong consistency</p> <p>Cons: - \u274c High latency (blocking protocol) - \u274c Kafka doesn't support 2PC - \u274c Single point of failure (coordinator) - \u274c Poor scalability</p> <p>Verdict: REJECTED - Not feasible with existing tech stack</p>"},{"location":"examples/example-adr/#4-decision-outcome","title":"4. Decision Outcome","text":""},{"location":"examples/example-adr/#selected-transactional-outbox-pattern-option-2","title":"Selected: Transactional Outbox Pattern (Option 2)","text":"<p>We will implement the booking cancellation feature using the Transactional Outbox Pattern with the following architecture:</p> <pre><code>sequenceDiagram\n    participant Client\n    participant API as Booking API\n    participant DB as PostgreSQL\n    participant Outbox as Outbox Table\n    participant Worker as Relay Worker\n    participant Kafka\n    participant NS as Notification Service\n    participant PMS as Property Mgmt\n\n    Client-&gt;&gt;API: POST /bookings/:id/cancel\n    API-&gt;&gt;API: Validate user &amp; booking status\n\n    rect rgb(200, 220, 250)\n        note right of API: Transaction Boundary\n        API-&gt;&gt;DB: UPDATE bookings SET status='cancelled'\n        API-&gt;&gt;Outbox: INSERT event (BookingCancelled)\n        API-&gt;&gt;DB: COMMIT\n    end\n\n    API--&gt;&gt;Client: 200 OK (booking cancelled)\n\n    Worker-&gt;&gt;Outbox: Poll for unprocessed events\n    Outbox--&gt;&gt;Worker: BookingCancelled event\n    Worker-&gt;&gt;Kafka: Publish event\n    Kafka--&gt;&gt;Worker: ACK\n    Worker-&gt;&gt;Outbox: UPDATE processed_at\n\n    Kafka-&gt;&gt;NS: BookingCancelled event\n    Kafka-&gt;&gt;PMS: BookingCancelled event\n    NS-&gt;&gt;NS: Send cancellation email\n    PMS-&gt;&gt;PMS: Update availability</code></pre>"},{"location":"examples/example-adr/#5-implementation-details","title":"5. Implementation Details","text":""},{"location":"examples/example-adr/#51-database-schema","title":"5.1 Database Schema","text":""},{"location":"examples/example-adr/#bookings-table-modifications","title":"Bookings Table Modifications","text":"<pre><code>-- Add cancellation fields to existing bookings table\nALTER TABLE bookings \n  ADD COLUMN cancelled_at TIMESTAMP NULL,\n  ADD COLUMN cancellation_reason VARCHAR(50) NULL,\n  ADD COLUMN cancellation_notes TEXT NULL,\n  ADD COLUMN version INTEGER NOT NULL DEFAULT 1;\n\n-- Enforce enum constraint for cancellation reason\nALTER TABLE bookings\n  ADD CONSTRAINT check_cancellation_reason \n  CHECK (cancellation_reason IN (\n    'change_of_plans', 'double_booking', \n    'found_alternative', 'no_longer_needed', 'other'\n  ));\n\n-- Enforce data consistency: if cancelled, reason must exist\nALTER TABLE bookings\n  ADD CONSTRAINT check_cancellation_consistency\n  CHECK (\n    (status = 'cancelled' AND cancellation_reason IS NOT NULL AND cancelled_at IS NOT NULL) OR\n    (status != 'cancelled' AND cancellation_reason IS NULL AND cancelled_at IS NULL)\n  );\n\n-- Add index for cancelled bookings queries\nCREATE INDEX idx_bookings_cancelled_at ON bookings(cancelled_at) \n  WHERE cancelled_at IS NOT NULL;\n\n-- Add index for version-based optimistic locking\nCREATE INDEX idx_bookings_version ON bookings(id, version);\n</code></pre>"},{"location":"examples/example-adr/#outbox-table","title":"Outbox Table","text":"<pre><code>-- Transactional outbox table for reliable event publishing\nCREATE TABLE booking_outbox (\n  id BIGSERIAL PRIMARY KEY,\n  booking_id UUID NOT NULL,\n  event_type VARCHAR(100) NOT NULL,\n  event_payload JSONB NOT NULL,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  processed_at TIMESTAMP NULL,\n  retry_count INTEGER NOT NULL DEFAULT 0,\n  last_error TEXT NULL\n);\n\n-- Index for efficient polling of unprocessed events\nCREATE INDEX idx_outbox_unprocessed \n  ON booking_outbox(created_at) \n  WHERE processed_at IS NULL;\n\n-- Index for monitoring and cleanup\nCREATE INDEX idx_outbox_processed \n  ON booking_outbox(processed_at) \n  WHERE processed_at IS NOT NULL;\n</code></pre>"},{"location":"examples/example-adr/#52-api-contract","title":"5.2 API Contract","text":"<pre><code>POST /v1/bookings/{booking_id}/cancel\nAuthorization: Bearer &lt;jwt_token&gt;\nContent-Type: application/json\n\nRequest Body:\n{\n  \"reason\": \"change_of_plans\",  // Required: one of enum values\n  \"notes\": \"Found a better option\"  // Optional: free text\n}\n\nResponse 200 OK:\n{\n  \"booking_id\": \"a1b2c3d4-5678-90ab-cdef-1234567890ab\",\n  \"user_id\": \"user-123\",\n  \"resource_id\": \"resource-456\",\n  \"status\": \"cancelled\",\n  \"cancelled_at\": \"2024-01-25T14:30:00Z\",\n  \"cancellation_reason\": \"change_of_plans\",\n  \"cancellation_notes\": \"Found a better option\",\n  \"confirmation_code\": \"A1B2C3D4\"\n}\n\nError Responses:\n- 400 Bad Request: Invalid reason or booking cannot be cancelled\n  {\"error\": \"INVALID_STATUS\", \"message\": \"Cannot cancel booking with status 'completed'\"}\n\n- 403 Forbidden: User does not own booking\n  {\"error\": \"UNAUTHORIZED\", \"message\": \"You do not own this booking\"}\n\n- 404 Not Found: Booking not found\n  {\"error\": \"NOT_FOUND\", \"message\": \"Booking not found\"}\n\n- 409 Conflict: Concurrent modification detected\n  {\"error\": \"CONFLICT\", \"message\": \"Booking was modified by another request. Please retry.\"}\n\n- 500 Internal Server Error: System failure\n  {\"error\": \"INTERNAL_ERROR\", \"message\": \"An unexpected error occurred\"}\n</code></pre>"},{"location":"examples/example-adr/#53-service-implementation","title":"5.3 Service Implementation","text":"<pre><code>// BookingService.CancelBooking implements the cancellation operation\nfunc (s *BookingService) CancelBooking(\n  ctx context.Context,\n  bookingID uuid.UUID,\n  userID uuid.UUID,\n  reason CancellationReason,\n  notes string,\n) (*Booking, error) {\n\n  // Start database transaction\n  tx, err := s.db.BeginTx(ctx, &amp;sql.TxOptions{\n    Isolation: sql.LevelReadCommitted,\n  })\n  if err != nil {\n    return nil, fmt.Errorf(\"begin transaction: %w\", err)\n  }\n  defer tx.Rollback()\n\n  // Load booking with row-level lock (SELECT FOR UPDATE)\n  booking, err := s.repo.FindByIDForUpdate(ctx, tx, bookingID)\n  if err != nil {\n    if errors.Is(err, ErrNotFound) {\n      return nil, ErrBookingNotFound\n    }\n    return nil, fmt.Errorf(\"find booking: %w\", err)\n  }\n\n  // Authorization: Verify user owns the booking\n  if booking.UserID != userID {\n    return nil, ErrUnauthorizedCancellation\n  }\n\n  // Validation: Check booking status\n  if booking.Status != StatusConfirmed {\n    return nil, ErrInvalidBookingStatus\n  }\n\n  // Update booking state (domain logic)\n  now := time.Now()\n  booking.Status = StatusCancelled\n  booking.CancelledAt = &amp;now\n  booking.CancellationReason = &amp;reason\n  booking.CancellationNotes = &amp;notes\n  booking.Version++ // Optimistic locking\n\n  // Persist booking changes\n  if err := s.repo.Update(ctx, tx, booking); err != nil {\n    if errors.Is(err, ErrVersionConflict) {\n      return nil, ErrConcurrentModification\n    }\n    return nil, fmt.Errorf(\"update booking: %w\", err)\n  }\n\n  // Create domain event\n  event := BookingCancelledEvent{\n    EventID:           uuid.New(),\n    BookingID:         booking.ID,\n    UserID:            booking.UserID,\n    ResourceID:        booking.ResourceID,\n    ConfirmationCode:  booking.ConfirmationCode,\n    CancelledAt:       now,\n    Reason:            reason,\n    Notes:             notes,\n    OccurredAt:        now,\n  }\n\n  // Write event to outbox (in same transaction)\n  if err := s.outbox.Insert(ctx, tx, OutboxEntry{\n    BookingID:    booking.ID,\n    EventType:    \"BookingCancelled\",\n    EventPayload: event.ToJSON(),\n  }); err != nil {\n    return nil, fmt.Errorf(\"insert outbox event: %w\", err)\n  }\n\n  // Commit transaction (atomically updates booking + outbox)\n  if err := tx.Commit(); err != nil {\n    return nil, fmt.Errorf(\"commit transaction: %w\", err)\n  }\n\n  // Log cancellation for audit\n  s.logger.Info(\"booking cancelled\",\n    \"booking_id\", booking.ID,\n    \"user_id\", userID,\n    \"reason\", reason,\n  )\n\n  return booking, nil\n}\n</code></pre>"},{"location":"examples/example-adr/#54-outbox-relay-worker","title":"5.4 Outbox Relay Worker","text":"<pre><code>// OutboxRelayWorker polls the outbox table and publishes events to Kafka\ntype OutboxRelayWorker struct {\n  outbox    OutboxRepository\n  kafka     KafkaProducer\n  logger    Logger\n  pollRate  time.Duration // 5 seconds\n  batchSize int           // 100 events per batch\n}\n\nfunc (w *OutboxRelayWorker) Run(ctx context.Context) error {\n  ticker := time.NewTicker(w.pollRate)\n  defer ticker.Stop()\n\n  for {\n    select {\n    case &lt;-ctx.Done():\n      return ctx.Err()\n    case &lt;-ticker.C:\n      if err := w.processOutbox(ctx); err != nil {\n        w.logger.Error(\"outbox processing failed\", \"error\", err)\n      }\n    }\n  }\n}\n\nfunc (w *OutboxRelayWorker) processOutbox(ctx context.Context) error {\n  // Fetch unprocessed events (oldest first)\n  events, err := w.outbox.FetchUnprocessed(ctx, w.batchSize)\n  if err != nil {\n    return fmt.Errorf(\"fetch unprocessed events: %w\", err)\n  }\n\n  if len(events) == 0 {\n    return nil // No events to process\n  }\n\n  w.logger.Info(\"processing outbox events\", \"count\", len(events))\n\n  for _, event := range events {\n    if err := w.publishEvent(ctx, event); err != nil {\n      // Log error but continue processing other events\n      w.logger.Error(\"failed to publish event\",\n        \"event_id\", event.ID,\n        \"booking_id\", event.BookingID,\n        \"error\", err,\n      )\n\n      // Update retry count and error message\n      w.outbox.IncrementRetryCount(ctx, event.ID, err.Error())\n\n      // Move to dead-letter queue after 5 retries\n      if event.RetryCount &gt;= 5 {\n        w.logger.Error(\"event moved to DLQ\", \"event_id\", event.ID)\n        w.outbox.MoveToDLQ(ctx, event.ID)\n      }\n\n      continue\n    }\n\n    // Mark event as processed\n    if err := w.outbox.MarkProcessed(ctx, event.ID); err != nil {\n      w.logger.Error(\"failed to mark event processed\",\n        \"event_id\", event.ID,\n        \"error\", err,\n      )\n    }\n  }\n\n  return nil\n}\n\nfunc (w *OutboxRelayWorker) publishEvent(ctx context.Context, event OutboxEntry) error {\n  // Publish to Kafka with retries\n  message := kafka.Message{\n    Topic: \"booking-events\",\n    Key:   event.BookingID.String(),\n    Value: event.EventPayload,\n    Headers: []kafka.Header{\n      {Key: \"event_type\", Value: []byte(event.EventType)},\n      {Key: \"event_id\", Value: []byte(uuid.New().String())},\n    },\n  }\n\n  // Kafka publish with timeout\n  publishCtx, cancel := context.WithTimeout(ctx, 10*time.Second)\n  defer cancel()\n\n  if err := w.kafka.Produce(publishCtx, message); err != nil {\n    return fmt.Errorf(\"kafka publish: %w\", err)\n  }\n\n  w.logger.Info(\"event published to kafka\",\n    \"event_id\", event.ID,\n    \"booking_id\", event.BookingID,\n    \"event_type\", event.EventType,\n  )\n\n  return nil\n}\n</code></pre>"},{"location":"examples/example-adr/#55-concurrency-control","title":"5.5 Concurrency Control","text":""},{"location":"examples/example-adr/#strategy-optimistic-locking-with-version-column","title":"Strategy: Optimistic Locking with Version Column","text":"<ul> <li>Add <code>version</code> column to bookings table</li> <li>Increment version on every update</li> <li>UPDATE query includes WHERE clause with current version</li> <li>If affected rows = 0, version conflict detected \u2192 return 409 Conflict</li> </ul> <pre><code>-- Optimistic locking in UPDATE query\nUPDATE bookings \nSET \n  status = 'cancelled',\n  cancelled_at = NOW(),\n  cancellation_reason = $1,\n  cancellation_notes = $2,\n  version = version + 1\nWHERE \n  id = $3 \n  AND version = $4  -- Only update if version matches\nRETURNING *;\n</code></pre>"},{"location":"examples/example-adr/#idempotency-handling","title":"Idempotency Handling","text":"<p>Decision: Cancellation API is idempotent - If booking is already cancelled, return 200 OK with existing cancellation data - No error, no duplicate event published - Simplifies client retry logic</p> <pre><code>// Idempotency check before processing\nif booking.Status == StatusCancelled {\n  // Already cancelled - return existing data (idempotent)\n  return booking, nil\n}\n</code></pre>"},{"location":"examples/example-adr/#6-monitoring-and-observability","title":"6. Monitoring and Observability","text":""},{"location":"examples/example-adr/#61-metrics-prometheus","title":"6.1 Metrics (Prometheus)","text":"<pre><code># API Metrics\nbooking_cancellation_requests_total{status=\"success|error|conflict\"} - Counter\nbooking_cancellation_duration_seconds - Histogram (p50, p95, p99)\nbooking_cancellation_errors_total{error_type} - Counter\n\n# Outbox Metrics\nbooking_outbox_size - Gauge (current unprocessed events)\nbooking_outbox_processing_lag_seconds - Gauge (oldest unprocessed event age)\nbooking_outbox_events_published_total{status=\"success|error\"} - Counter\nbooking_outbox_retry_count - Histogram\nbooking_outbox_dlq_size - Gauge (dead-letter queue size)\n</code></pre>"},{"location":"examples/example-adr/#62-alerts-alertmanager","title":"6.2 Alerts (Alertmanager)","text":"<pre><code>groups:\n  - name: booking_cancellation\n    rules:\n      - alert: HighCancellationErrorRate\n        expr: |\n          rate(booking_cancellation_errors_total[5m]) \n          / rate(booking_cancellation_requests_total[5m]) &gt; 0.05\n        for: 5m\n        annotations:\n          summary: \"Cancellation API error rate &gt; 5%\"\n\n      - alert: CancellationLatencyHigh\n        expr: |\n          histogram_quantile(0.95, booking_cancellation_duration_seconds) &gt; 0.5\n        for: 5m\n        annotations:\n          summary: \"Cancellation API p95 latency &gt; 500ms\"\n\n      - alert: OutboxBacklogHigh\n        expr: booking_outbox_size &gt; 10000\n        for: 10m\n        annotations:\n          summary: \"Outbox backlog &gt; 10k events\"\n\n      - alert: OutboxProcessingLag\n        expr: booking_outbox_processing_lag_seconds &gt; 60\n        for: 5m\n        annotations:\n          summary: \"Outbox processing lag &gt; 60 seconds\"\n\n      - alert: OutboxDLQGrowing\n        expr: increase(booking_outbox_dlq_size[1h]) &gt; 100\n        annotations:\n          summary: \"Dead-letter queue growing (100+ events/hour)\"\n</code></pre>"},{"location":"examples/example-adr/#63-logging","title":"6.3 Logging","text":"<pre><code>// Structured logging with correlation IDs\nlog.Info(\"booking cancellation requested\",\n  \"booking_id\", bookingID,\n  \"user_id\", userID,\n  \"request_id\", requestID,\n)\n\nlog.Info(\"booking cancelled successfully\",\n  \"booking_id\", bookingID,\n  \"user_id\", userID,\n  \"reason\", reason,\n  \"duration_ms\", elapsed,\n)\n\nlog.Error(\"cancellation failed\",\n  \"booking_id\", bookingID,\n  \"error\", err,\n  \"error_type\", errorType,\n)\n</code></pre>"},{"location":"examples/example-adr/#64-tracing-opentelemetry","title":"6.4 Tracing (OpenTelemetry)","text":"<ul> <li>Distributed trace from API \u2192 Database \u2192 Outbox \u2192 Kafka \u2192 Notification</li> <li>Trace cancellation flow across microservices</li> <li>Identify bottlenecks and latency sources</li> </ul>"},{"location":"examples/example-adr/#7-deployment-strategy","title":"7. Deployment Strategy","text":""},{"location":"examples/example-adr/#71-migration-plan","title":"7.1 Migration Plan","text":""},{"location":"examples/example-adr/#phase-1-database-migration-week-1-monday","title":"Phase 1: Database Migration (Week 1 - Monday)","text":"<pre><code># Apply schema changes (non-breaking)\n./migrate apply 023_booking_cancellation\n</code></pre> <ul> <li>Add new columns to bookings table (nullable, non-breaking)</li> <li>Create outbox table</li> <li>Create indexes</li> <li>Run in staging environment first</li> <li>Verify performance impact on existing queries</li> </ul>"},{"location":"examples/example-adr/#phase-2-code-deployment-week-1-wednesday","title":"Phase 2: Code Deployment (Week 1 - Wednesday)","text":"<pre><code># Deploy with feature flag OFF\n./deploy booking-service v2.3.0 --flag enable_booking_cancellation=false\n</code></pre> <ul> <li>Deploy new code to production</li> <li>Feature flag keeps cancellation endpoint disabled</li> <li>Verify service health metrics</li> </ul>"},{"location":"examples/example-adr/#phase-3-outbox-worker-deployment-week-1-thursday","title":"Phase 3: Outbox Worker Deployment (Week 1 - Thursday)","text":"<pre><code># Deploy 3 instances of outbox relay worker\n./deploy booking-outbox-worker v1.0.0 --replicas=3\n</code></pre> <ul> <li>Deploy outbox relay workers</li> <li>Verify workers are polling outbox table</li> <li>Verify Kafka connectivity</li> </ul>"},{"location":"examples/example-adr/#phase-4-soft-launch-week-2-monday","title":"Phase 4: Soft Launch (Week 2 - Monday)","text":"<pre><code># Enable for 10% of users\n./feature-flag enable_booking_cancellation --percentage=10\n</code></pre> <ul> <li>Enable feature flag for 10% of traffic</li> <li>Monitor metrics closely for 24 hours</li> <li>Watch for errors, latency spikes, outbox backlog</li> </ul>"},{"location":"examples/example-adr/#phase-5-gradual-rollout-week-2","title":"Phase 5: Gradual Rollout (Week 2)","text":"<ul> <li>Day 2: 25% of users</li> <li>Day 3: 50% of users</li> <li>Day 4: 100% of users</li> </ul>"},{"location":"examples/example-adr/#72-rollback-plan","title":"7.2 Rollback Plan","text":""},{"location":"examples/example-adr/#if-api-issues-detected","title":"If API Issues Detected","text":"<pre><code># Instant rollback via feature flag\n./feature-flag enable_booking_cancellation --percentage=0\n</code></pre>"},{"location":"examples/example-adr/#if-database-issues-detected","title":"If Database Issues Detected","text":"<pre><code># Rollback migration (safe - columns are nullable)\n./migrate rollback 023_booking_cancellation\n</code></pre>"},{"location":"examples/example-adr/#if-outbox-worker-issues-detected","title":"If Outbox Worker Issues Detected","text":"<pre><code># Stop outbox workers\n./deploy booking-outbox-worker --replicas=0\n\n# Events are safe in outbox table, can replay later\n</code></pre>"},{"location":"examples/example-adr/#8-testing-strategy","title":"8. Testing Strategy","text":""},{"location":"examples/example-adr/#81-unit-tests","title":"8.1 Unit Tests","text":"<pre><code>// Service layer tests\nTestCancelBooking_Success\nTestCancelBooking_AlreadyCancelled_Idempotent\nTestCancelBooking_InvalidStatus_ReturnsError\nTestCancelBooking_UnauthorizedUser_ReturnsError\nTestCancelBooking_ConcurrentModification_ReturnsConflict\nTestCancelBooking_OutboxWriteFailure_RollsBackTransaction\n\n// Outbox worker tests\nTestOutboxRelay_PublishesEvents\nTestOutboxRelay_RetriesOnFailure\nTestOutboxRelay_MovesToDLQAfter5Retries\n</code></pre>"},{"location":"examples/example-adr/#82-integration-tests","title":"8.2 Integration Tests","text":"<pre><code>// End-to-end tests with real database\nTestE2E_CancelBooking_DatabaseAndOutbox\nTestE2E_ConcurrentCancellations_NoRaceCondition\nTestE2E_OutboxWorker_PublishesToKafka\n</code></pre>"},{"location":"examples/example-adr/#83-load-tests-locustk6","title":"8.3 Load Tests (Locust/k6)","text":"<pre><code>// Load test scenario: 1000 concurrent cancellations\nexport default function() {\n  const bookingId = getRandomBooking();\n  const response = http.post(\n    `${BASE_URL}/v1/bookings/${bookingId}/cancel`,\n    JSON.stringify({\n      reason: 'change_of_plans',\n      notes: 'Load test'\n    }),\n    { headers: { 'Authorization': `Bearer ${TOKEN}` } }\n  );\n\n  check(response, {\n    'status is 200': (r) =&gt; r.status === 200,\n    'latency &lt; 500ms': (r) =&gt; r.timings.duration &lt; 500,\n  });\n}\n</code></pre> <p>Load Test Targets: - 1000 concurrent requests - p95 latency &lt; 500ms - Error rate &lt; 1% - Zero data loss (all events in outbox)</p>"},{"location":"examples/example-adr/#9-security-considerations","title":"9. Security Considerations","text":""},{"location":"examples/example-adr/#91-authorization","title":"9.1 Authorization","text":"<ul> <li>\u2705 JWT token validation on every request</li> <li>\u2705 User ownership verification (booking.user_id == jwt.user_id)</li> <li>\u2705 No admin override without audit log</li> </ul>"},{"location":"examples/example-adr/#92-input-validation","title":"9.2 Input Validation","text":"<ul> <li>\u2705 Cancellation reason must be valid enum</li> <li>\u2705 Notes field max length: 1000 characters</li> <li>\u2705 SQL injection prevention (parameterized queries)</li> </ul>"},{"location":"examples/example-adr/#93-audit-logging","title":"9.3 Audit Logging","text":"<ul> <li>\u2705 All cancellations logged with user_id, IP address, timestamp</li> <li>\u2705 Logs retained for 12 months for compliance</li> <li>\u2705 Audit log writes do not block API response</li> </ul>"},{"location":"examples/example-adr/#94-rate-limiting-future-enhancement","title":"9.4 Rate Limiting (Future Enhancement)","text":"<ul> <li>\ud83d\udd04 Not implemented in MVP</li> <li>\ud83d\udd04 Monitor cancellation patterns in production</li> <li>\ud83d\udd04 Add rate limiting if abuse detected</li> </ul>"},{"location":"examples/example-adr/#10-operational-playbook","title":"10. Operational Playbook","text":""},{"location":"examples/example-adr/#101-common-issues","title":"10.1 Common Issues","text":""},{"location":"examples/example-adr/#issue-outbox-backlog-growing","title":"Issue: Outbox backlog growing","text":"<p>Symptoms: <code>booking_outbox_size</code> metric increasing Diagnosis: <pre><code># Check outbox size\nSELECT COUNT(*) FROM booking_outbox WHERE processed_at IS NULL;\n\n# Check oldest unprocessed event\nSELECT MIN(created_at) FROM booking_outbox WHERE processed_at IS NULL;\n</code></pre> Resolution: - Scale up outbox workers: <code>./scale booking-outbox-worker --replicas=10</code> - Check Kafka connectivity - Check worker logs for errors</p>"},{"location":"examples/example-adr/#issue-dead-letter-queue-growing","title":"Issue: Dead-letter queue growing","text":"<p>Symptoms: <code>booking_outbox_dlq_size</code> metric increasing Diagnosis: <pre><code># Check DLQ events\nSELECT * FROM booking_outbox WHERE retry_count &gt;= 5 LIMIT 10;\n</code></pre> Resolution: - Investigate event payload for malformed data - Fix issue and manually replay events - Update event schema if needed</p>"},{"location":"examples/example-adr/#issue-high-cancellation-error-rate","title":"Issue: High cancellation error rate","text":"<p>Symptoms: <code>booking_cancellation_errors_total</code> spiking Diagnosis: <pre><code># Check error types\nSELECT error_type, COUNT(*) \nFROM logs \nWHERE operation='cancel_booking' AND level='error' \nGROUP BY error_type;\n</code></pre> Resolution: - If authorization errors: check JWT validation logic - If database errors: check connection pool health - If conflict errors: check for UI bug causing double-clicks</p>"},{"location":"examples/example-adr/#11-consequences","title":"11. Consequences","text":""},{"location":"examples/example-adr/#positive-consequences","title":"Positive Consequences","text":"<p>\u2705 Reliability: Zero event loss guaranteed by transactional outbox \u2705 Performance: API latency meets SLA (async event publishing) \u2705 Scalability: Handles 1000 concurrent requests easily \u2705 Maintainability: Clear separation of concerns (API \u2192 DB \u2192 Events) \u2705 Observability: Comprehensive metrics, alerts, and tracing \u2705 Resilience: System degrades gracefully (Kafka downtime doesn't break API)</p>"},{"location":"examples/example-adr/#negative-consequences","title":"Negative Consequences","text":"<p>\u26a0\ufe0f Complexity: Additional infrastructure (outbox table + relay workers) \u26a0\ufe0f Eventual Consistency: Slight delay between cancellation and notification (acceptable) \u26a0\ufe0f Operational Overhead: Need to monitor outbox backlog and DLQ</p>"},{"location":"examples/example-adr/#mitigations-for-negative-consequences","title":"Mitigations for Negative Consequences","text":"<ul> <li>Complexity: Playbook entry documents pattern for future use</li> <li>Eventual Consistency: SLA allows 30 seconds for notification delivery</li> <li>Operational Overhead: Automated alerts and runbooks reduce manual work</li> </ul>"},{"location":"examples/example-adr/#12-follow-up-actions","title":"12. Follow-Up Actions","text":""},{"location":"examples/example-adr/#immediate-before-production-launch","title":"Immediate (Before Production Launch)","text":"<ul> <li> Create runbook for outbox backlog issues</li> <li> Set up Prometheus alerts</li> <li> Create Grafana dashboard for cancellation metrics</li> <li> Document rollback procedure</li> <li> Load test with 1000 concurrent requests</li> </ul>"},{"location":"examples/example-adr/#short-term-1-2-sprints","title":"Short-term (1-2 Sprints)","text":"<ul> <li> Add distributed tracing with OpenTelemetry</li> <li> Implement outbox cleanup job (delete processed events &gt; 30 days)</li> <li> Add cancellation analytics dashboard</li> <li> Create playbook entry for Transactional Outbox Pattern</li> </ul>"},{"location":"examples/example-adr/#long-term-future-enhancements","title":"Long-term (Future Enhancements)","text":"<ul> <li> Add cancellation deadlines (e.g., can't cancel within 24h of start time)</li> <li> Add cancellation fees/penalties</li> <li> Add partial cancellations (cancel some items in booking)</li> <li> Add rate limiting per user</li> </ul>"},{"location":"examples/example-adr/#13-references","title":"13. References","text":""},{"location":"examples/example-adr/#related-patterns","title":"Related Patterns","text":"<ul> <li>Transactional Outbox Pattern: See <code>example-playbook-entry.md</code></li> <li>Optimistic Locking: Standard concurrency control pattern</li> <li>Idempotent API Design: REST API best practice</li> </ul>"},{"location":"examples/example-adr/#related-documents","title":"Related Documents","text":"<ul> <li>PRD-015: Booking Cancellation Feature (Product Requirements)</li> <li>AI-DAA: Booking Cancellation Domain Model (Domain Analysis)</li> <li>RFC-023: Booking Cancellation Implementation (Technical Proposal)</li> </ul>"},{"location":"examples/example-adr/#external-resources","title":"External Resources","text":"<ul> <li>Transactional Outbox Pattern - Chris Richardson</li> <li>Optimistic Offline Lock - Martin Fowler</li> <li>Idempotency in APIs - Stripe Documentation</li> </ul> <p>Decision Status: Accepted Decision Date: 2024-01-25 Review Date: 2024-04-25 (3 months post-launch)  </p> <p>Approval Signatures: - Engineering Lead: Jane Smith \u2713 - Senior Architect: Mike Johnson \u2713 - DevOps Lead: Sarah Chen \u2713 - Product Manager: Alex Kumar \u2713</p>"},{"location":"examples/example-daa/","title":"AI-DAA: Booking Cancellation Domain Model","text":"<p>Status: Validated Generated By: AI Validated By: Engineering Team Date: 2024-01-22 Source PRD: PRD-015 Version: 1.0  </p>"},{"location":"examples/example-daa/#1-bounded-context","title":"1. Bounded Context","text":""},{"location":"examples/example-daa/#context-name","title":"Context Name","text":"<p>Booking Management Context</p>"},{"location":"examples/example-daa/#responsibility","title":"Responsibility","text":"<p>Manages the complete lifecycle of bookings including creation, modification, cancellation, and completion.</p>"},{"location":"examples/example-daa/#core-domain-concepts","title":"Core Domain Concepts","text":"<p>This context is responsible for: - Enforcing booking business rules and invariants - Managing booking state transitions - Publishing domain events for booking lifecycle changes - Ensuring data consistency within the booking aggregate</p>"},{"location":"examples/example-daa/#2-ubiquitous-language","title":"2. Ubiquitous Language","text":""},{"location":"examples/example-daa/#key-terms","title":"Key Terms","text":"<p>Booking: A reservation made by a user for a specific resource (room, equipment, time slot)</p> <p>Booking Status: The current state of a booking - <code>confirmed</code>: Active booking that can be used or cancelled - <code>cancelled</code>: Booking that was terminated by user - <code>completed</code>: Booking that reached its end time naturally</p> <p>Cancellation: The act of terminating a confirmed booking before its scheduled end</p> <p>Cancellation Reason: User-provided explanation for why the booking was cancelled</p> <p>Confirmation Code: Unique identifier displayed to users for their booking</p>"},{"location":"examples/example-daa/#3-strategic-design","title":"3. Strategic Design","text":""},{"location":"examples/example-daa/#context-map","title":"Context Map","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Booking Management     \u2502\n\u2502  (This Context)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n            \u2502 publishes BookingCancelled event\n            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Notification           \u2502\u25c4\u2500\u2500\u2500 Downstream Consumer\n\u2502  Context                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n            \u2502 publishes BookingCancelled event\n            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Property Management    \u2502\u25c4\u2500\u2500\u2500 External System\n\u2502  Context                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"examples/example-daa/#bounded-context-relationships","title":"Bounded Context Relationships","text":"<ul> <li>Booking Management \u2192 Notification (Publisher/Subscriber)</li> <li>Booking Management \u2192 Property Management (Publisher/Subscriber)</li> <li>User Context \u2192 Booking Management (Upstream/Downstream - User provides identity)</li> </ul>"},{"location":"examples/example-daa/#4-tactical-design","title":"4. Tactical Design","text":""},{"location":"examples/example-daa/#aggregate-booking","title":"Aggregate: Booking","text":""},{"location":"examples/example-daa/#aggregate-root","title":"Aggregate Root","text":"<p>Entity: <code>Booking</code></p> <p>Identity: <code>booking_id</code> (UUID)</p>"},{"location":"examples/example-daa/#attributes","title":"Attributes","text":"<pre><code>AGGREGATE: Booking\n  AGGREGATE_ROOT: Booking\n    IDENTITY: booking_id (UUID)\n\n    ATTRIBUTES:\n      user_id: UserID (value object)\n      resource_id: ResourceID (value object)\n      status: BookingStatus (value object)\n      confirmation_code: ConfirmationCode (value object)\n      start_time: Timestamp\n      end_time: Timestamp\n      created_at: Timestamp\n      cancelled_at: Timestamp (nullable)\n      cancellation_reason: CancellationReason (value object, nullable)\n      cancellation_notes: String (nullable)\n</code></pre>"},{"location":"examples/example-daa/#value-objects","title":"Value Objects","text":"<p>BookingStatus <pre><code>VALUE_OBJECT: BookingStatus\n  VALID_VALUES: confirmed | cancelled | completed\n\n  INVARIANTS:\n    - Value must be one of the valid values\n    - Once 'cancelled' or 'completed', cannot transition to other states (terminal)\n</code></pre></p> <p>CancellationReason <pre><code>VALUE_OBJECT: CancellationReason\n  VALID_VALUES: \n    - change_of_plans\n    - double_booking\n    - found_alternative\n    - no_longer_needed\n    - other\n\n  INVARIANTS:\n    - Must be one of valid values\n    - Can only exist when status is 'cancelled'\n</code></pre></p> <p>ConfirmationCode <pre><code>VALUE_OBJECT: ConfirmationCode\n  FORMAT: 8-character alphanumeric string (e.g., \"A1B2C3D4\")\n\n  INVARIANTS:\n    - Must be unique across all bookings\n    - Cannot be changed after creation\n</code></pre></p>"},{"location":"examples/example-daa/#aggregate-invariants","title":"Aggregate Invariants","text":"<p>INV-1: Status Transition Rules <pre><code>INVARIANT: valid_status_transitions\n  - FROM confirmed TO cancelled (allowed via cancel operation)\n  - FROM confirmed TO completed (allowed via complete operation)\n  - FROM cancelled TO any state (FORBIDDEN - terminal state)\n  - FROM completed TO any state (FORBIDDEN - terminal state)\n</code></pre></p> <p>INV-2: Cancellation Consistency <pre><code>INVARIANT: cancellation_data_consistency\n  - IF status = cancelled THEN cancellation_reason MUST exist\n  - IF status = cancelled THEN cancelled_at MUST exist\n  - IF status \u2260 cancelled THEN cancellation_reason MUST be null\n  - IF status \u2260 cancelled THEN cancelled_at MUST be null\n</code></pre></p> <p>INV-3: Ownership <pre><code>INVARIANT: user_ownership\n  - Only the user who created the booking (user_id) can cancel it\n  - This is enforced at the application/service layer, not in the aggregate\n</code></pre></p>"},{"location":"examples/example-daa/#5-operations","title":"5. Operations","text":""},{"location":"examples/example-daa/#operation-cancel","title":"Operation: cancel()","text":"<pre><code>OPERATION: cancel(cancellation_reason: CancellationReason, notes: String) \u2192 Result&lt;BookingCancelled, CancellationError&gt;\n\n  PRECONDITIONS:\n    - booking.status MUST equal 'confirmed'\n    - cancellation_reason MUST be valid CancellationReason value\n\n  PROCESS:\n    1. Validate preconditions\n       IF status \u2260 'confirmed' THEN\n         RETURN Error(CancellationError.InvalidState)\n\n    2. Update aggregate state\n       SET status = 'cancelled'\n       SET cancelled_at = NOW()\n       SET cancellation_reason = cancellation_reason\n       SET cancellation_notes = notes\n\n    3. Create domain event\n       CREATE EVENT BookingCancelled WITH {\n         booking_id: this.booking_id,\n         user_id: this.user_id,\n         resource_id: this.resource_id,\n         confirmation_code: this.confirmation_code,\n         cancelled_at: this.cancelled_at,\n         reason: cancellation_reason,\n         notes: notes\n       }\n\n  POSTCONDITIONS:\n    - booking.status = 'cancelled'\n    - booking.cancelled_at is set\n    - booking.cancellation_reason is set\n    - BookingCancelled event is emitted\n\n  SIDE_EFFECTS:\n    - Aggregate state persisted to database\n    - BookingCancelled event published to event stream\n</code></pre>"},{"location":"examples/example-daa/#operation-complete","title":"Operation: complete()","text":"<pre><code>OPERATION: complete() \u2192 Result&lt;BookingCompleted, CompletionError&gt;\n\n  PRECONDITIONS:\n    - booking.status MUST equal 'confirmed'\n    - current_time &gt;= booking.end_time\n\n  PROCESS:\n    1. Validate preconditions\n       IF status \u2260 'confirmed' THEN\n         RETURN Error(CompletionError.InvalidState)\n       IF NOW() &lt; end_time THEN\n         RETURN Error(CompletionError.TooEarly)\n\n    2. Update aggregate state\n       SET status = 'completed'\n\n    3. Create domain event\n       CREATE EVENT BookingCompleted WITH {\n         booking_id: this.booking_id,\n         user_id: this.user_id,\n         resource_id: this.resource_id,\n         completed_at: NOW()\n       }\n\n  POSTCONDITIONS:\n    - booking.status = 'completed'\n    - BookingCompleted event is emitted\n</code></pre>"},{"location":"examples/example-daa/#6-domain-events","title":"6. Domain Events","text":""},{"location":"examples/example-daa/#bookingcancelled","title":"BookingCancelled","text":"<pre><code>DOMAIN_EVENT: BookingCancelled\n  ATTRIBUTES:\n    event_id: UUID (unique event identifier)\n    booking_id: UUID\n    user_id: UUID\n    resource_id: UUID\n    confirmation_code: String\n    cancelled_at: Timestamp\n    reason: CancellationReason\n    notes: String (optional)\n    occurred_at: Timestamp\n\n  SUBSCRIBERS:\n    - Notification Service (sends cancellation email)\n    - Property Management System (updates availability)\n    - Analytics Service (tracks cancellation metrics)\n</code></pre>"},{"location":"examples/example-daa/#bookingcompleted","title":"BookingCompleted","text":"<pre><code>DOMAIN_EVENT: BookingCompleted\n  ATTRIBUTES:\n    event_id: UUID\n    booking_id: UUID\n    user_id: UUID\n    resource_id: UUID\n    completed_at: Timestamp\n    occurred_at: Timestamp\n\n  SUBSCRIBERS:\n    - Analytics Service (tracks completion metrics)\n</code></pre>"},{"location":"examples/example-daa/#7-domain-services","title":"7. Domain Services","text":""},{"location":"examples/example-daa/#bookingcancellationservice","title":"BookingCancellationService","text":"<pre><code>DOMAIN_SERVICE: BookingCancellationService\n\n  PURPOSE:\n    Orchestrates booking cancellation logic that doesn't naturally\n    belong to the Booking aggregate\n\n  OPERATION: cancel_booking(booking_id: UUID, user_id: UUID, reason: CancellationReason, notes: String)\n\n    PROCESS:\n      1. Load Booking aggregate by booking_id\n         IF not found THEN RETURN Error(BookingNotFound)\n\n      2. Verify user ownership\n         IF booking.user_id \u2260 user_id THEN\n           RETURN Error(UnauthorizedCancellation)\n\n      3. Call booking.cancel(reason, notes)\n         IF error THEN RETURN error\n\n      4. Persist aggregate changes\n\n      5. Publish BookingCancelled event\n\n      6. RETURN Success(booking)\n</code></pre>"},{"location":"examples/example-daa/#8-repository-interface","title":"8. Repository Interface","text":"<pre><code>REPOSITORY: BookingRepository\n\n  OPERATION: find_by_id(booking_id: UUID) \u2192 Option&lt;Booking&gt;\n    Load booking aggregate by ID\n\n  OPERATION: find_by_user(user_id: UUID, status: BookingStatus) \u2192 List&lt;Booking&gt;\n    Find all bookings for a user filtered by status\n\n  OPERATION: save(booking: Booking) \u2192 Result&lt;Void, RepositoryError&gt;\n    Persist booking aggregate\n    Enforces unique confirmation_code constraint\n\n  OPERATION: exists_with_confirmation_code(code: ConfirmationCode) \u2192 Boolean\n    Check if confirmation code is already used\n</code></pre>"},{"location":"examples/example-daa/#9-sequence-diagram","title":"9. Sequence Diagram","text":"<pre><code>sequenceDiagram\n    participant User\n    participant API\n    participant Service as BookingCancellationService\n    participant Aggregate as Booking Aggregate\n    participant Repo as BookingRepository\n    participant Events as Event Publisher\n\n    User-&gt;&gt;API: POST /bookings/{id}/cancel\n    API-&gt;&gt;Service: cancel_booking(booking_id, user_id, reason, notes)\n    Service-&gt;&gt;Repo: find_by_id(booking_id)\n    Repo--&gt;&gt;Service: Booking\n\n    Service-&gt;&gt;Service: Verify user_id ownership\n\n    Service-&gt;&gt;Aggregate: cancel(reason, notes)\n    Aggregate-&gt;&gt;Aggregate: Validate status = 'confirmed'\n    Aggregate-&gt;&gt;Aggregate: Update state to 'cancelled'\n    Aggregate-&gt;&gt;Aggregate: Create BookingCancelled event\n    Aggregate--&gt;&gt;Service: Result&lt;BookingCancelled&gt;\n\n    Service-&gt;&gt;Repo: save(booking)\n    Repo--&gt;&gt;Service: Success\n\n    Service-&gt;&gt;Events: publish(BookingCancelled)\n    Events--&gt;&gt;Service: Acknowledged\n\n    Service--&gt;&gt;API: Success(booking)\n    API--&gt;&gt;User: 200 OK</code></pre>"},{"location":"examples/example-daa/#10-validation-summary","title":"10. Validation Summary","text":""},{"location":"examples/example-daa/#prd-coverage","title":"PRD Coverage","text":"<p>\u2705 US-015-1: User Cancels Confirmed Booking \u2192 Covered by <code>Booking.cancel()</code> operation</p> <p>\u2705 US-015-2: User Views Cancellation History \u2192 Covered by <code>BookingRepository.find_by_user()</code> with status filter</p> <p>\u2705 US-015-3: Prevent Invalid Cancellations \u2192 Covered by aggregate invariants and preconditions</p> <p>\u2705 BR-015-1: Cancellation Eligibility \u2192 Enforced by <code>cancel()</code> precondition (status = confirmed)</p> <p>\u2705 BR-015-2: State Transitions \u2192 Enforced by <code>BookingStatus</code> value object invariants</p> <p>\u2705 BR-015-3: Cancellation Reason \u2192 Modeled as <code>CancellationReason</code> value object</p> <p>\u2705 BR-015-4: Notification Requirements \u2192 Handled by <code>BookingCancelled</code> event subscribers</p>"},{"location":"examples/example-daa/#technology-agnostic","title":"Technology Agnostic","text":"<ul> <li>\u2705 No database mentioned (PostgreSQL, MongoDB, etc.)</li> <li>\u2705 No framework mentioned (Spring, Django, Express, etc.)</li> <li>\u2705 No programming language specified (Java, Python, Go, etc.)</li> <li>\u2705 Pure business logic and domain rules</li> </ul>"},{"location":"examples/example-daa/#11-open-questions-for-adr-phase","title":"11. Open Questions for ADR Phase","text":"<ol> <li> <p>Event Delivery Guarantee: How to ensure BookingCancelled event is published even if notification service is down?    \u2192 Suggest: Transactional Outbox Pattern</p> </li> <li> <p>Concurrent Cancellations: How to handle race condition if user clicks cancel twice?    \u2192 Suggest: Optimistic locking or database constraint</p> </li> <li> <p>Audit Trail: Should we store cancellation history separately?    \u2192 Decision needed in ADR</p> </li> <li> <p>Performance: Expected load for cancellation endpoint?    \u2192 Need to design for scalability in ADR</p> </li> </ol> <p>Validation Date: 2024-01-22 Validated By: Engineering Lead, Senior Architect Status: Approved for ADR Phase  </p>"},{"location":"examples/example-playbook-entry/","title":"PLAYBOOK-001: Transactional Outbox Pattern","text":"<p>Pattern Category: Data Consistency Complexity: Medium Maturity: Proven Last Updated: 2024-01-25  </p>"},{"location":"examples/example-playbook-entry/#1-pattern-name","title":"1. Pattern Name","text":"<p>Transactional Outbox Pattern (also known as \"Application Events Pattern\")</p>"},{"location":"examples/example-playbook-entry/#2-problem","title":"2. Problem","text":"<p>How do you reliably publish events to a message broker (e.g., Kafka, RabbitMQ) after updating a database, ensuring atomicity between the database write and the event publish?</p>"},{"location":"examples/example-playbook-entry/#common-failure-scenarios","title":"Common Failure Scenarios","text":"<p>\u274c Scenario 1: Publish-First <pre><code>1. Publish event to Kafka \u2713\n2. Write to database \u2717 (fails)\nResult: Event published but state not persisted \u2192 inconsistency\n</code></pre></p> <p>\u274c Scenario 2: Write-First, Synchronous Publish <pre><code>1. Write to database \u2713\n2. Publish event to Kafka \u2717 (Kafka down)\nResult: State persisted but event never published \u2192 downstream services miss update\n</code></pre></p> <p>\u274c Scenario 3: Distributed Transaction (2PC) <pre><code>1. Prepare: Database + Kafka\n2. Commit: Both or neither\nResult: High latency, complex coordination, single point of failure\n</code></pre></p>"},{"location":"examples/example-playbook-entry/#core-challenge","title":"Core Challenge","text":"<p>You cannot use distributed transactions across a database and a message broker because: - Kafka, RabbitMQ, and most brokers don't support two-phase commit (2PC) - Distributed transactions have high latency and poor scalability - Introduces tight coupling and single points of failure</p>"},{"location":"examples/example-playbook-entry/#3-context","title":"3. Context","text":""},{"location":"examples/example-playbook-entry/#when-this-problem-occurs","title":"When This Problem Occurs","text":"<ul> <li>Microservices Architecture: Services communicate via events/messages</li> <li>Event-Driven Systems: State changes must trigger downstream actions</li> <li>CQRS: Command side publishes events to update read models</li> <li>Domain Events: Aggregate state changes must notify other bounded contexts</li> </ul>"},{"location":"examples/example-playbook-entry/#example-use-cases","title":"Example Use Cases","text":"<p>\u2705 Order placed \u2192 Notify inventory service \u2705 User registered \u2192 Send welcome email \u2705 Payment processed \u2192 Update analytics \u2705 Booking cancelled \u2192 Send cancellation notification  </p>"},{"location":"examples/example-playbook-entry/#requirements-that-make-this-pattern-necessary","title":"Requirements That Make This Pattern Necessary","text":"<ul> <li>Atomicity: Either both database write and event publish succeed, or neither</li> <li>Reliability: No event loss even during broker downtime</li> <li>Performance: Low latency for user-facing operations</li> <li>Scalability: Handle high throughput</li> </ul>"},{"location":"examples/example-playbook-entry/#4-solution","title":"4. Solution","text":""},{"location":"examples/example-playbook-entry/#pattern-overview","title":"Pattern Overview","text":"<p>Store events in an outbox table within the same database as your primary data. A separate relay worker polls the outbox and publishes events to the message broker.</p> <pre><code>sequenceDiagram\n    participant API as Service API\n    participant DB as Database\n    participant Outbox as Outbox Table\n    participant Worker as Relay Worker\n    participant Broker as Message Broker\n    participant Consumer as Downstream Service\n\n    API-&gt;&gt;API: Business logic\n\n    rect rgb(200, 220, 250)\n        note right of API: Single ACID Transaction\n        API-&gt;&gt;DB: Write business data\n        API-&gt;&gt;Outbox: Write event\n        API-&gt;&gt;DB: COMMIT\n    end\n\n    API--&gt;&gt;API: Return success to caller\n\n    Worker-&gt;&gt;Outbox: Poll for unprocessed events\n    Outbox--&gt;&gt;Worker: Event(s)\n    Worker-&gt;&gt;Broker: Publish event\n    Broker--&gt;&gt;Worker: ACK\n    Worker-&gt;&gt;Outbox: Mark as processed\n\n    Broker-&gt;&gt;Consumer: Event\n    Consumer-&gt;&gt;Consumer: Process event</code></pre>"},{"location":"examples/example-playbook-entry/#key-components","title":"Key Components","text":"<ol> <li>Outbox Table: Database table that stores events to be published</li> <li>Transaction: Single database transaction writes both business data and outbox event</li> <li>Relay Worker: Background process that polls outbox and publishes events</li> <li>Message Broker: Kafka, RabbitMQ, etc. (downstream event distribution)</li> </ol>"},{"location":"examples/example-playbook-entry/#5-implementation-details","title":"5. Implementation Details","text":""},{"location":"examples/example-playbook-entry/#51-database-schema","title":"5.1 Database Schema","text":""},{"location":"examples/example-playbook-entry/#outbox-table-structure","title":"Outbox Table Structure","text":"<pre><code>CREATE TABLE outbox (\n  id BIGSERIAL PRIMARY KEY,\n\n  -- Event identification\n  aggregate_id UUID NOT NULL,           -- ID of the aggregate that changed\n  event_type VARCHAR(100) NOT NULL,     -- Type of event (e.g., \"OrderPlaced\")\n\n  -- Event data\n  event_payload JSONB NOT NULL,         -- Full event data as JSON\n\n  -- Metadata\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  processed_at TIMESTAMP NULL,          -- NULL = unprocessed\n\n  -- Retry handling\n  retry_count INTEGER NOT NULL DEFAULT 0,\n  last_error TEXT NULL\n);\n\n-- Index for efficient polling (only unprocessed events)\nCREATE INDEX idx_outbox_unprocessed \n  ON outbox(created_at) \n  WHERE processed_at IS NULL;\n\n-- Index for cleanup queries (processed events)\nCREATE INDEX idx_outbox_processed \n  ON outbox(processed_at) \n  WHERE processed_at IS NOT NULL;\n</code></pre>"},{"location":"examples/example-playbook-entry/#example-booking-cancellation","title":"Example: Booking Cancellation","text":"<pre><code>-- Business table\nCREATE TABLE bookings (\n  id UUID PRIMARY KEY,\n  user_id UUID NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  cancelled_at TIMESTAMP NULL,\n  -- other fields...\n);\n\n-- Outbox table (shared across all events)\nCREATE TABLE booking_outbox (\n  id BIGSERIAL PRIMARY KEY,\n  booking_id UUID NOT NULL,\n  event_type VARCHAR(100) NOT NULL,\n  event_payload JSONB NOT NULL,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  processed_at TIMESTAMP NULL\n);\n</code></pre>"},{"location":"examples/example-playbook-entry/#52-writing-events-producer-side","title":"5.2 Writing Events (Producer Side)","text":""},{"location":"examples/example-playbook-entry/#go-implementation","title":"Go Implementation","text":"<pre><code>// Service method with transaction\nfunc (s *BookingService) CancelBooking(\n  ctx context.Context,\n  bookingID uuid.UUID,\n  userID uuid.UUID,\n  reason string,\n) (*Booking, error) {\n\n  // Start database transaction\n  tx, err := s.db.BeginTx(ctx, nil)\n  if err != nil {\n    return nil, err\n  }\n  defer tx.Rollback() // Rollback if not committed\n\n  // 1. Load and update business entity\n  booking, err := s.repo.FindByID(ctx, tx, bookingID)\n  if err != nil {\n    return nil, err\n  }\n\n  booking.Cancel(reason)\n\n  if err := s.repo.Update(ctx, tx, booking); err != nil {\n    return nil, err\n  }\n\n  // 2. Write event to outbox (same transaction)\n  event := BookingCancelledEvent{\n    EventID:     uuid.New(),\n    BookingID:   bookingID,\n    UserID:      userID,\n    CancelledAt: time.Now(),\n    Reason:      reason,\n  }\n\n  if err := s.outbox.Insert(ctx, tx, OutboxEntry{\n    AggregateID:  bookingID,\n    EventType:    \"BookingCancelled\",\n    EventPayload: event.ToJSON(),\n  }); err != nil {\n    return nil, err\n  }\n\n  // 3. Commit transaction (atomic write)\n  if err := tx.Commit(); err != nil {\n    return nil, err\n  }\n\n  // Success - event will be published by relay worker\n  return booking, nil\n}\n</code></pre>"},{"location":"examples/example-playbook-entry/#python-implementation","title":"Python Implementation","text":"<pre><code>def cancel_booking(\n    booking_id: UUID,\n    user_id: UUID,\n    reason: str,\n    db: Session\n) -&gt; Booking:\n    # Start transaction\n    with db.begin():\n        # 1. Load and update business entity\n        booking = db.query(Booking).filter_by(id=booking_id).first()\n        if not booking:\n            raise BookingNotFound()\n\n        booking.cancel(reason)\n        db.add(booking)\n\n        # 2. Write event to outbox (same transaction)\n        event = BookingCancelledEvent(\n            event_id=uuid4(),\n            booking_id=booking_id,\n            user_id=user_id,\n            cancelled_at=datetime.now(),\n            reason=reason\n        )\n\n        outbox_entry = OutboxEntry(\n            aggregate_id=booking_id,\n            event_type=\"BookingCancelled\",\n            event_payload=event.to_json()\n        )\n        db.add(outbox_entry)\n\n        # 3. Commit transaction (atomic write)\n        db.commit()\n\n    return booking\n</code></pre>"},{"location":"examples/example-playbook-entry/#53-publishing-events-relay-worker","title":"5.3 Publishing Events (Relay Worker)","text":""},{"location":"examples/example-playbook-entry/#polling-based-relay-worker-go","title":"Polling-Based Relay Worker (Go)","text":"<pre><code>type OutboxRelayWorker struct {\n  outbox    OutboxRepository\n  broker    MessageBroker\n  logger    Logger\n  pollRate  time.Duration // e.g., 5 seconds\n  batchSize int           // e.g., 100 events\n}\n\nfunc (w *OutboxRelayWorker) Run(ctx context.Context) error {\n  ticker := time.NewTicker(w.pollRate)\n  defer ticker.Stop()\n\n  for {\n    select {\n    case &lt;-ctx.Done():\n      return ctx.Err()\n    case &lt;-ticker.C:\n      if err := w.processOutbox(ctx); err != nil {\n        w.logger.Error(\"outbox processing failed\", err)\n      }\n    }\n  }\n}\n\nfunc (w *OutboxRelayWorker) processOutbox(ctx context.Context) error {\n  // Fetch oldest unprocessed events (FIFO order)\n  events, err := w.outbox.FetchUnprocessed(ctx, w.batchSize)\n  if err != nil {\n    return err\n  }\n\n  if len(events) == 0 {\n    return nil // No work to do\n  }\n\n  for _, event := range events {\n    if err := w.publishEvent(ctx, event); err != nil {\n      w.logger.Error(\"failed to publish event\",\n        \"event_id\", event.ID,\n        \"error\", err,\n      )\n\n      // Increment retry count\n      w.outbox.IncrementRetry(ctx, event.ID, err.Error())\n\n      // Move to dead-letter queue after max retries\n      if event.RetryCount &gt;= 5 {\n        w.outbox.MoveToDLQ(ctx, event.ID)\n      }\n\n      continue // Continue processing other events\n    }\n\n    // Mark as processed (idempotent)\n    w.outbox.MarkProcessed(ctx, event.ID)\n  }\n\n  return nil\n}\n\nfunc (w *OutboxRelayWorker) publishEvent(\n  ctx context.Context,\n  event OutboxEntry,\n) error {\n  message := Message{\n    Topic: \"events\",\n    Key:   event.AggregateID.String(),\n    Value: event.EventPayload,\n    Headers: map[string]string{\n      \"event_type\": event.EventType,\n      \"event_id\":   uuid.New().String(),\n    },\n  }\n\n  // Publish with timeout\n  publishCtx, cancel := context.WithTimeout(ctx, 10*time.Second)\n  defer cancel()\n\n  return w.broker.Publish(publishCtx, message)\n}\n</code></pre>"},{"location":"examples/example-playbook-entry/#sql-query-for-fetching-unprocessed-events","title":"SQL Query for Fetching Unprocessed Events","text":"<pre><code>-- Fetch oldest unprocessed events (FIFO order)\nSELECT id, aggregate_id, event_type, event_payload, retry_count\nFROM outbox\nWHERE processed_at IS NULL\nORDER BY created_at ASC\nLIMIT 100;\n</code></pre>"},{"location":"examples/example-playbook-entry/#54-alternative-change-data-capture-cdc","title":"5.4 Alternative: Change Data Capture (CDC)","text":"<p>Instead of polling, use database change streams (CDC) to detect new outbox entries.</p>"},{"location":"examples/example-playbook-entry/#using-debezium-kafka-connect","title":"Using Debezium (Kafka Connect)","text":"<pre><code># Debezium connector configuration\nname: outbox-connector\nconfig:\n  connector.class: io.debezium.connector.postgresql.PostgresConnector\n  database.hostname: postgres\n  database.port: 5432\n  database.user: user\n  database.password: pass\n  database.dbname: bookings\n  table.include.list: public.outbox\n  transforms: outbox\n  transforms.outbox.type: io.debezium.transforms.outbox.EventRouter\n</code></pre> <p>Pros: - Lower latency (near real-time) - No polling overhead - Built-in at-least-once delivery</p> <p>Cons: - Additional infrastructure (Debezium, Kafka Connect) - More complex setup - Database-specific (requires WAL for PostgreSQL)</p>"},{"location":"examples/example-playbook-entry/#6-when-to-use","title":"6. When to Use","text":""},{"location":"examples/example-playbook-entry/#use-this-pattern-when","title":"\u2705 Use This Pattern When","text":"<ul> <li>Event-driven architecture: Services communicate via events</li> <li>Microservices: Need to publish domain events to other services</li> <li>Reliability required: Cannot tolerate event loss</li> <li>Database + broker: Using both transactional DB and message broker</li> <li>Asynchronous processing: Downstream consumers don't need immediate processing</li> </ul>"},{"location":"examples/example-playbook-entry/#do-not-use-this-pattern-when","title":"\u274c Do NOT Use This Pattern When","text":"<ul> <li>Synchronous responses needed: If caller needs immediate downstream result</li> <li> <p>Alternative: Use request/response (HTTP, gRPC)</p> </li> <li> <p>No database: If you're not using a transactional database</p> </li> <li> <p>Alternative: Use broker's built-in transactions (if available)</p> </li> <li> <p>Simple pub/sub: If you don't need transactional guarantees</p> </li> <li> <p>Alternative: Publish directly to broker (accept risk of event loss)</p> </li> <li> <p>Low complexity tolerance: If team can't maintain additional infrastructure</p> </li> <li>Alternative: Accept eventual consistency gaps or use simpler patterns</li> </ul>"},{"location":"examples/example-playbook-entry/#7-trade-offs","title":"7. Trade-offs","text":""},{"location":"examples/example-playbook-entry/#advantages","title":"Advantages","text":"<p>\u2705 Atomicity: Guarantees either both database write and event publish succeed, or neither \u2705 Reliability: Zero event loss (events persisted in database) \u2705 Performance: Fast API response (async event publishing) \u2705 Resilience: System continues working even if broker is down \u2705 Ordering: Events processed in FIFO order per aggregate \u2705 Retry logic: Built-in retry mechanism for failed publishes  </p>"},{"location":"examples/example-playbook-entry/#disadvantages","title":"Disadvantages","text":"<p>\u26a0\ufe0f Eventual consistency: Slight delay between database write and event delivery \u26a0\ufe0f Complexity: Additional infrastructure (outbox table + relay worker) \u26a0\ufe0f Operational overhead: Need to monitor outbox backlog and DLQ \u26a0\ufe0f Storage growth: Outbox table grows (requires cleanup job) \u26a0\ufe0f At-least-once delivery: Events may be published multiple times (consumers must be idempotent)  </p>"},{"location":"examples/example-playbook-entry/#8-edge-cases-and-gotchas","title":"8. Edge Cases and Gotchas","text":""},{"location":"examples/example-playbook-entry/#edge-case-1-duplicate-event-publishing","title":"Edge Case 1: Duplicate Event Publishing","text":"<p>Problem: Relay worker crashes after publishing event but before marking as processed.</p> <p>Impact: Event published twice to broker \u2192 downstream consumers receive duplicate.</p> <p>Solution:  - Add unique <code>event_id</code> to each event - Consumers implement idempotency (deduplicate by event_id)</p> <pre><code>// Consumer-side deduplication\nfunc (c *Consumer) HandleEvent(event Event) error {\n  // Check if event already processed\n  if c.cache.Contains(event.EventID) {\n    log.Info(\"duplicate event detected\", \"event_id\", event.EventID)\n    return nil // Skip processing\n  }\n\n  // Process event\n  if err := c.processEvent(event); err != nil {\n    return err\n  }\n\n  // Mark as processed\n  c.cache.Set(event.EventID, true, 24*time.Hour)\n  return nil\n}\n</code></pre>"},{"location":"examples/example-playbook-entry/#edge-case-2-outbox-table-growth","title":"Edge Case 2: Outbox Table Growth","text":"<p>Problem: Outbox table grows indefinitely if processed events aren't deleted.</p> <p>Impact: Slower queries, increased storage costs.</p> <p>Solution: Periodic cleanup job</p> <pre><code>-- Delete processed events older than 30 days\nDELETE FROM outbox\nWHERE processed_at IS NOT NULL\n  AND processed_at &lt; NOW() - INTERVAL '30 days';\n</code></pre> <pre><code>// Cleanup job (cron)\nfunc (j *OutboxCleanupJob) Run(ctx context.Context) error {\n  result, err := j.db.ExecContext(ctx, `\n    DELETE FROM outbox\n    WHERE processed_at IS NOT NULL\n      AND processed_at &lt; NOW() - INTERVAL '30 days'\n  `)\n  if err != nil {\n    return err\n  }\n\n  deleted, _ := result.RowsAffected()\n  j.logger.Info(\"outbox cleanup completed\", \"rows_deleted\", deleted)\n  return nil\n}\n</code></pre>"},{"location":"examples/example-playbook-entry/#edge-case-3-poisoned-events-malformed-data","title":"Edge Case 3: Poisoned Events (Malformed Data)","text":"<p>Problem: Event payload is malformed and fails to publish repeatedly.</p> <p>Impact: Blocks outbox processing, causes backlog.</p> <p>Solution: Dead-letter queue (DLQ)</p> <pre><code>// Move to DLQ after 5 failed retries\nif event.RetryCount &gt;= 5 {\n  // Move to separate DLQ table\n  if err := w.outbox.MoveToDLQ(ctx, event.ID); err != nil {\n    return err\n  }\n\n  // Alert operations team\n  w.alerting.Send(\"Outbox event moved to DLQ\", event)\n}\n</code></pre> <pre><code>-- Dead-letter queue table\nCREATE TABLE outbox_dlq (\n  id BIGINT PRIMARY KEY,\n  original_event JSONB NOT NULL,\n  error_message TEXT NOT NULL,\n  moved_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\n</code></pre>"},{"location":"examples/example-playbook-entry/#edge-case-4-relay-worker-crashes","title":"Edge Case 4: Relay Worker Crashes","text":"<p>Problem: Relay worker process crashes or is killed.</p> <p>Impact: Events not published until worker restarts.</p> <p>Solution: Deploy multiple worker instances (redundancy)</p> <pre><code># Kubernetes deployment with 3 replicas\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: outbox-relay-worker\nspec:\n  replicas: 3  # Multiple workers for redundancy\n  template:\n    spec:\n      containers:\n      - name: worker\n        image: outbox-relay:v1.0\n</code></pre> <p>Note: Multiple workers are safe because: - Each worker fetches different batch of events - <code>processed_at</code> prevents duplicate processing - Database-level locks prevent race conditions</p>"},{"location":"examples/example-playbook-entry/#edge-case-5-broker-unavailability","title":"Edge Case 5: Broker Unavailability","text":"<p>Problem: Kafka/RabbitMQ is down for extended period.</p> <p>Impact: Outbox backlog grows.</p> <p>Solution:  - Monitoring: Alert when outbox size &gt; threshold - Auto-scaling: Scale up worker replicas to handle backlog - Graceful degradation: API continues working (events queued)</p> <pre><code># Prometheus alert\n- alert: OutboxBacklogHigh\n  expr: outbox_unprocessed_count &gt; 10000\n  for: 10m\n  annotations:\n    summary: \"Outbox backlog &gt; 10k events - check broker health\"\n</code></pre>"},{"location":"examples/example-playbook-entry/#9-checklist-for-implementation","title":"9. Checklist for Implementation","text":""},{"location":"examples/example-playbook-entry/#before-writing-code","title":"Before Writing Code","text":"<ul> <li> Identify aggregates that publish events</li> <li> Define event schemas (payload structure)</li> <li> Choose event serialization format (JSON, Protobuf, Avro)</li> <li> Design outbox table schema</li> <li> Plan cleanup strategy for processed events</li> </ul>"},{"location":"examples/example-playbook-entry/#during-implementation","title":"During Implementation","text":"<ul> <li> Create outbox table with indexes</li> <li> Update service layer to write to outbox in transactions</li> <li> Implement relay worker with retry logic</li> <li> Add dead-letter queue for poisoned events</li> <li> Implement idempotency in consumers (deduplicate by event_id)</li> <li> Add unique event_id to each event</li> </ul>"},{"location":"examples/example-playbook-entry/#after-implementation","title":"After Implementation","text":"<ul> <li> Add monitoring metrics (outbox size, processing lag)</li> <li> Set up alerts (backlog, DLQ growth)</li> <li> Test failure scenarios (broker down, worker crash)</li> <li> Load test with high throughput</li> <li> Document operational runbooks</li> </ul>"},{"location":"examples/example-playbook-entry/#production-readiness","title":"Production Readiness","text":"<ul> <li> Deploy multiple relay worker instances (redundancy)</li> <li> Configure auto-scaling for workers</li> <li> Set up outbox cleanup job (cron)</li> <li> Verify at-least-once delivery guarantees</li> <li> Test rollback procedure</li> </ul>"},{"location":"examples/example-playbook-entry/#10-monitoring-and-observability","title":"10. Monitoring and Observability","text":""},{"location":"examples/example-playbook-entry/#key-metrics","title":"Key Metrics","text":"<pre><code># Prometheus metrics\noutbox_unprocessed_count - Gauge (current backlog)\noutbox_processing_lag_seconds - Gauge (age of oldest unprocessed event)\noutbox_events_published_total{status=\"success|error\"} - Counter\noutbox_retry_count - Histogram (distribution of retry counts)\noutbox_dlq_size - Gauge (dead-letter queue size)\n</code></pre>"},{"location":"examples/example-playbook-entry/#recommended-alerts","title":"Recommended Alerts","text":"<pre><code># High backlog\n- alert: OutboxBacklogHigh\n  expr: outbox_unprocessed_count &gt; 10000\n  for: 10m\n\n# Processing lag\n- alert: OutboxProcessingLag\n  expr: outbox_processing_lag_seconds &gt; 60\n  for: 5m\n\n# DLQ growth\n- alert: OutboxDLQGrowing\n  expr: increase(outbox_dlq_size[1h]) &gt; 100\n</code></pre>"},{"location":"examples/example-playbook-entry/#observability-best-practices","title":"Observability Best Practices","text":"<ul> <li>Correlation IDs: Include request_id in logs for tracing</li> <li>Distributed tracing: Trace event flow (API \u2192 Outbox \u2192 Broker \u2192 Consumer)</li> <li>Dashboard: Grafana dashboard showing outbox health metrics</li> </ul>"},{"location":"examples/example-playbook-entry/#11-example-references","title":"11. Example References","text":""},{"location":"examples/example-playbook-entry/#real-world-implementations","title":"Real-World Implementations","text":"<ul> <li>ADR-023: Booking Cancellation (this codebase)</li> <li>See <code>/docs/examples/example-adr.md</code></li> <li> <p>Cancels booking and publishes <code>BookingCancelled</code> event</p> </li> <li> <p>Order Service: Order placement</p> </li> <li>Writes order to <code>orders</code> table</li> <li>Writes <code>OrderPlaced</code> event to outbox</li> <li> <p>Triggers inventory reservation and payment processing</p> </li> <li> <p>User Service: User registration</p> </li> <li>Writes user to <code>users</code> table</li> <li>Writes <code>UserRegistered</code> event to outbox</li> <li>Triggers welcome email and analytics tracking</li> </ul>"},{"location":"examples/example-playbook-entry/#12-alternatives-considered","title":"12. Alternatives Considered","text":""},{"location":"examples/example-playbook-entry/#alternative-1-direct-broker-publish-no-outbox","title":"Alternative 1: Direct Broker Publish (No Outbox)","text":"<p>Approach: Publish to broker immediately after database write</p> <pre><code>// \u274c NOT RECOMMENDED\ntx.Commit()\nkafka.Publish(event) // If this fails, data is lost\n</code></pre> <p>Why Rejected: No atomicity guarantee - event can be lost if broker is down</p>"},{"location":"examples/example-playbook-entry/#alternative-2-two-phase-commit-2pc","title":"Alternative 2: Two-Phase Commit (2PC)","text":"<p>Approach: Distributed transaction across database and broker</p> <p>Why Rejected:  - Most brokers don't support 2PC - High latency and complexity - Single point of failure</p>"},{"location":"examples/example-playbook-entry/#alternative-3-saga-pattern","title":"Alternative 3: Saga Pattern","text":"<p>Approach: Compensating transactions for rollback</p> <p>Why Rejected: Overkill for simple event publishing (Saga better for multi-step workflows)</p>"},{"location":"examples/example-playbook-entry/#13-further-reading","title":"13. Further Reading","text":""},{"location":"examples/example-playbook-entry/#academic-papers","title":"Academic Papers","text":"<ul> <li>\"Making Reliable Distributed Systems in the Presence of Software Errors\" - Joe Armstrong (Erlang)</li> </ul>"},{"location":"examples/example-playbook-entry/#articles","title":"Articles","text":"<ul> <li>Transactional Outbox Pattern - Chris Richardson</li> <li>The Outbox Pattern - Debezium Blog</li> <li>Achieving Exactly-Once Delivery - Confluent</li> </ul>"},{"location":"examples/example-playbook-entry/#tools","title":"Tools","text":"<ul> <li>Debezium - CDC-based outbox pattern</li> <li>Kafka Connect - Connector framework</li> <li>Outbox Pattern Library (Java) - Reference implementation</li> </ul>"},{"location":"examples/example-playbook-entry/#14-version-history","title":"14. Version History","text":"Version Date Changes Author 1.0 2024-01-25 Initial playbook entry Jane Smith <p>Pattern Status: Proven in Production Recommended: Yes Review Date: 2025-01-25  </p>"},{"location":"examples/example-prd/","title":"PRD-015: Booking Cancellation Feature","text":"<p>Status: Approved Author: Product Team Date: 2024-01-15 Epic: Booking Management  </p>"},{"location":"examples/example-prd/#1-overview","title":"1. Overview","text":""},{"location":"examples/example-prd/#problem-statement","title":"Problem Statement","text":"<p>Users currently cannot cancel their bookings through the application. They must contact customer support, leading to increased support costs and poor user experience.</p>"},{"location":"examples/example-prd/#objective","title":"Objective","text":"<p>Enable users to self-serve booking cancellations directly through the application, improving user experience and reducing support burden.</p>"},{"location":"examples/example-prd/#success-metrics","title":"Success Metrics","text":"<ul> <li>80% of cancellations handled through self-service (no support contact)</li> <li>Cancellation flow completion rate &gt; 90%</li> <li>Average cancellation time &lt; 2 minutes</li> <li>Support ticket volume reduced by 50% for cancellation requests</li> </ul>"},{"location":"examples/example-prd/#2-user-stories","title":"2. User Stories","text":""},{"location":"examples/example-prd/#us-015-1-user-cancels-confirmed-booking","title":"US-015-1: User Cancels Confirmed Booking","text":"<p>As a user with a confirmed booking I want to cancel my booking So that I can free up the reservation when my plans change</p> <p>Acceptance Criteria: - User can view their confirmed bookings - User can click \"Cancel Booking\" on a confirmed booking - System prompts user to provide cancellation reason - System displays cancellation confirmation - User receives email notification of cancellation - Cancelled bookings appear in \"Cancelled\" tab</p>"},{"location":"examples/example-prd/#us-015-2-user-views-cancellation-history","title":"US-015-2: User Views Cancellation History","text":"<p>As a user I want to view my cancelled bookings So that I can track my booking history</p> <p>Acceptance Criteria: - Cancelled bookings show cancellation date - Cancelled bookings show cancellation reason - Historical data retained for at least 12 months</p>"},{"location":"examples/example-prd/#us-015-3-prevent-invalid-cancellations","title":"US-015-3: Prevent Invalid Cancellations","text":"<p>As a system I want to prevent cancellation of invalid bookings So that data integrity is maintained</p> <p>Acceptance Criteria: - Cannot cancel already-cancelled bookings - Cannot cancel completed bookings - Cannot cancel another user's bookings - Clear error messages for invalid operations</p>"},{"location":"examples/example-prd/#3-non-functional-requirements-nfrs","title":"3. Non-Functional Requirements (NFRs)","text":""},{"location":"examples/example-prd/#performance","title":"Performance","text":"<ul> <li>NFR-015-1: Cancellation API response time &lt; 500ms (p95)</li> <li>NFR-015-2: Notification delivery within 30 seconds of cancellation</li> </ul>"},{"location":"examples/example-prd/#reliability","title":"Reliability","text":"<ul> <li>NFR-015-3: 99.9% uptime for cancellation endpoint</li> <li>NFR-015-4: Zero data loss for cancellation events</li> <li>NFR-015-5: Guaranteed notification delivery (at-least-once)</li> </ul>"},{"location":"examples/example-prd/#security","title":"Security","text":"<ul> <li>NFR-015-6: Users can only cancel their own bookings</li> <li>NFR-015-7: All cancellation actions logged for audit</li> <li>NFR-015-8: Authorization checks on every cancellation request</li> </ul>"},{"location":"examples/example-prd/#scalability","title":"Scalability","text":"<ul> <li>NFR-015-9: Support 1000 concurrent cancellation requests</li> <li>NFR-015-10: Handle 50,000 cancellations per day</li> </ul>"},{"location":"examples/example-prd/#4-business-rules","title":"4. Business Rules","text":""},{"location":"examples/example-prd/#br-015-1-cancellation-eligibility","title":"BR-015-1: Cancellation Eligibility","text":"<p>Only bookings with status = <code>confirmed</code> can be cancelled.</p>"},{"location":"examples/example-prd/#br-015-2-state-transitions","title":"BR-015-2: State Transitions","text":"<ul> <li><code>confirmed</code> \u2192 <code>cancelled</code> (allowed)</li> <li><code>cancelled</code> \u2192 any state (not allowed, terminal state)</li> <li><code>completed</code> \u2192 any state (not allowed, terminal state)</li> </ul>"},{"location":"examples/example-prd/#br-015-3-cancellation-reason","title":"BR-015-3: Cancellation Reason","text":"<p>Users must provide a cancellation reason from predefined options: - Change of plans - Double booking - Found alternative - No longer needed - Other (with free text)</p>"},{"location":"examples/example-prd/#br-015-4-notification-requirements","title":"BR-015-4: Notification Requirements","text":"<p>Upon successful cancellation: 1. Send email to user with cancellation details 2. Send notification to property/resource owner 3. Trigger refund processing (if applicable)</p>"},{"location":"examples/example-prd/#5-out-of-scope","title":"5. Out of Scope","text":"<p>The following are explicitly NOT included in this release: - Partial cancellations (cancelling only some items in a booking) - Cancellation fees or penalties - Refund processing logic (handled by separate payment service) - Cancellation deadlines or time windows - Waitlist management for freed-up slots</p>"},{"location":"examples/example-prd/#6-technical-constraints","title":"6. Technical Constraints","text":""},{"location":"examples/example-prd/#tc-015-1-service-architecture","title":"TC-015-1: Service Architecture","text":"<p>Must integrate with existing booking-service microservice.</p>"},{"location":"examples/example-prd/#tc-015-2-database","title":"TC-015-2: Database","text":"<p>Use existing PostgreSQL database for booking state.</p>"},{"location":"examples/example-prd/#tc-015-3-event-publishing","title":"TC-015-3: Event Publishing","text":"<p>Use Kafka for publishing cancellation events to downstream services.</p>"},{"location":"examples/example-prd/#tc-015-4-api-standards","title":"TC-015-4: API Standards","text":"<p>Follow existing REST API conventions (versioned, JSON responses).</p>"},{"location":"examples/example-prd/#7-dependencies","title":"7. Dependencies","text":""},{"location":"examples/example-prd/#internal-dependencies","title":"Internal Dependencies","text":"<ul> <li>Booking Service: Core booking management service</li> <li>Notification Service: Email and push notification delivery</li> <li>User Service: User authentication and authorization</li> </ul>"},{"location":"examples/example-prd/#external-dependencies","title":"External Dependencies","text":"<ul> <li>Property Management System: Sync cancelled bookings with external PMS</li> <li>Email Service Provider: SendGrid for email delivery</li> </ul>"},{"location":"examples/example-prd/#8-risks","title":"8. Risks","text":""},{"location":"examples/example-prd/#r-015-1-race-conditions","title":"R-015-1: Race Conditions","text":"<p>Risk: Concurrent cancellation requests for same booking Mitigation: Database-level constraints and optimistic locking</p>"},{"location":"examples/example-prd/#r-015-2-event-delivery-failures","title":"R-015-2: Event Delivery Failures","text":"<p>Risk: Notification service unavailable during cancellation Mitigation: Use transactional outbox pattern for guaranteed delivery</p>"},{"location":"examples/example-prd/#r-015-3-high-cancellation-volume","title":"R-015-3: High Cancellation Volume","text":"<p>Risk: Unexpected spike in cancellations (e.g., weather event) Mitigation: Auto-scaling configuration and rate limiting</p>"},{"location":"examples/example-prd/#9-open-questions","title":"9. Open Questions","text":"<p>Q1: Should we allow cancellation within X hours of booking start time? Answer: Not in this phase. Future enhancement.</p> <p>Q2: Do we need a cancellation confirmation step (double-confirm)? Answer: Yes, show confirmation modal before executing cancellation.</p> <p>Q3: Should we log IP address for audit purposes? Answer: Yes, for security and fraud detection.</p>"},{"location":"examples/example-prd/#10-timeline","title":"10. Timeline","text":"<ul> <li>Design Phase: Week of Jan 22</li> <li>Implementation: Jan 29 - Feb 9</li> <li>Testing: Feb 12 - Feb 16</li> <li>Deployment: Feb 19 (soft launch to 10% users)</li> <li>Full Release: Feb 26</li> </ul>"},{"location":"examples/example-prd/#appendix-a-ui-mockups","title":"Appendix A: UI Mockups","text":"<p>(Link to Figma designs)</p>"},{"location":"examples/example-prd/#appendix-b-api-contract-draft","title":"Appendix B: API Contract Draft","text":"<pre><code>POST /v1/bookings/{booking_id}/cancel\n{\n  \"reason\": \"change_of_plans\",\n  \"notes\": \"Optional free text\"\n}\n</code></pre> <p>Approval Signatures: - Product Manager: \u2713 - Engineering Lead: \u2713 - UX Design: \u2713 - Legal/Compliance: \u2713</p>"},{"location":"examples/example-rfc/","title":"RFC-023: Booking Cancellation Implementation","text":"<p>RFC Number: RFC-023 Author: Jane Smith (Senior Engineer) Contributors: Engineering Team Status: Under Review Created: 2024-01-22 Updated: 2024-01-23 Related PRD: PRD-015 Related DAA: AI-DAA Booking Cancellation  </p>"},{"location":"examples/example-rfc/#1-summary","title":"1. Summary","text":"<p>This RFC proposes the technical implementation for the booking cancellation feature defined in PRD-015. Users will be able to cancel their confirmed bookings through a REST API, with reliable event publishing to downstream services.</p>"},{"location":"examples/example-rfc/#2-context","title":"2. Context","text":""},{"location":"examples/example-rfc/#business-need","title":"Business Need","text":"<ul> <li>Currently, 60% of support tickets are cancellation requests</li> <li>Users have no self-service option to cancel bookings</li> <li>Manual cancellations are slow and error-prone</li> </ul>"},{"location":"examples/example-rfc/#technical-context","title":"Technical Context","text":"<ul> <li>Existing <code>booking-service</code> written in Go</li> <li>PostgreSQL database for booking state</li> <li>Kafka for event streaming</li> <li>Microservices architecture with Notification and Property Management services as downstream consumers</li> </ul>"},{"location":"examples/example-rfc/#success-criteria-from-prd","title":"Success Criteria (from PRD)","text":"<ul> <li>80% self-service cancellations</li> <li>p95 API latency &lt; 500ms</li> <li>99.9% uptime</li> <li>Zero event loss</li> </ul>"},{"location":"examples/example-rfc/#3-proposed-solution","title":"3. Proposed Solution","text":""},{"location":"examples/example-rfc/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph LR\n    Client[Mobile/Web Client] --&gt;|POST /bookings/:id/cancel| API[Booking API]\n    API --&gt;|1. Update booking| DB[(PostgreSQL)]\n    API --&gt;|2. Write event| Outbox[(booking_outbox table)]\n    Worker[Outbox Relay Worker] --&gt;|3. Poll| Outbox\n    Worker --&gt;|4. Publish| Kafka[Kafka Topic: booking-events]\n    Kafka --&gt;|5. Subscribe| NS[Notification Service]\n    Kafka --&gt;|5. Subscribe| PMS[Property Mgmt Service]</code></pre>"},{"location":"examples/example-rfc/#key-design-decisions","title":"Key Design Decisions","text":""},{"location":"examples/example-rfc/#decision-1-transactional-outbox-pattern","title":"Decision 1: Transactional Outbox Pattern","text":"<p>Use the outbox pattern to guarantee event delivery without distributed transactions.</p> <p>Why: Ensures atomicity between database write and event publish. If notification service is down, cancellation still succeeds and events are delivered later.</p> <p>Trade-off: Additional complexity (outbox table + relay worker) vs. reliability guarantee.</p>"},{"location":"examples/example-rfc/#decision-2-synchronous-api-response","title":"Decision 2: Synchronous API Response","text":"<p>Return success immediately after database commit, before event publishing.</p> <p>Why: Meets p95 latency requirement of 500ms. Event publishing can be async.</p> <p>Trade-off: User might see success before notification is sent.</p>"},{"location":"examples/example-rfc/#decision-3-database-level-constraints","title":"Decision 3: Database-Level Constraints","text":"<p>Enforce business rules via database constraints where possible.</p> <p>Why: Prevents race conditions even under high concurrency.</p> <p>Trade-off: Some business logic in database layer.</p>"},{"location":"examples/example-rfc/#4-implementation-details","title":"4. Implementation Details","text":""},{"location":"examples/example-rfc/#api-contract","title":"API Contract","text":"<pre><code>POST /v1/bookings/{booking_id}/cancel\n\nRequest:\n{\n  \"reason\": \"change_of_plans\",  // Required enum\n  \"notes\": \"Optional free text\"  // Optional string\n}\n\nResponse 200 OK:\n{\n  \"booking_id\": \"uuid\",\n  \"status\": \"cancelled\",\n  \"cancelled_at\": \"2024-01-22T14:30:00Z\",\n  \"cancellation_reason\": \"change_of_plans\",\n  \"cancellation_notes\": \"Optional free text\"\n}\n\nErrors:\n- 400: Invalid reason or booking cannot be cancelled\n- 403: User does not own booking\n- 404: Booking not found\n- 500: Internal server error\n</code></pre>"},{"location":"examples/example-rfc/#database-schema-changes","title":"Database Schema Changes","text":"<pre><code>-- Add cancellation fields\nALTER TABLE bookings \n  ADD COLUMN cancelled_at TIMESTAMP,\n  ADD COLUMN cancellation_reason VARCHAR(50),\n  ADD COLUMN cancellation_notes TEXT;\n\n-- Enforce enum constraint\nALTER TABLE bookings\n  ADD CONSTRAINT check_cancellation_reason \n  CHECK (cancellation_reason IN (\n    'change_of_plans', 'double_booking', \n    'found_alternative', 'no_longer_needed', 'other'\n  ));\n\n-- Enforce consistency: if cancelled, reason must exist\nALTER TABLE bookings\n  ADD CONSTRAINT check_cancellation_consistency\n  CHECK (\n    (status = 'cancelled' AND cancellation_reason IS NOT NULL) OR\n    (status != 'cancelled' AND cancellation_reason IS NULL)\n  );\n\n-- Outbox table for reliable event publishing\nCREATE TABLE booking_outbox (\n  id BIGSERIAL PRIMARY KEY,\n  booking_id UUID NOT NULL,\n  event_type VARCHAR(100) NOT NULL,\n  event_payload JSONB NOT NULL,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  processed_at TIMESTAMP\n);\n\nCREATE INDEX idx_outbox_unprocessed ON booking_outbox(created_at) \n  WHERE processed_at IS NULL;\n</code></pre>"},{"location":"examples/example-rfc/#service-flow","title":"Service Flow","text":"<ol> <li>Authentication: Verify user JWT token</li> <li>Authorization: Verify user owns the booking</li> <li>Validation: Check booking status = 'confirmed'</li> <li>Transaction Begin</li> <li>Update booking status to 'cancelled'</li> <li>Set cancelled_at, cancellation_reason, cancellation_notes</li> <li>Insert BookingCancelled event into outbox table</li> <li>Transaction Commit</li> <li>Return 200 OK to client</li> </ol>"},{"location":"examples/example-rfc/#outbox-relay-worker","title":"Outbox Relay Worker","text":"<ul> <li>Polls <code>booking_outbox</code> every 5 seconds for unprocessed events</li> <li>Publishes events to Kafka topic <code>booking-events</code></li> <li>Marks events as processed after successful publish</li> <li>Implements retry logic with exponential backoff</li> <li>Dead-letter queue for poison pills after 5 retry attempts</li> </ul>"},{"location":"examples/example-rfc/#5-applicable-playbook-patterns","title":"5. Applicable Playbook Patterns","text":""},{"location":"examples/example-rfc/#playbook-001-transactional-outbox-pattern","title":"PLAYBOOK-001: Transactional Outbox Pattern","text":"<p>Applied: Yes - for reliable event publishing Reference: See <code>example-playbook-entry.md</code></p>"},{"location":"examples/example-rfc/#playbook-004-idempotent-api-design","title":"PLAYBOOK-004: Idempotent API Design","text":"<p>Applied: Partially - need to discuss idempotency key approach Question: Should duplicate cancel requests return 200 or 409?</p>"},{"location":"examples/example-rfc/#playbook-007-database-constraint-based-validation","title":"PLAYBOOK-007: Database Constraint-Based Validation","text":"<p>Applied: Yes - using CHECK constraints for business rules</p>"},{"location":"examples/example-rfc/#6-open-questions","title":"6. Open Questions","text":""},{"location":"examples/example-rfc/#q1-idempotency-strategy","title":"Q1: Idempotency Strategy","text":"<p>Question: How should we handle duplicate cancellation requests (e.g., user clicks twice)?</p> <p>Options: 1. Return 400 \"Already Cancelled\" error 2. Return 200 with existing cancellation data (idempotent) 3. Use idempotency key in request header</p> <p>Recommendation: Option 2 (idempotent) - simplest for clients</p> <p>Decision Needed By: Design review session</p>"},{"location":"examples/example-rfc/#q2-outbox-worker-failure-handling","title":"Q2: Outbox Worker Failure Handling","text":"<p>Question: What happens if outbox worker crashes for extended period?</p> <p>Options: 1. Manual intervention to replay events 2. Alert on outbox table size &gt; threshold 3. Multiple worker instances for redundancy</p> <p>Recommendation: Option 2 + 3 (alerting + redundancy)</p> <p>Decision Needed By: Design review session</p>"},{"location":"examples/example-rfc/#q3-cancellation-rate-limiting","title":"Q3: Cancellation Rate Limiting","text":"<p>Question: Should we rate-limit cancellations per user to prevent abuse?</p> <p>Initial Thought: Not needed for MVP. Monitor in production first.</p> <p>Decision Needed By: Product review</p>"},{"location":"examples/example-rfc/#7-security-considerations","title":"7. Security Considerations","text":"<ul> <li>\u2705 Authorization: Verify user owns booking before cancellation</li> <li>\u2705 Input validation: Enum validation for cancellation reason</li> <li>\u2705 SQL injection: Using parameterized queries</li> <li>\u2705 Audit logging: All cancellations logged with user_id and timestamp</li> <li>\u2753 Rate limiting: See Q3 above</li> </ul>"},{"location":"examples/example-rfc/#8-monitoring-observability","title":"8. Monitoring &amp; Observability","text":""},{"location":"examples/example-rfc/#metrics","title":"Metrics","text":"<pre><code>booking_cancellation_requests_total{status=\"success|error\"}\nbooking_cancellation_duration_seconds (histogram)\nbooking_outbox_size (gauge)\nbooking_outbox_processing_lag_seconds (gauge)\n</code></pre>"},{"location":"examples/example-rfc/#alerts","title":"Alerts","text":"<pre><code>- CancellationAPIErrorRate &gt; 5% for 5 minutes\n- CancellationAPILatencyP95 &gt; 500ms for 5 minutes\n- OutboxSize &gt; 10000 events (backlog alert)\n- OutboxLag &gt; 60 seconds (processing delay)\n</code></pre>"},{"location":"examples/example-rfc/#logging","title":"Logging","text":"<ul> <li>INFO: Every cancellation with booking_id, user_id, reason</li> <li>ERROR: All failures with stack traces</li> <li>Structured JSON logs for easy querying</li> </ul>"},{"location":"examples/example-rfc/#9-testing-strategy","title":"9. Testing Strategy","text":""},{"location":"examples/example-rfc/#unit-tests","title":"Unit Tests","text":"<ul> <li>Service layer: cancel logic with mocked repository</li> <li>Validation: all error cases (invalid status, wrong user, etc.)</li> <li>Outbox worker: event publishing logic</li> </ul>"},{"location":"examples/example-rfc/#integration-tests","title":"Integration Tests","text":"<ul> <li>End-to-end: API \u2192 Database \u2192 Outbox \u2192 Kafka</li> <li>Concurrent cancellations (race condition test)</li> <li>Database constraint enforcement</li> </ul>"},{"location":"examples/example-rfc/#load-tests","title":"Load Tests","text":"<ul> <li>1000 concurrent cancellation requests</li> <li>Verify p95 &lt; 500ms under load</li> <li>Verify no event loss under stress</li> </ul>"},{"location":"examples/example-rfc/#10-rollout-plan","title":"10. Rollout Plan","text":""},{"location":"examples/example-rfc/#phase-1-internal-testing-week-1","title":"Phase 1: Internal Testing (Week 1)","text":"<ul> <li>Deploy to staging with feature flag OFF</li> <li>Run integration tests and load tests</li> <li>Manual QA testing</li> </ul>"},{"location":"examples/example-rfc/#phase-2-soft-launch-week-2","title":"Phase 2: Soft Launch (Week 2)","text":"<ul> <li>Enable feature flag for 10% of users</li> <li>Monitor metrics and error rates</li> <li>Gather user feedback</li> </ul>"},{"location":"examples/example-rfc/#phase-3-full-rollout-week-3","title":"Phase 3: Full Rollout (Week 3)","text":"<ul> <li>Enable for 50% of users (if Phase 2 successful)</li> <li>Full rollout to 100% after 24 hours</li> <li>Monitor cancellation rate and support ticket reduction</li> </ul>"},{"location":"examples/example-rfc/#rollback-plan","title":"Rollback Plan","text":"<ul> <li>Feature flag can disable feature instantly</li> <li>Database migration is backwards compatible</li> <li>No data migration needed for rollback</li> </ul>"},{"location":"examples/example-rfc/#11-timeline-effort","title":"11. Timeline &amp; Effort","text":"Task Estimate Owner Database migration 2 hours Jane Service layer implementation 8 hours Jane Outbox relay worker 6 hours Mike API endpoint + validation 4 hours Jane Unit tests 6 hours Team Integration tests 4 hours Team Load testing 3 hours SRE Documentation 2 hours Jane Total 35 hours (~1 week)"},{"location":"examples/example-rfc/#12-risks-mitigation","title":"12. Risks &amp; Mitigation","text":"Risk Impact Probability Mitigation Race condition on concurrent cancels High Medium Database constraint + optimistic locking Outbox worker failure High Low Multiple workers + alerting Kafka unavailability Medium Low Outbox buffers events, no data loss High cancellation volume Medium Medium Auto-scaling + rate limiting if needed"},{"location":"examples/example-rfc/#13-alternative-approaches-considered","title":"13. Alternative Approaches Considered","text":""},{"location":"examples/example-rfc/#alternative-1-synchronous-event-publishing","title":"Alternative 1: Synchronous Event Publishing","text":"<p>Description: Publish to Kafka directly in API handler</p> <p>Pros: Simpler implementation, no outbox table needed</p> <p>Cons:  - Violates atomicity - booking cancelled but event lost if Kafka down - Increases API latency - Doesn't meet reliability NFR</p> <p>Decision: Rejected</p>"},{"location":"examples/example-rfc/#alternative-2-saga-pattern","title":"Alternative 2: Saga Pattern","text":"<p>Description: Use distributed transaction/saga for cancellation</p> <p>Pros: Stronger consistency guarantees</p> <p>Cons: - Massive overkill for this use case - Increased complexity - Cancellation is one-way operation, saga not needed</p> <p>Decision: Rejected</p>"},{"location":"examples/example-rfc/#14-next-steps","title":"14. Next Steps","text":"<ol> <li>\u2705 Draft RFC (this document)</li> <li>\u23f3 Team review and discussion</li> <li>\u23f3 AI collaborative design session (consult Playbook)</li> <li>\u23f3 Finalize design and create ADR</li> <li>\u23f3 Implementation (Bolts)</li> <li>\u23f3 Testing</li> <li>\u23f3 Deployment</li> </ol>"},{"location":"examples/example-rfc/#15-feedback-discussion","title":"15. Feedback &amp; Discussion","text":""},{"location":"examples/example-rfc/#comment-thread","title":"Comment Thread","text":"<p>Mike (DevOps) - Jan 23, 10:00 AM:</p> <p>For Q2, I recommend deploying 3 outbox worker instances behind a load balancer. We should also add a Prometheus alert if outbox size &gt; 10k.</p> <p>Sarah (Architect) - Jan 23, 11:30 AM:</p> <p>Agree with outbox pattern choice. Have you considered optimistic locking for the booking update? CAS (Compare-and-Swap) on a version column?</p> <p>Jane (Author) - Jan 23, 2:00 PM:</p> <p>@Sarah Good point. I'll add a <code>version</code> column to bookings table and implement optimistic locking in the service layer. Will update RFC.</p> <p>Status: Awaiting final review before ADR generation Next Review: 2024-01-24 Design Session</p>"},{"location":"examples/example-tip/","title":"TIP: Booking Cancellation Implementation","text":"<p>Author: Senior Engineer (Jane Smith) Date: 2024-01-22 Source PRD: PRD-015 Status: Draft (for RFC)  </p>"},{"location":"examples/example-tip/#overview","title":"Overview","text":"<p>This is a lightweight technical proposal for implementing the booking cancellation feature. Since this is a straightforward CRUD operation on an existing domain model, we can skip the full DAA and move directly to technical implementation details.</p>"},{"location":"examples/example-tip/#database-changes","title":"Database Changes","text":""},{"location":"examples/example-tip/#schema-modification","title":"Schema Modification","text":"<p>Add cancellation-related columns to existing <code>bookings</code> table:</p> <pre><code>ALTER TABLE bookings \n  ADD COLUMN cancelled_at TIMESTAMP NULL,\n  ADD COLUMN cancellation_reason VARCHAR(50) NULL,\n  ADD COLUMN cancellation_notes TEXT NULL;\n\n-- Add check constraint for cancellation reason enum\nALTER TABLE bookings\n  ADD CONSTRAINT check_cancellation_reason \n  CHECK (cancellation_reason IN (\n    'change_of_plans',\n    'double_booking', \n    'found_alternative',\n    'no_longer_needed',\n    'other'\n  ));\n\n-- Add constraint: if status = 'cancelled', reason must exist\nALTER TABLE bookings\n  ADD CONSTRAINT check_cancellation_consistency\n  CHECK (\n    (status = 'cancelled' AND cancellation_reason IS NOT NULL) OR\n    (status != 'cancelled' AND cancellation_reason IS NULL)\n  );\n\n-- Add index for querying cancelled bookings\nCREATE INDEX idx_bookings_cancelled_at ON bookings(cancelled_at) \n  WHERE cancelled_at IS NOT NULL;\n</code></pre>"},{"location":"examples/example-tip/#event-outbox-table","title":"Event Outbox Table","text":"<p>Create outbox table for reliable event publishing:</p> <pre><code>CREATE TABLE booking_outbox (\n  id BIGSERIAL PRIMARY KEY,\n  booking_id UUID NOT NULL,\n  event_type VARCHAR(100) NOT NULL,\n  event_payload JSONB NOT NULL,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  processed_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_outbox_unprocessed ON booking_outbox(created_at) \n  WHERE processed_at IS NULL;\n</code></pre>"},{"location":"examples/example-tip/#api-changes","title":"API Changes","text":""},{"location":"examples/example-tip/#new-endpoint","title":"New Endpoint","text":"<pre><code>POST /v1/bookings/{booking_id}/cancel\n</code></pre> <p>Request Headers: <pre><code>Authorization: Bearer &lt;token&gt;\nContent-Type: application/json\n</code></pre></p> <p>Request Body: <pre><code>{\n  \"reason\": \"change_of_plans\",\n  \"notes\": \"Found a better option\"\n}\n</code></pre></p> <p>Response (200 OK): <pre><code>{\n  \"booking_id\": \"a1b2c3d4-5678-90ab-cdef-1234567890ab\",\n  \"status\": \"cancelled\",\n  \"cancelled_at\": \"2024-01-22T14:30:00Z\",\n  \"cancellation_reason\": \"change_of_plans\",\n  \"cancellation_notes\": \"Found a better option\"\n}\n</code></pre></p> <p>Error Responses:</p> <pre><code>// 400 Bad Request - Invalid state\n{\n  \"error\": \"INVALID_STATUS\",\n  \"message\": \"Cannot cancel booking with status 'completed'\"\n}\n\n// 403 Forbidden - Not owner\n{\n  \"error\": \"UNAUTHORIZED\",\n  \"message\": \"You do not own this booking\"\n}\n\n// 404 Not Found\n{\n  \"error\": \"NOT_FOUND\",\n  \"message\": \"Booking not found\"\n}\n</code></pre>"},{"location":"examples/example-tip/#service-layer-changes","title":"Service Layer Changes","text":""},{"location":"examples/example-tip/#bookingservice-updates","title":"BookingService Updates","text":"<p>Add new method to <code>BookingService</code>:</p> <pre><code>// CancelBooking cancels a booking and publishes cancellation event\nfunc (s *BookingService) CancelBooking(\n  ctx context.Context,\n  bookingID uuid.UUID,\n  userID uuid.UUID,\n  reason string,\n  notes string,\n) (*Booking, error) {\n\n  // Start transaction\n  tx, err := s.db.BeginTx(ctx, nil)\n  if err != nil {\n    return nil, err\n  }\n  defer tx.Rollback()\n\n  // Load booking\n  booking, err := s.repo.FindByID(ctx, tx, bookingID)\n  if err != nil {\n    return nil, err\n  }\n\n  // Verify ownership\n  if booking.UserID != userID {\n    return nil, ErrUnauthorized\n  }\n\n  // Verify status\n  if booking.Status != StatusConfirmed {\n    return nil, ErrInvalidStatus\n  }\n\n  // Update booking\n  booking.Status = StatusCancelled\n  booking.CancelledAt = time.Now()\n  booking.CancellationReason = reason\n  booking.CancellationNotes = notes\n\n  // Save booking\n  if err := s.repo.Update(ctx, tx, booking); err != nil {\n    return nil, err\n  }\n\n  // Write to outbox\n  event := BookingCancelledEvent{\n    BookingID:   booking.ID,\n    UserID:      booking.UserID,\n    ResourceID:  booking.ResourceID,\n    CancelledAt: booking.CancelledAt,\n    Reason:      reason,\n    Notes:       notes,\n  }\n  if err := s.outbox.Insert(ctx, tx, event); err != nil {\n    return nil, err\n  }\n\n  // Commit transaction\n  if err := tx.Commit(); err != nil {\n    return nil, err\n  }\n\n  return booking, nil\n}\n</code></pre>"},{"location":"examples/example-tip/#event-publishing","title":"Event Publishing","text":""},{"location":"examples/example-tip/#outbox-relay-worker","title":"Outbox Relay Worker","text":"<p>Background worker to poll outbox and publish to Kafka:</p> <pre><code>// OutboxRelay polls outbox table and publishes events\nfunc (r *OutboxRelay) Run(ctx context.Context) {\n  ticker := time.NewTicker(5 * time.Second)\n  defer ticker.Stop()\n\n  for {\n    select {\n    case &lt;-ctx.Done():\n      return\n    case &lt;-ticker.C:\n      r.processOutbox(ctx)\n    }\n  }\n}\n\nfunc (r *OutboxRelay) processOutbox(ctx context.Context) {\n  // Fetch unprocessed events (limit 100)\n  events, err := r.outbox.FetchUnprocessed(ctx, 100)\n  if err != nil {\n    log.Error(\"failed to fetch outbox events\", err)\n    return\n  }\n\n  for _, event := range events {\n    // Publish to Kafka\n    if err := r.kafka.Publish(ctx, event); err != nil {\n      log.Error(\"failed to publish event\", err)\n      continue\n    }\n\n    // Mark as processed\n    if err := r.outbox.MarkProcessed(ctx, event.ID); err != nil {\n      log.Error(\"failed to mark event processed\", err)\n    }\n  }\n}\n</code></pre>"},{"location":"examples/example-tip/#testing-plan","title":"Testing Plan","text":""},{"location":"examples/example-tip/#unit-tests","title":"Unit Tests","text":"<ol> <li><code>TestCancelBooking_Success</code> - Happy path cancellation</li> <li><code>TestCancelBooking_AlreadyCancelled</code> - Reject already cancelled</li> <li><code>TestCancelBooking_Completed</code> - Reject completed booking</li> <li><code>TestCancelBooking_Unauthorized</code> - Reject wrong user</li> <li><code>TestCancelBooking_NotFound</code> - Handle missing booking</li> <li><code>TestOutboxRelay_PublishesEvents</code> - Verify event publishing</li> </ol>"},{"location":"examples/example-tip/#integration-tests","title":"Integration Tests","text":"<ol> <li>End-to-end cancellation flow with database</li> <li>Event publishing via outbox pattern</li> <li>Concurrent cancellation attempts (race condition)</li> </ol>"},{"location":"examples/example-tip/#load-tests","title":"Load Tests","text":"<ol> <li>1000 concurrent cancellation requests</li> <li>Verify p95 latency &lt; 500ms per NFR-015-1</li> </ol>"},{"location":"examples/example-tip/#deployment","title":"Deployment","text":""},{"location":"examples/example-tip/#database-migration","title":"Database Migration","text":"<pre><code># Run migration\n./migrate up booking_cancellation_v1\n\n# Rollback plan\n./migrate down booking_cancellation_v1\n</code></pre>"},{"location":"examples/example-tip/#feature-flag","title":"Feature Flag","text":"<p>Deploy behind feature flag <code>enable_booking_cancellation</code>:</p> <pre><code># config.yaml\nfeatures:\n  enable_booking_cancellation: true\n</code></pre>"},{"location":"examples/example-tip/#monitoring","title":"Monitoring","text":"<p>Add Prometheus metrics: - <code>booking_cancellation_requests_total</code> (counter) - <code>booking_cancellation_duration_seconds</code> (histogram) - <code>booking_cancellation_errors_total</code> (counter by error type)</p>"},{"location":"examples/example-tip/#open-questions","title":"Open Questions","text":""},{"location":"examples/example-tip/#q1-outbox-worker-failure-handling","title":"Q1: Outbox Worker Failure Handling","text":"<p>Question: What happens if outbox worker crashes? Do we risk losing events? Answer Needed: Define retry strategy and dead-letter queue</p>"},{"location":"examples/example-tip/#q2-cancellation-rate-limiting","title":"Q2: Cancellation Rate Limiting","text":"<p>Question: Should we rate-limit cancellations per user? Answer Needed: Product decision - probably not for MVP</p>"},{"location":"examples/example-tip/#q3-audit-logging","title":"Q3: Audit Logging","text":"<p>Question: Should we log cancellations to separate audit table? Answer Needed: Compliance requirement?</p>"},{"location":"examples/example-tip/#q4-idempotency","title":"Q4: Idempotency","text":"<p>Question: Should API be idempotent (same cancel request twice)? Answer Needed: Probably yes, but how to implement?</p>"},{"location":"examples/example-tip/#timeline-estimate","title":"Timeline Estimate","text":"<ul> <li>Database migration: 1 hour</li> <li>Service layer implementation: 4 hours</li> <li>Outbox relay worker: 3 hours</li> <li>API endpoint + validation: 2 hours</li> <li>Unit tests: 3 hours</li> <li>Integration tests: 2 hours</li> <li>Documentation: 1 hour</li> </ul> <p>Total: ~16 hours (2 days)</p>"},{"location":"examples/example-tip/#next-steps","title":"Next Steps","text":"<ol> <li>Review this TIP with team</li> <li>Create RFC for collaborative design review</li> <li>Consult Architectural Playbook for outbox pattern best practices</li> <li>Finalize design and create ADR</li> </ol> <p>Status: Ready for RFC review</p>"}]}